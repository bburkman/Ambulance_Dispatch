{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767154e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\tableofcontents\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea489d64",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa423799",
   "metadata": {},
   "source": [
    "- We will build models reflecting three levels of available data\n",
    "    - \"Easy\" is mostly data already available to the emergency dispatcher before the notification comes in, like month, day of week, hour, weather, urban/rural, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e2353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97e1d2b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7d47d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122b4fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install Packages\n",
      "Python version: 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:26:08) [Clang 14.0.6 ]\n",
      "NumPy version: 1.24.2\n",
      "SciPy version:  1.7.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bburkman/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.11.0\n",
      "Keras version:  2.11.0\n",
      "Pandas version:  1.5.3\n",
      "SciKit-Learn version: 1.2.2\n",
      "Imbalanced-Learn version: 0.10.1\n",
      "Finished Installing Packages\n"
     ]
    }
   ],
   "source": [
    "print ('Install Packages')\n",
    "\n",
    "import sys, copy, math, time, os\n",
    "\n",
    "print ('Python version: {}'.format(sys.version))\n",
    "\n",
    "#from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import scipy as sc\n",
    "print ('SciPy version:  {}'.format(sc.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print ('TensorFlow version:  {}'.format(tf.__version__))\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "from tensorflow import keras\n",
    "print ('Keras version:  {}'.format(keras.__version__))\n",
    "\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "#from keras.layers import IntegerLookup\n",
    "#from keras.layers import Normalization\n",
    "#from keras.layers import StringLookup\n",
    "#from keras.utils import get_custom_objects\n",
    "#from keras.utils import tf_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import pandas as pd\n",
    "print ('Pandas version:  {}'.format(pd.__version__))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "#    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Library for reading Microsoft Access files\n",
    "#import pandas_access as mdb\n",
    "\n",
    "import sklearn\n",
    "print ('SciKit-Learn version: {}'.format(sklearn.__version__))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import imblearn\n",
    "print ('Imbalanced-Learn version: {}'.format(imblearn.__version__))\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "#!pip install pydot\n",
    "\n",
    "# Set Randomness.  Copied from https://www.kaggle.com/code/abazdyrev/keras-nn-focal-loss-experiments\n",
    "import random\n",
    "#np.random.seed(42) # NumPy\n",
    "#random.seed(42) # Python\n",
    "#tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print ('Finished Installing Packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437f109",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919fb2db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Get_Data():\n",
    "    print ('Get_Data()')\n",
    "    data = pd.read_csv(\n",
    "        '../../Big_Files/CRSS_Imputed.csv',\n",
    "        low_memory=False\n",
    "    )\n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Get_Data()')\n",
    "    print ()\n",
    "    return data\n",
    "\n",
    "def Test_Get_Data():\n",
    "    data = Get_Data()\n",
    "    display (data.head())\n",
    "    \n",
    "#Test_Get_Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146091c",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb9dce",
   "metadata": {},
   "source": [
    "## Engineer Features\n",
    "- AGE_x_SEX\n",
    "    - We had found that the correlation between age and hospitalization varied by sex, so we made a new feature that captured the complexities\n",
    "- AGE_x_SCH_BUS\n",
    "    - We also found that those on a school bus had different rates of hospitalization based on age, so we created this more complex feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85fa858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Engineering_Cross_Two(data):\n",
    "    print ('Feature_Engineering_Cross_Two')\n",
    "    Pairs = [\n",
    "        ['AGE', 'SEX', 'AGE_x_SEX'],\n",
    "        ['AGE', 'SCH_BUS', 'AGE_x_SCH_BUS']\n",
    "    ]\n",
    "    for P in Pairs:\n",
    "        data[P[2]] = data[P[0]].map(str) + '_x_' + data[P[1]].map(str)\n",
    "    \n",
    "    print ()\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b900000",
   "metadata": {},
   "source": [
    "## Thin Features \n",
    "### Thin Features to only \"Hard\" Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a0c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Thin_to_Hard_Features(data):\n",
    "    print ('Thin_to_Hard_Features()')\n",
    "\n",
    "    Merge = [\n",
    "        'CASENUM',\n",
    "        'VEH_NO',\n",
    "        'PER_NO',        \n",
    "    ]\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "        'INT_HWY',\n",
    "        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "        'PERMVIT',\n",
    "        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "        'PVH_INVL',\n",
    "        'REGION',\n",
    "        'REL_ROAD',\n",
    "        'RELJCT1',\n",
    "        'RELJCT2',\n",
    "        'SCH_BUS',\n",
    "        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "        'VE_FORMS',\n",
    "        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "        'BODY_TYP',\n",
    "        'BUS_USE',\n",
    "        'EMER_USE',\n",
    "        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "        'MODEL',\n",
    "        'NUMOCCS',\n",
    "        'VALIGN',\n",
    "        'VNUM_LAN',\n",
    "        'VPROFILE',\n",
    "        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "        'VTRAFCON',\n",
    "        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "        'AGE',\n",
    "        'LOCATION',\n",
    "        'PER_TYP',\n",
    "        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "        'VEH_AGE',\n",
    "        'AGE_x_SEX',\n",
    "        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_to_Hard_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Thin_to_Hard_Features():\n",
    "    data = Get_Data()\n",
    "    data = Thin_to_Hard_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "#Test_Thin_to_Hard_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e759eda",
   "metadata": {},
   "source": [
    "### Thin Features to \"Medium\" Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4202cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Thin_to_Medium_Features(data):\n",
    "    print ('Thin_to_Medium_Features()')\n",
    "\n",
    "    Merge = [\n",
    "        'CASENUM',\n",
    "        'VEH_NO',\n",
    "        'PER_NO',        \n",
    "    ]\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "        'INT_HWY',\n",
    "#        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "#        'PERMVIT',\n",
    "#        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "#        'PVH_INVL',\n",
    "        'REGION',\n",
    "        'REL_ROAD',\n",
    "        'RELJCT1',\n",
    "#        'RELJCT2',\n",
    "#        'SCH_BUS',\n",
    "        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "#        'VE_FORMS',\n",
    "#        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "#        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "#        'BODY_TYP',\n",
    "#        'BUS_USE',\n",
    "#        'EMER_USE',\n",
    "#        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "#        'MODEL',\n",
    "#        'NUMOCCS',\n",
    "        'VALIGN',\n",
    "        'VNUM_LAN',\n",
    "        'VPROFILE',\n",
    "        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "        'VTRAFCON',\n",
    "        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "        'AGE',\n",
    "#        'LOCATION',\n",
    "#        'PER_TYP',\n",
    "        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "#        'VEH_AGE',\n",
    "        'AGE_x_SEX',\n",
    "#        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_to_Medium_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Thin_to_Medium_Features():\n",
    "    data = Get_Data()\n",
    "    data = Thin_to_Medium_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "#Test_Thin_to_Medium_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc4855",
   "metadata": {},
   "source": [
    "### Thin Features to \"Easy\" Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11264ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Thin_to_Easy_Features(data):\n",
    "    print ('Thin_to_Easy_Features()')\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "#        'INT_HWY',\n",
    "#        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "#        'PERMVIT',\n",
    "#        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "#        'PVH_INVL',\n",
    "        'REGION',\n",
    "#        'REL_ROAD',\n",
    "#        'RELJCT1',\n",
    "#        'RELJCT2',\n",
    "#        'SCH_BUS',\n",
    "#        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "#        'VE_FORMS',\n",
    "#        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "#        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "#        'BODY_TYP',\n",
    "#        'BUS_USE',\n",
    "#        'EMER_USE',\n",
    "#        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "#        'MODEL',\n",
    "#        'NUMOCCS',\n",
    "#        'VALIGN',\n",
    "#        'VNUM_LAN',\n",
    "#        'VPROFILE',\n",
    "#        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "#        'VTRAFCON',\n",
    "#        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "#        'AGE',\n",
    "#        'LOCATION',\n",
    "#        'PER_TYP',\n",
    "#        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "#        'VEH_AGE',\n",
    "#        'AGE_x_SEX',\n",
    "#        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_to_Easy_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Thin_to_Easy_Features():\n",
    "    data = Get_Data()\n",
    "    data = Thin_to_Easy_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "#Test_Thin_to_Easy_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52366e1a",
   "metadata": {},
   "source": [
    "## Get Dummies\n",
    "- Transform categorical data into one-hot-encoded features\n",
    "- For each value in the category, make a new feature that is \"1\" when the feature has that value, \"0\" otherwise.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47cefa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Dummies(data, target):\n",
    "    print ('Get_Dummies')\n",
    "    data = data.astype('category')\n",
    "    Target = data.pop(target)\n",
    "    data_Dummies = pd.get_dummies(data, prefix = data.columns)\n",
    "    data_Dummies = data_Dummies.join(Target)\n",
    "#    for feature in data_Dummies:\n",
    "#        print (feature)\n",
    "    print ()\n",
    "\n",
    "    return data_Dummies\n",
    "\n",
    "def Test_Get_Dummies():\n",
    "    print ('Test_Get_Dummies')\n",
    "    A = pd.DataFrame({\n",
    "        'A': ['a', 'b', 'a'], \n",
    "        'B': ['b', 'a', 'c'], \n",
    "        'C': [1, 2, 3]})\n",
    "    C = Get_Dummies(A, 'C')\n",
    "    display(C)\n",
    "    print ()\n",
    "\n",
    "#Test_Get_Dummies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438a4ed",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf675fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_Classifier(X_train, X_test, y_train, y_test, estimator, filename, title):\n",
    "    print ('Random Forest Classifier ', filename)\n",
    "    model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train.values.ravel(),\n",
    "    )\n",
    "    \n",
    "    # Test on training set for overfit\n",
    "    y_proba = model.predict_proba(X_train)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    y_proba = np.array(y_proba)\n",
    "    Chart_and_Plots(y_train, y_proba, y_pred, filename + '_Train', title)  \n",
    "    \n",
    "    # Test on test data, to test for underfit\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    y_proba = [x[1] for x in y_proba]\n",
    "    y_pred = K.round(y_proba).numpy()\n",
    "    y_proba = np.array(y_proba)\n",
    "    Chart_and_Plots(y_test, y_proba, y_pred, filename + '_Test', title)\n",
    "\n",
    "    print ()\n",
    "    return model    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44982302",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89d83bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chart_and_Plots(y_test, y_proba, y_pred, filename, title):\n",
    "    \n",
    "    Analyze_Prediction(y_test, y_proba, filename, title)\n",
    "    \n",
    "    print ()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d26ec6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value_Counts_y_proba\n",
      "430 332\n",
      "310\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "def Value_Counts_y_proba(y_proba, filename):\n",
    "#    print ()\n",
    "    print ('Value_Counts_y_proba')\n",
    "#    print (type(y_proba))\n",
    "    Y_proba = pd.Series(y_proba)\n",
    "    A = Y_proba.value_counts().reset_index(drop=True)\n",
    "    n = len(y_proba)\n",
    "    nA = len(A)\n",
    "#    display(Y_proba)\n",
    "#    display(A)\n",
    "    B = A.cumsum()\n",
    "#    display(B)\n",
    "#    print (B[10])\n",
    "#    print ()\n",
    "    cutoff_95 = B.sub(0.95*n).abs().idxmin() + 1\n",
    "    cutoff_90 = B.sub(0.90*n).abs().idxmin() + 1\n",
    "    cutoff_80 = B.sub(0.80*n).abs().idxmin() + 1\n",
    "    m = Y_proba.min()\n",
    "    M = Y_proba.max()\n",
    "    print (n, nA)\n",
    "    print (cutoff_95)\n",
    "#    print ()\n",
    "\n",
    "    n100 = min(100, len(B)-1)\n",
    "    n200 = min(200, len(B)-1)\n",
    "#    print ('n200 = ', n200)\n",
    "    f = open('./Analyze_Proba/Value_Counts_y_proba.csv', 'a')\n",
    "    f.write('%s,%d,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%0.4f,%0.4f\\n' % (\n",
    "        filename, n, nA, nA/n, \n",
    "        cutoff_95, cutoff_95/n,\n",
    "        cutoff_90, cutoff_90/n,\n",
    "        cutoff_80, cutoff_80/n,\n",
    "        B[10], B[10]/n,\n",
    "        B[20], B[20]/n,\n",
    "        B[n100], B[n100]/n,\n",
    "        B[n200], B[n200]/n,\n",
    "        m,M,\n",
    "    ))\n",
    "    f.close()\n",
    "    \n",
    "    H = Y_proba.value_counts().head(100)\n",
    "    Filename = './Analyze_Proba/' + filename + '_Value_Counts.csv'\n",
    "    H.to_csv(Filename)\n",
    "    \n",
    "    \n",
    "    print ('Finished')\n",
    "    return 0\n",
    "    \n",
    "def Create_Files_for_Value_Counts_y_proba():\n",
    "    f = open('./Analyze_Proba/Value_Counts_y_proba.csv', 'w')\n",
    "    f.write(\"Filename,n,nUnique,nUnique/n,95%,95%/n,90%,90%/n,80%,80%/n,B[10],B[10]/n,B[20],B[20]/n,B[100],B[100]/n,B[200],B[200],min,max,\\n\")\n",
    "    f.close()\n",
    "    \n",
    "#Create_Files_for_Value_Counts_y_proba()\n",
    "\n",
    "def Create_Files_for_Lengths_of_fpr_tpr():\n",
    "    f = open('./Analyze_Proba/Lengths_of_fpr_tpr.csv', 'w')\n",
    "    f.write(\"Filename,len(y_proba),nUnique(y_proba),len(fpr),nUnique(fpr),len(tpr),nUnique(tpr),len(fpr tpr),nUnique(fpr tpr)\\n\")\n",
    "    f.close()\n",
    "    \n",
    "def Create_Files_for_ROC_AUC():\n",
    "    f = open('./Analyze_Proba/ROC_AUC.csv', 'w')\n",
    "    f.write(\"Filename,ROC_AUC\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "def Test_Value_Counts_y_proba():\n",
    "    A = [5]*50 + [6]*20 + [i for i in range (10,40)]*2 + [i for i in range (100,400)]\n",
    "    Value_Counts_y_proba(A, 'Test')\n",
    "\n",
    "Test_Value_Counts_y_proba()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de839f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0.21039748 0.21290835 0.11695099 ... 0.1222773  0.12225795 0.12225795]\n",
      "Analyze_Prediction()\n",
      "Test_Analyze_Prediction\n",
      "y_proba:  [0.21039748 0.21290835 0.11695099 ... 0.1222773  0.12225795 0.12225795]\n",
      "y_test:  [0 0 0 ... 0 0 0]\n",
      "Test_Analyze_Prediction  has  106  custom_cut intervals\n",
      "         y_proba  y_test  custom_cut\n",
      "0       0.311074       1           0\n",
      "1       0.311074       1           0\n",
      "2       0.310847       1           0\n",
      "3       0.309719       1           0\n",
      "4       0.309220       1           0\n",
      "...          ...     ...         ...\n",
      "713561  0.106282       0         106\n",
      "713562  0.106282       0         106\n",
      "713563  0.106282       0         106\n",
      "713564  0.106282       0         106\n",
      "713565  0.106190       0         106\n",
      "\n",
      "[713566 rows x 3 columns]\n",
      "     index    Neg   Pos  index1      TN      FP      FN      TP      Prec  \\\n",
      "0      106  35559   777     106   35559  570051     777  107179  0.158261   \n",
      "1      105  26988  1000     105   62547  543063    1777  106179  0.163543   \n",
      "2      104  22833  1000     104   85380  520230    2777  105179  0.168176   \n",
      "3      103  20235  1000     103  105615  499995    3777  104179  0.172432   \n",
      "4      102  17022  1000     102  122637  482973    4777  103179  0.176028   \n",
      "5      101  15985  1000     101  138622  466988    5777  102179  0.179524   \n",
      "6      100  14405  1002     100  153027  452583    6779  101177  0.182709   \n",
      "7       99  12372  1000      99  165399  440211    7779  100177  0.185380   \n",
      "8       98  12359  1000      98  177758  427852    8779   99177  0.188181   \n",
      "9       97  11844  1000      97  189602  416008    9779   98177  0.190937   \n",
      "10      96  11819  1001      96  201421  404189   10780   97176  0.193823   \n",
      "11      95  10562  1000      95  211983  393627   11780   96176  0.196356   \n",
      "12      94  10159  1000      94  222142  383468   12780   95176  0.198845   \n",
      "13      93   9167  1000      93  231309  374301   13780   94176  0.201026   \n",
      "14      92   8903  1000      92  240212  365398   14780   93176  0.203186   \n",
      "15      91   8924  1001      91  249136  356474   15781   92175  0.205450   \n",
      "16      90   8724  1000      90  257860  347750   16781   91175  0.207723   \n",
      "17      89   8359  1000      89  266219  339391   17781   90175  0.209921   \n",
      "18      88   8171  1000      88  274390  331220   18781   89175  0.212122   \n",
      "19      87   7608  1000      87  281998  323612   19781   88175  0.214128   \n",
      "20      86   6834  1000      86  288832  316778   20781   87175  0.215805   \n",
      "21      85   7163  1000      85  295995  309615   21781   86175  0.217729   \n",
      "22      84   6347  1000      84  302342  303268   22781   85175  0.219273   \n",
      "23      83   5966  1000      83  308308  297302   23781   84175  0.220656   \n",
      "24      82   5457  1001      82  313765  291845   24782   83174  0.221786   \n",
      "25      81   5815  1000      81  319580  286030   25782   82174  0.223175   \n",
      "26      80   5221  1000      80  324801  280809   26782   81174  0.224248   \n",
      "27      79   5601  1000      79  330402  275208   27782   80174  0.225599   \n",
      "28      78   6196  1003      78  336598  269012   28785   79171  0.227383   \n",
      "29      77   6302  1000      77  342900  262710   29785   78171  0.229320   \n",
      "30      76   5631  1000      76  348531  257079   30785   77171  0.230878   \n",
      "31      75   5752  1000      75  354283  251327   31785   76171  0.232585   \n",
      "32      74   5610  1000      74  359893  245717   32785   75171  0.234259   \n",
      "33      73   5992  1000      73  365885  239725   33785   74171  0.236292   \n",
      "34      72   5776  1000      72  371661  233949   34785   73171  0.238249   \n",
      "35      71   5256  1000      71  376917  228693   35785   72171  0.239879   \n",
      "36      70   5538  1000      70  382455  223155   36785   71171  0.241810   \n",
      "37      69   5127  1000      69  387582  218028   37785   70171  0.243481   \n",
      "38      68   5517  1000      68  393099  212511   38785   69171  0.245564   \n",
      "39      67   5163  1000      67  398262  207348   39785   68171  0.247428   \n",
      "40      66   4926  1000      66  403188  202422   40785   67171  0.249157   \n",
      "41      65   5116  1000      65  408304  197306   41785   66171  0.251145   \n",
      "42      64   4880  1000      64  413184  192426   42785   65171  0.252996   \n",
      "43      63   4870  1000      63  418054  187556   43785   64171  0.254923   \n",
      "44      62   5348  1000      62  423402  182208   44785   63171  0.257443   \n",
      "45      61   4978  1000      61  428380  177230   45785   62171  0.259694   \n",
      "46      60   4874  1000      60  433254  172356   46785   61171  0.261944   \n",
      "47      59   4638  1000      59  437892  167718   47785   60171  0.264036   \n",
      "48      58   4776  1000      58  442668  162942   48785   59171  0.266400   \n",
      "49      57   4348  1000      57  447016  158594   49785   58171  0.268360   \n",
      "50      56   4409  1000      56  451425  154185   50785   57171  0.270496   \n",
      "51      55   4006  1000      55  455431  150179   51785   56171  0.272212   \n",
      "52      54   3982  1000      54  459413  146197   52785   55171  0.273981   \n",
      "53      53   4029  1000      53  463442  142168   53785   54171  0.275905   \n",
      "54      52   3991  1000      52  467433  138177   54785   53171  0.277876   \n",
      "55      51   3949  1000      51  471382  134228   55785   52171  0.279889   \n",
      "56      50   3609  1000      50  474991  130619   56785   51171  0.281484   \n",
      "57      49   3439  1000      49  478430  127180   57785   50171  0.282891   \n",
      "58      48   3822  1000      48  482252  123358   58785   49171  0.285001   \n",
      "59      47   3774  1000      47  486026  119584   59785   48171  0.287151   \n",
      "60      46   3471  1004      46  489497  116113   60789   47167  0.288872   \n",
      "61      45   3787  1000      45  493284  112326   61789   46167  0.291287   \n",
      "62      44   3561  1000      44  496845  108765   62789   45167  0.293422   \n",
      "63      43   3572  1000      43  500417  105193   63789   44167  0.295708   \n",
      "64      42   3935  1000      42  504352  101258   64789   43167  0.298889   \n",
      "65      41   4636  1000      41  508988   96622   65789   42167  0.303821   \n",
      "66      40   4531  1000      40  513519   92091   66789   41167  0.308927   \n",
      "67      39   4501  1000      39  518020   87590   67789   40167  0.314402   \n",
      "68      38   4211  1000      38  522231   83379   68789   39167  0.319611   \n",
      "69      37   3976  1000      37  526207   79403   69789   38167  0.324632   \n",
      "70      36   3855  1000      36  530062   75548   70789   37167  0.329743   \n",
      "71      35   3937  1000      35  533999   71611   71789   36167  0.335569   \n",
      "72      34   3419  1000      34  537418   68192   72789   35167  0.340241   \n",
      "73      33   3106  1000      33  540524   65086   73789   34167  0.344241   \n",
      "74      32   2759  1000      32  543283   62327   74789   33167  0.347320   \n",
      "75      31   2450  1000      31  545733   59877   75789   32167  0.349474   \n",
      "76      30   2395  1000      30  548128   57482   76789   31167  0.351578   \n",
      "77      29   3000  1000      29  551128   54482   77789   30167  0.356378   \n",
      "78      28   3110  1000      28  554238   51372   78789   29167  0.362148   \n",
      "79      27   2856  1000      27  557094   48516   79789   28167  0.367317   \n",
      "80      26   2621  1000      26  559715   45895   80789   27167  0.371835   \n",
      "81      25   2410  1000      25  562125   43485   81789   26167  0.375682   \n",
      "82      24   2743  1000      24  564868   40742   82789   25167  0.381845   \n",
      "83      23   3040  1000      23  567908   37702   83789   24167  0.390616   \n",
      "84      22   2648  1001      22  570556   35054   84790   23166  0.397905   \n",
      "85      21   2514  1000      21  573070   32540   85790   22166  0.405184   \n",
      "86      20   2120  1000      20  575190   30420   86790   21166  0.410305   \n",
      "87      19   2303  1000      19  577493   28117   87790   20166  0.417663   \n",
      "88      18   2077  1000      18  579570   26040   88790   19166  0.423970   \n",
      "89      17   1834  1000      17  581404   24206   89790   18166  0.428727   \n",
      "90      16   1642  1000      16  583046   22564   90790   17166  0.432066   \n",
      "91      15   1699  1000      15  584745   20865   91790   16166  0.436553   \n",
      "92      14   1758  1000      14  586503   19107   92790   15166  0.442506   \n",
      "93      13   1673  1000      13  588176   17434   93790   14166  0.448291   \n",
      "94      12   1634  1000      12  589810   15800   94790   13166  0.454533   \n",
      "95      11   1490  1000      11  591300   14310   95790   12166  0.459511   \n",
      "96      10   1574  1000      10  592874   12736   96790   11166  0.467158   \n",
      "97       9   1405  1000       9  594279   11331   97790   10166  0.472903   \n",
      "98       8   1322  1000       8  595601   10009   98790    9166  0.478018   \n",
      "99       7   1346  1000       7  596947    8663   99790    8166  0.485234   \n",
      "100      6   1431  1000       6  598378    7232  100790    7166  0.497708   \n",
      "101      5   1380  1000       5  599758    5852  101790    6166  0.513064   \n",
      "102      4   1318  1000       4  601076    4534  102790    5166  0.532577   \n",
      "103      3   1227  1000       3  602303    3307  103790    4166  0.557474   \n",
      "104      2   1307  1000       2  603610    2000  104790    3166  0.612853   \n",
      "105      1   1000  1100       1  604610    1000  105890    2066  0.673842   \n",
      "106      0   1000  2066       0  605610       0  107956       0       NaN   \n",
      "\n",
      "          Rec      FP/P       min       max  $\\frac{Pos}{Neg+Pos}$  \n",
      "0    0.992803  5.280401  0.106190  0.118651               0.021384  \n",
      "1    0.983540  5.030411  0.118652  0.121707               0.035730  \n",
      "2    0.974277  4.818908  0.121707  0.123417               0.041959  \n",
      "3    0.965014  4.631470  0.123417  0.125086               0.047092  \n",
      "4    0.955750  4.473795  0.125086  0.126315               0.055488  \n",
      "5    0.946487  4.325725  0.126316  0.127423               0.058875  \n",
      "6    0.937206  4.192291  0.127423  0.128316               0.065035  \n",
      "7    0.927943  4.077689  0.128317  0.129031               0.074783  \n",
      "8    0.918680  3.963207  0.129031  0.129716               0.074856  \n",
      "9    0.909417  3.853496  0.129716  0.130438               0.077857  \n",
      "10   0.900145  3.744016  0.130438  0.131103               0.078081  \n",
      "11   0.890881  3.646180  0.131103  0.131621               0.086490  \n",
      "12   0.881618  3.552077  0.131621  0.132119               0.089614  \n",
      "13   0.872355  3.467163  0.132119  0.132661               0.098357  \n",
      "14   0.863092  3.384694  0.132661  0.133235               0.100980  \n",
      "15   0.853820  3.302030  0.133235  0.133865               0.100856  \n",
      "16   0.844557  3.221220  0.133865  0.134545               0.102838  \n",
      "17   0.835294  3.143790  0.134545  0.135239               0.106849  \n",
      "18   0.826031  3.068102  0.135239  0.135864               0.109039  \n",
      "19   0.816768  2.997629  0.135864  0.136381               0.116171  \n",
      "20   0.807505  2.934325  0.136381  0.136863               0.127649  \n",
      "21   0.798242  2.867974  0.136863  0.137355               0.122504  \n",
      "22   0.788979  2.809182  0.137355  0.137757               0.136110  \n",
      "23   0.779716  2.753918  0.137757  0.138116               0.143554  \n",
      "24   0.770444  2.703370  0.138116  0.138438               0.155002  \n",
      "25   0.761180  2.649505  0.138438  0.138799               0.146735  \n",
      "26   0.751917  2.601143  0.138799  0.139165               0.160746  \n",
      "27   0.742654  2.549261  0.139165  0.139633               0.151492  \n",
      "28   0.733364  2.491867  0.139633  0.140160               0.139325  \n",
      "29   0.724101  2.433491  0.140160  0.140678               0.136949  \n",
      "30   0.714838  2.381331  0.140678  0.141152               0.150807  \n",
      "31   0.705574  2.328050  0.141152  0.141686               0.148104  \n",
      "32   0.696311  2.276085  0.141686  0.142265               0.151286  \n",
      "33   0.687048  2.220581  0.142265  0.142902               0.143021  \n",
      "34   0.677785  2.167077  0.142902  0.143531               0.147580  \n",
      "35   0.668522  2.118391  0.143532  0.144098               0.159847  \n",
      "36   0.659259  2.067092  0.144098  0.144698               0.152952  \n",
      "37   0.649996  2.019601  0.144698  0.145239               0.163212  \n",
      "38   0.640733  1.968496  0.145239  0.145835               0.153445  \n",
      "39   0.631470  1.920671  0.145836  0.146414               0.162259  \n",
      "40   0.622207  1.875042  0.146414  0.146983               0.168748  \n",
      "41   0.612944  1.827652  0.146983  0.147588               0.163506  \n",
      "42   0.603681  1.782448  0.147588  0.148211               0.170068  \n",
      "43   0.594418  1.737337  0.148211  0.148834               0.170358  \n",
      "44   0.585155  1.687799  0.148835  0.149543               0.157530  \n",
      "45   0.575892  1.641687  0.149543  0.150215               0.167280  \n",
      "46   0.566629  1.596539  0.150215  0.150839               0.170242  \n",
      "47   0.557366  1.553577  0.150839  0.151472               0.177368  \n",
      "48   0.548103  1.509337  0.151472  0.152128               0.173130  \n",
      "49   0.538840  1.469061  0.152128  0.152720               0.186986  \n",
      "50   0.529577  1.428221  0.152720  0.153344               0.184877  \n",
      "51   0.520314  1.391113  0.153344  0.153999               0.199760  \n",
      "52   0.511051  1.354228  0.153999  0.154658               0.200723  \n",
      "53   0.501788  1.316907  0.154658  0.155373               0.198847  \n",
      "54   0.492525  1.279938  0.155373  0.156150               0.200361  \n",
      "55   0.483262  1.243358  0.156150  0.156916               0.202061  \n",
      "56   0.473999  1.209928  0.156916  0.157677               0.216967  \n",
      "57   0.464736  1.178073  0.157678  0.158423               0.225276  \n",
      "58   0.455473  1.142669  0.158423  0.159308               0.207383  \n",
      "59   0.446210  1.107711  0.159308  0.160229               0.209468  \n",
      "60   0.436909  1.075559  0.160229  0.161109               0.224358  \n",
      "61   0.427646  1.040479  0.161110  0.162218               0.208899  \n",
      "62   0.418383  1.007494  0.162219  0.163385               0.219250  \n",
      "63   0.409120  0.974406  0.163385  0.164657               0.218723  \n",
      "64   0.399857  0.937956  0.164658  0.166141               0.202634  \n",
      "65   0.390594  0.895013  0.166141  0.167854               0.177431  \n",
      "66   0.381331  0.853042  0.167854  0.169525               0.180799  \n",
      "67   0.372068  0.811349  0.169525  0.171305               0.181785  \n",
      "68   0.362805  0.772342  0.171305  0.173105               0.191902  \n",
      "69   0.353542  0.735513  0.173107  0.174833               0.200965  \n",
      "70   0.344279  0.699804  0.174833  0.176858               0.205973  \n",
      "71   0.335016  0.663335  0.176858  0.179061               0.202552  \n",
      "72   0.325753  0.631665  0.179062  0.181193               0.226296  \n",
      "73   0.316490  0.602894  0.181193  0.183266               0.243546  \n",
      "74   0.307227  0.577337  0.183266  0.185282               0.266028  \n",
      "75   0.297964  0.554643  0.185282  0.187127               0.289855  \n",
      "76   0.288701  0.532458  0.187128  0.189130               0.294551  \n",
      "77   0.279438  0.504669  0.189130  0.192043               0.250000  \n",
      "78   0.270175  0.475861  0.192044  0.195425               0.243309  \n",
      "79   0.260912  0.449405  0.195425  0.198937               0.259336  \n",
      "80   0.251649  0.425127  0.198938  0.202616               0.276167  \n",
      "81   0.242386  0.402803  0.202616  0.206867               0.293255  \n",
      "82   0.233123  0.377394  0.206867  0.212250               0.267165  \n",
      "83   0.223860  0.349235  0.212252  0.217494               0.247525  \n",
      "84   0.214587  0.324706  0.217497  0.221466               0.274322  \n",
      "85   0.205324  0.301419  0.221467  0.224702               0.284576  \n",
      "86   0.196061  0.281781  0.224702  0.226970               0.320513  \n",
      "87   0.186798  0.260449  0.226970  0.229306               0.302755  \n",
      "88   0.177535  0.241209  0.229307  0.231450               0.324992  \n",
      "89   0.168272  0.224221  0.231451  0.233235               0.352858  \n",
      "90   0.159009  0.209011  0.233236  0.234778               0.378501  \n",
      "91   0.149746  0.193273  0.234779  0.236420               0.370508  \n",
      "92   0.140483  0.176989  0.236421  0.238195               0.362582  \n",
      "93   0.131220  0.161492  0.238196  0.239977               0.374111  \n",
      "94   0.121957  0.146356  0.239978  0.241828               0.379651  \n",
      "95   0.112694  0.132554  0.241828  0.243582               0.401606  \n",
      "96   0.103431  0.117974  0.243583  0.245643               0.388500  \n",
      "97   0.094168  0.104959  0.245643  0.247554               0.415800  \n",
      "98   0.084905  0.092714  0.247555  0.249536               0.430663  \n",
      "99   0.075642  0.080246  0.249537  0.251618               0.426257  \n",
      "100  0.066379  0.066990  0.251619  0.254114               0.411353  \n",
      "101  0.057116  0.054207  0.254114  0.257019               0.420168  \n",
      "102  0.047853  0.041999  0.257021  0.260243               0.431406  \n",
      "103  0.038590  0.030633  0.260246  0.263991               0.449035  \n",
      "104  0.029327  0.018526  0.263997  0.269729               0.433463  \n",
      "105  0.019137  0.009263  0.269732  0.277632               0.523810  \n",
      "106  0.000000  0.000000  0.277642  0.311074               0.673842  \n"
     ]
    }
   ],
   "source": [
    "def Analyze_Prediction(y_test, y_proba, filename, title):\n",
    "    print ('Analyze_Prediction()')\n",
    "    print (filename)\n",
    "    \n",
    "\n",
    "    print ('y_proba: ',y_proba)\n",
    "    print ('y_test: ', y_test)\n",
    "    A = pd.DataFrame(y_proba, columns=['y_proba'])\n",
    "    B = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    C = pd.concat([A,B], axis=1)\n",
    "    \n",
    "    # Sort the y_proba values with p==1 at the top.\n",
    "    # Make a feature, 'custom_cut'\n",
    "    # Make a cut large enough that it has at least 1000 elements of each class.\n",
    "    # Do not cut between two y_proba of the same value; \n",
    "    #    keep going until you get to a different y_proba value.\n",
    "    # Label that cut \"0,\" and the next cut \"1,\" etc.\n",
    "    \n",
    "    C.sort_values(by=['y_proba'], ascending=False, inplace=True)\n",
    "    C = C.reset_index(drop=True)\n",
    "    C['custom_cut'] = 0\n",
    "    \n",
    "    n0 = 0\n",
    "    n1 = 0\n",
    "    j = 0\n",
    "    C['custom_cut'][0] = j\n",
    "    if C['y_test'][0]==0:\n",
    "        n0 += 1\n",
    "    else:\n",
    "        n1 += 1\n",
    "    for i in range (1,len(C)):\n",
    "#        if i%1000==0:\n",
    "#            print (i, j)\n",
    "        if (\n",
    "            min(n0,n1)>=1000 and \n",
    "            C['y_proba'][i] != C['y_proba'][i-1] \n",
    "        ):\n",
    "            n0 = 0\n",
    "            n1 = 0\n",
    "            j = j+1\n",
    "        if C['y_test'][i]==0:\n",
    "            n0 += 1\n",
    "        else:\n",
    "            n1 += 1\n",
    "        C['custom_cut'][i] = j\n",
    "    print (filename, ' has ', j, ' custom_cut intervals')\n",
    "    print (C)\n",
    "    \n",
    "    # Count the positive and negative elements in each of the custom_cuts\n",
    "    \n",
    "    D = C[C['y_test']==0]\n",
    "    E = C[C['y_test']==1]\n",
    "\n",
    "    F = D['custom_cut'].value_counts(sort=False).rename(\"Neg\")\n",
    "    G = E['custom_cut'].value_counts(sort=False).rename(\"Pos\")\n",
    "    H = pd.concat([F,G], axis=1, names=['Neg','Pos'])\n",
    "\n",
    "    H['index1'] = H.index\n",
    "    H.sort_values(by=['index1'], ascending=False, inplace=True)\n",
    "    H = H.reset_index()\n",
    "    H['TN'] = H['Neg'].cumsum()\n",
    "    H['FP'] = len(D) - H['TN']\n",
    "    H['FN'] = H['Pos'].cumsum()\n",
    "    H['TP'] = len(E) - H['FN']\n",
    "    H['Prec'] = H['TP']/(H['FP'] + H['TP'])\n",
    "    H['Rec'] = H['TP']/(H['FN'] + H['TP'])\n",
    "    H['FP/P'] = H['FP']/(H['FN'] + H['TP'])\n",
    "    \n",
    "\n",
    "    H['min'] = 0\n",
    "    H['max'] = 0\n",
    "    \n",
    "    for i in range (len(H)):\n",
    "        I = C[C['custom_cut']==H['index1'][i]]\n",
    "        H['min'][i] = I['y_proba'].min()\n",
    "        H['max'][i] = I['y_proba'].max()\n",
    "        \n",
    "    \n",
    "    \n",
    "    H['$\\\\frac{Pos}{Neg+Pos}$'] = H['Pos']/(H['Neg']+H['Pos'])\n",
    "    print (H)\n",
    "    \n",
    "def Test_Analyze_Prediction():\n",
    "    y_test = pd.read_csv(\"../../Big_Files/y_test.csv\").to_numpy().transpose()[0]\n",
    "    y_proba = pd.read_csv(\"../../Big_Files/y_proba.csv\").to_numpy().transpose()[0]\n",
    "    print (y_test)\n",
    "    print (y_proba)\n",
    "    Analyze_Prediction(y_test, y_proba, 'Test_Analyze_Prediction', '')\n",
    "    \n",
    "Test_Analyze_Prediction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49200a4f",
   "metadata": {},
   "source": [
    "# Five-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "536ee811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Five_Fold_Cross_Validation(data, model, filename, title):\n",
    "    print ()\n",
    "    print ('------------------------')\n",
    "    print ()\n",
    "    print (filename)\n",
    "    print ()\n",
    "    \n",
    "    target = 'HOSPITAL'\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    target_column = data.loc[:,target]\n",
    "    y_test = []\n",
    "    y_proba = []\n",
    "    y_pred = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for train_index, test_index in skf.split(data, target_column):\n",
    "        print ('K-fold iteration = ', iteration)\n",
    "        iteration += 1\n",
    "        \n",
    "#        print ('len(train_index) = ', len(train_index))\n",
    "#        print (train_index)\n",
    "#        print ('len(test_index) = ', len(test_index))\n",
    "#        print (test_index)\n",
    "        \n",
    "        train_fold = data.iloc[train_index]\n",
    "#        print ()\n",
    "#        print ('train_fold')\n",
    "#        display(train_fold)\n",
    "        \n",
    "        test_fold = data.iloc[test_index]\n",
    "#        print ()\n",
    "#        print ('test_fold')\n",
    "#        display(test_fold)\n",
    "#        print ('type(test_fold) = ', type(test_fold))\n",
    "        \n",
    "        \n",
    "        X_train_fold = train_fold.drop(columns=[target])\n",
    "        X_test_fold = test_fold.drop(columns=[target])\n",
    "        y_train_fold = train_fold[target].squeeze()        \n",
    "        y_test_fold = test_fold[target].squeeze()\n",
    "#        print ('type(y_test_fold) = ', type(y_test_fold))\n",
    "        \n",
    "#        print ()\n",
    "        model.fit(X_train_fold, y_train_fold.values.ravel())\n",
    "        y_proba_fold = model.predict_proba(X_test_fold)\n",
    "        y_proba_fold = [x[1] for x in y_proba_fold]\n",
    "        y_pred_fold = list(np.around(np.array(y_proba_fold),0))\n",
    "        \n",
    "        ###\n",
    "#        print ('X_train_fold')\n",
    "#        display(X_train_fold)\n",
    "#        print ('y_train_fold')\n",
    "#        display(y_train_fold)\n",
    "#        print ('y_train_fold.value_counts()')\n",
    "#        display(y_train_fold.value_counts())\n",
    "#        print ('y_proba_fold')\n",
    "#        print (y_proba_fold)\n",
    "#        ###\n",
    "#        \n",
    "        y_test = y_test + y_test_fold.to_list()\n",
    "        y_proba = y_proba + y_proba_fold\n",
    "#        print ('len(y_proba) = ', len(y_proba))\n",
    "        y_pred = y_pred + y_pred_fold\n",
    "\n",
    "    y_test = np.array(y_test)\n",
    "    y_proba = np.array(y_proba)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    pd.Series(y_test).to_csv(\"../../Big_Files/y_test.csv\", index=False)\n",
    "    pd.Series(y_proba).to_csv(\"../../Big_Files/y_proba.csv\", index=False)\n",
    "    \n",
    "    \n",
    "    Chart_and_Plots(y_test, y_proba, y_pred, filename + '_Test', title)\n",
    "    \n",
    "    \n",
    "    print ()\n",
    "    return 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae040db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFC_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52566066",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72178501",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Run_with_Hard_Features():\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "    data = Thin_to_Hard_Features(data)\n",
    "    write_filename_features = '_Hard'\n",
    "    data = Get_Dummies(data, target)\n",
    "    \n",
    "    y = data[target]\n",
    "    N = len(y)\n",
    "    n = len(y[y==1])\n",
    "    p = (N-n)/n\n",
    "    alpha_balanced = p/(p+1)\n",
    "    print ('p = ', p)\n",
    "    print ('alpha_balanced = ', alpha_balanced)    \n",
    "\n",
    "    filename = 'RFC_5_Fold' + write_filename_features\n",
    "    RFC_5_Fold(data, target, filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6e23c1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get_Data()\n",
      "data.shape:  (713566, 78)\n",
      "End Get_Data()\n",
      "\n",
      "Feature_Engineering_Cross_Two\n",
      "\n",
      "Thin_to_Hard_Features()\n",
      "data.shape:  (713566, 40)\n",
      "End Thin_to_Hard_Features()\n",
      "\n",
      "Get_Dummies\n",
      "\n",
      "p =  5.609785468153692\n",
      "alpha_balanced =  0.84870915934896\n",
      "\n",
      "------------------------\n",
      "\n",
      "RFC_5_Fold_Hard\n",
      "\n",
      "K-fold iteration =  0\n",
      "K-fold iteration =  1\n",
      "K-fold iteration =  2\n",
      "K-fold iteration =  3\n",
      "K-fold iteration =  4\n",
      "Analyze_Prediction()\n",
      "RFC_5_Fold_Hard_Test\n",
      "y_proba:  [0.21039748 0.21290835 0.11695099 ... 0.1222773  0.12225795 0.12225795]\n",
      "y_test:  [0 0 0 ... 0 0 0]\n",
      "RFC_5_Fold_Hard_Test  has  106  custom_cut intervals\n",
      "       Neg   Pos\n",
      "0     1000  2066\n",
      "1     1000  1100\n",
      "2     1307  1000\n",
      "3     1227  1000\n",
      "4     1318  1000\n",
      "5     1380  1000\n",
      "6     1431  1000\n",
      "7     1346  1000\n",
      "8     1322  1000\n",
      "9     1405  1000\n",
      "10    1574  1000\n",
      "11    1490  1000\n",
      "12    1634  1000\n",
      "13    1673  1000\n",
      "14    1758  1000\n",
      "15    1699  1000\n",
      "16    1642  1000\n",
      "17    1834  1000\n",
      "18    2077  1000\n",
      "19    2303  1000\n",
      "20    2120  1000\n",
      "21    2514  1000\n",
      "22    2648  1001\n",
      "23    3040  1000\n",
      "24    2743  1000\n",
      "25    2410  1000\n",
      "26    2621  1000\n",
      "27    2856  1000\n",
      "28    3110  1000\n",
      "29    3000  1000\n",
      "30    2395  1000\n",
      "31    2450  1000\n",
      "32    2759  1000\n",
      "33    3106  1000\n",
      "34    3419  1000\n",
      "35    3937  1000\n",
      "36    3855  1000\n",
      "37    3976  1000\n",
      "38    4211  1000\n",
      "39    4501  1000\n",
      "40    4531  1000\n",
      "41    4636  1000\n",
      "42    3935  1000\n",
      "43    3572  1000\n",
      "44    3561  1000\n",
      "45    3787  1000\n",
      "46    3471  1004\n",
      "47    3774  1000\n",
      "48    3822  1000\n",
      "49    3439  1000\n",
      "50    3609  1000\n",
      "51    3949  1000\n",
      "52    3991  1000\n",
      "53    4029  1000\n",
      "54    3982  1000\n",
      "55    4006  1000\n",
      "56    4409  1000\n",
      "57    4348  1000\n",
      "58    4776  1000\n",
      "59    4638  1000\n",
      "60    4874  1000\n",
      "61    4978  1000\n",
      "62    5348  1000\n",
      "63    4870  1000\n",
      "64    4880  1000\n",
      "65    5116  1000\n",
      "66    4926  1000\n",
      "67    5163  1000\n",
      "68    5517  1000\n",
      "69    5127  1000\n",
      "70    5538  1000\n",
      "71    5256  1000\n",
      "72    5776  1000\n",
      "73    5992  1000\n",
      "74    5610  1000\n",
      "75    5752  1000\n",
      "76    5631  1000\n",
      "77    6302  1000\n",
      "78    6196  1003\n",
      "79    5601  1000\n",
      "80    5221  1000\n",
      "81    5815  1000\n",
      "82    5457  1001\n",
      "83    5966  1000\n",
      "84    6347  1000\n",
      "85    7163  1000\n",
      "86    6834  1000\n",
      "87    7608  1000\n",
      "88    8171  1000\n",
      "89    8359  1000\n",
      "90    8724  1000\n",
      "91    8924  1001\n",
      "92    8903  1000\n",
      "93    9167  1000\n",
      "94   10159  1000\n",
      "95   10562  1000\n",
      "96   11819  1001\n",
      "97   11844  1000\n",
      "98   12359  1000\n",
      "99   12372  1000\n",
      "100  14405  1002\n",
      "101  15985  1000\n",
      "102  17022  1000\n",
      "103  20235  1000\n",
      "104  22833  1000\n",
      "105  26988  1000\n",
      "106  35559   777\n",
      "\n",
      "\n",
      "CPU times: user 1min 40s, sys: 4.89 s, total: 1min 45s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Run_with_Hard_Features()\n",
    "# CPU times: user 4h 45min 20s, sys: 7min 22s, total: 4h 52min 43s\n",
    "# Wall time: 4h 30min 47s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb852de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_2_11",
   "language": "python",
   "name": "tensorflow_2_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
