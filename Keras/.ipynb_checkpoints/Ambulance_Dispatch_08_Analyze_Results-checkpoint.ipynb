{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767154e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\tableofcontents\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea489d64",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa423799",
   "metadata": {},
   "source": [
    "- We will build models reflecting three levels of available data\n",
    "    - \"Easy\" is mostly data already available to the emergency dispatcher before the notification comes in, like month, day of week, hour, weather, urban/rural, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e2353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97e1d2b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7d47d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122b4fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install Packages\n",
      "Python version: 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:26:08) [Clang 14.0.6 ]\n",
      "NumPy version: 1.24.2\n",
      "SciPy version:  1.7.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bburkman/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.11.0\n",
      "Keras version:  2.11.0\n",
      "Pandas version:  1.5.3\n",
      "SciKit-Learn version: 1.2.2\n",
      "Imbalanced-Learn version: 0.10.1\n",
      "Finished Installing Packages\n"
     ]
    }
   ],
   "source": [
    "print ('Install Packages')\n",
    "\n",
    "import sys, copy, math, time, os\n",
    "\n",
    "print ('Python version: {}'.format(sys.version))\n",
    "\n",
    "#from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import scipy as sc\n",
    "print ('SciPy version:  {}'.format(sc.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print ('TensorFlow version:  {}'.format(tf.__version__))\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "from tensorflow import keras\n",
    "print ('Keras version:  {}'.format(keras.__version__))\n",
    "\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "#from keras.layers import IntegerLookup\n",
    "#from keras.layers import Normalization\n",
    "#from keras.layers import StringLookup\n",
    "#from keras.utils import get_custom_objects\n",
    "#from keras.utils import tf_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import pandas as pd\n",
    "print ('Pandas version:  {}'.format(pd.__version__))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "#    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Library for reading Microsoft Access files\n",
    "#import pandas_access as mdb\n",
    "\n",
    "import sklearn\n",
    "print ('SciKit-Learn version: {}'.format(sklearn.__version__))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import imblearn\n",
    "print ('Imbalanced-Learn version: {}'.format(imblearn.__version__))\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "#!pip install pydot\n",
    "\n",
    "# Set Randomness.  Copied from https://www.kaggle.com/code/abazdyrev/keras-nn-focal-loss-experiments\n",
    "import random\n",
    "#np.random.seed(42) # NumPy\n",
    "#random.seed(42) # Python\n",
    "#tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print ('Finished Installing Packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d83bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chart_and_Plots(y_test, y_proba, y_pred, filename, title):\n",
    "    print ('Charts_and_Plots() for ', filename)\n",
    "    \n",
    "    Analyze_Prediction(y_test, y_proba, filename, title)\n",
    "    \n",
    "    Plot_Prediction(y_test, y_proba, filename, title)\n",
    "    Plot_Prediction_Wide(y_test, y_proba, filename, title)\n",
    "#    print (\"type(y_proba): \", type(y_proba))\n",
    "    left = min(y_proba)\n",
    "    right = max(y_proba)\n",
    "#    print (left, right)\n",
    "    Plot_Prediction_Zoom(y_test, y_proba, filename, title, left, right)\n",
    "    Plot_Prediction_Zoom_Wide(y_test, y_proba, filename, title, left, right)\n",
    "    Plot_Prediction_Zoom_Wide_Right(y_test, y_proba, filename, title, left, right)\n",
    "    \n",
    "    \n",
    "\n",
    "    ROC(y_test, y_proba, [], filename)\n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename)\n",
    "    \n",
    "#    print ()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97848247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate_Model(y_test, y_proba, y_pred, center, filename):\n",
    "    print ('Evaluate_Model() for ', filename)\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred = [round(x) for x in y_proba]\n",
    "    y_pred = np.array(y_pred)\n",
    "#    print ('np.unique(y_proba) = ', np.unique(y_proba))\n",
    "#    print ('np.unique(y_pred) = ', np.unique(y_pred))\n",
    "    CM = confusion_matrix(y_test, y_pred)\n",
    "#    print(CM)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    f = open('./Analyze_Proba/ROC_AUC.csv', 'a')\n",
    "    f.write('%s,%f\\n' % (filename, auc_value))\n",
    "    f.close()\n",
    "    \n",
    "    CSV = [[filename, CM[0][0], CM[0][1], CM[1][0], CM[1][1], center, auc_value]]\n",
    "    np.savetxt('./Confusion_Matrices/' + filename + '.csv', \n",
    "        CSV,\n",
    "        delimiter =\", \", \n",
    "        fmt ='% s'\n",
    "              )\n",
    "#    print ()\n",
    "    CM = confusion_matrix(y_test, y_pred, normalize='all')\n",
    "#    print(CM)\n",
    "#    print ()\n",
    "\n",
    "#    y_pred = y_pred.ravel()\n",
    "#    y_test = tf.convert_to_tensor(y_test)\n",
    "#    y_pred = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "#    print ('%.3f & Precision \\cr ' %  Precision_Metric(y_test, y_pred).numpy())\n",
    "#    print ('%.3f & Recall \\cr ' %  Recall_Metric(y_test, y_pred).numpy())\n",
    "#    print ('%.3f & F1 \\cr ' %  F1_Metric(y_test, y_pred).numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082fee38",
   "metadata": {},
   "source": [
    "# Plots and Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf928217",
   "metadata": {},
   "source": [
    "## Plot Prediction\n",
    "\n",
    "How to insert a .pgf plot into a \\LaTeX document:\n",
    "\n",
    "\\begin{figure}\n",
    "    \\begin{center}\n",
    "        \\input{Plot.pgf}\n",
    "    \\end{center}\n",
    "    \\caption{A PGF histogram from \\texttt{matplotlib}.}\n",
    "\\end{figure}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3496ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction(y_test, y_proba, filename, title):\n",
    "    print ('Plot_Prediction() for ', filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 10\n",
    "    bins= [x/n for x in range (0, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "    \n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "    plt.xticks(\n",
    "        ticks = [0, 2.5, 5, 7.5, 10], \n",
    "        labels = ['0.0', '0.25', '0.5', '0.75', '1.0'],\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Data Set')\n",
    "    plt.savefig('./Images/' + filename + '_Pred.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + filename + '_Pred.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b634349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Zoom(y_test, y_proba, filename, title, left, right):\n",
    "    print ('Plot_Prediction_Zoom() for ', filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    B = B[A['HOSPITAL'] > left]\n",
    "    B = B[A['HOSPITAL'] < right]\n",
    "    A = A[A['HOSPITAL'] > left]\n",
    "    A = A[A['HOSPITAL'] < right]\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 10\n",
    "    bins= [left + (right-left)*x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "\n",
    "    ticks = [0, 5, 10]\n",
    "    num_prec = int(-(math.log10((right-left)/2)))+2\n",
    "    num_prec = max(num_prec,2)\n",
    "    \n",
    "    if num_prec==2:\n",
    "        labels = [\"{:.2f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    if num_prec==3:\n",
    "        labels = [\"{:.3f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    if num_prec==4:\n",
    "        labels = [\"{:.4f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    if num_prec>4:\n",
    "        labels = [\"{:.5f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    \n",
    "    \n",
    "#    labels = [str(round(left + (right-left) * t/10,3)) for t in ticks]\n",
    "    plt.xticks(\n",
    "        ticks = ticks, \n",
    "        labels = labels,\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Data Set')\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Zoom.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Zoom.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred_Zoom.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4131e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Zoom_Wide(y_test, y_proba, filename, title, left, right):\n",
    "    print ('Plot_Prediction_Zoom_Wide() for ', filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    B = B[A['HOSPITAL'] > left]\n",
    "    B = B[A['HOSPITAL'] < right]\n",
    "    A = A[A['HOSPITAL'] > left]\n",
    "    A = A[A['HOSPITAL'] < right]\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 20\n",
    "    bins= [left + (right-left)*x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(4.5,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "\n",
    "#    ticks = [0, 2.5, 5, 7.5, 10]\n",
    "    ticks = [0, 4, 8, 12, 16, 20]\n",
    "    num_prec = int(-(math.log10((right-left)/4)))+2\n",
    "    num_prec = max(num_prec,2)\n",
    "#    print (\"left, right, (right-left)/5, -(math.log10((right-left)/5)), num_prec\")\n",
    "#    print (left, right, (right-left)/5, -(math.log10((right-left)/5)), num_prec)\n",
    "    \n",
    "    if num_prec<3:\n",
    "        labels = [\"{:.2f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec==3:\n",
    "        labels = [\"{:.3f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec==4:\n",
    "        labels = [\"{:.4f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec>4:\n",
    "        labels = [\"{:.5f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "#    labels = [str(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    plt.xticks(\n",
    "        ticks = ticks, \n",
    "        labels = labels,\n",
    "        rotation=0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Data Set')\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Zoom_Wide.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Zoom_Wide.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred_Zoom_Wide.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e568ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Zoom_Wide_Right(y_test, y_proba, filename, title, left, right):\n",
    "    print ('Plot_Prediction_Zoom_Wide_Right() for ', filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "\n",
    "    left = (left + right)/2\n",
    "\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    B = B[A['HOSPITAL'] > left]\n",
    "    B = B[A['HOSPITAL'] < right]\n",
    "    A = A[A['HOSPITAL'] > left]\n",
    "    A = A[A['HOSPITAL'] < right]\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 20\n",
    "    bins= [left + (right-left)*x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(4.5,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "\n",
    "#    ticks = [0, 2.5, 5, 7.5, 10]\n",
    "    ticks = [0, 4, 8, 12, 16, 20]\n",
    "    num_prec = int(-(math.log10((right-left)/4)))+2\n",
    "    num_prec = max(num_prec,2)\n",
    "#    print (\"left, right, (right-left)/5, -(math.log10((right-left)/5)), num_prec\")\n",
    "#    print (left, right, (right-left)/5, -(math.log10((right-left)/5)), num_prec)\n",
    "    \n",
    "    if num_prec<3:\n",
    "        labels = [\"{:.2f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec==3:\n",
    "        labels = [\"{:.3f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec==4:\n",
    "        labels = [\"{:.4f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec>4:\n",
    "        labels = [\"{:.5f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "#    labels = [str(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    plt.xticks(\n",
    "        ticks = ticks, \n",
    "        labels = labels,\n",
    "        rotation=0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Data Set')\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Zoom_Wide_Right.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Zoom_Wide_Right.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred_Zoom_Wide.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9eda862",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot_Prediction_Wide() for  Test\n"
     ]
    }
   ],
   "source": [
    "def Plot_Prediction_Wide(y_test, y_proba, filename, title):\n",
    "    print ('Plot_Prediction_Wide() for ', filename)\n",
    "    \n",
    "#    print ('y_test = ', y_test)\n",
    "#    print ('y_proba = ',y_proba)\n",
    "\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    print (\"A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\")\n",
    "#    display(A)\n",
    "#    print (\"B = pd.DataFrame(y_test, columns=['HOSPITAL'])\")\n",
    "#    display(B)\n",
    "#    print (\"C = A[B['HOSPITAL']==0]\")\n",
    "#    display(C)\n",
    "#    print (\"D = A[B['HOSPITAL']==1]\")\n",
    "#    display(D)\n",
    "    n = 20\n",
    "#    bins= [x/n - 1/(2*n) for x in range (-1, n+3)]\n",
    "    bins= [x/n for x in range (-1, n+1)]\n",
    "#    print ('Bins = ', bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "#    print (\"E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=True)\")\n",
    "#    display(E)\n",
    "#    print (\"F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=True)\")\n",
    "#    display(F)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "#    print (\"G = E.value_counts(sort=False)\")\n",
    "#    display(G)\n",
    "#    print (\"H = F.value_counts(sort=False)\")\n",
    "#    display(H)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "#    print (\"G = G/len(y_proba)*100\")\n",
    "#    display(G)\n",
    "#    print (\"H = H/len(y_proba)*100\")\n",
    "#    display(H)\n",
    "\n",
    "    fig = plt.figure(figsize=(4.5,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "    ticks = [n/20*i for i in range (-1,22)]\n",
    "#    print ('ticks = ', ticks)\n",
    "    plt.xticks(\n",
    "        ticks = ticks,\n",
    "        labels = ['','0.0', '', '0.1', '', '0.2', '', '0.3', '', '0.4', '', '0.5', '', '0.6', '', '0.7', '', '0.8', '', '0.9', '', '1.0', ''],\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Data Set')\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Wide.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + filename + '_Pred_Wide.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred_Wide.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n",
    "\n",
    "def Test_Plot_Prediction_Wide():\n",
    "    \n",
    "    y_proba = (\n",
    "        [0.0]*5 + \n",
    "        [0.0]*0 + \n",
    "        [0.1]*6 + \n",
    "        [0.1]*1 + \n",
    "        [0.2]*7 + \n",
    "        [0.2]*2 + \n",
    "        [0.3]*6 + \n",
    "        [0.3]*1 + \n",
    "        [0.4]*8 + \n",
    "        [0.4]*2 + \n",
    "        [0.5]*9 + \n",
    "        [0.5]*2 + \n",
    "        [0.6]*8 + \n",
    "        [0.6]*2 + \n",
    "        [0.7]*6 + \n",
    "        [0.7]*3 + \n",
    "        [0.8]*5 + \n",
    "        [0.8]*3 + \n",
    "        [0.9]*3 + \n",
    "        [0.9]*2 + \n",
    "        [1.0]*0 + \n",
    "        [1.0]*2 \n",
    "    )\n",
    "    y_test = (\n",
    "        [0]*5 + \n",
    "        [1]*0 + \n",
    "        [0]*6 + \n",
    "        [1]*1 + \n",
    "        [0]*7 + \n",
    "        [1]*2 + \n",
    "        [0]*6 + \n",
    "        [1]*1 + \n",
    "        [0]*8 + \n",
    "        [1]*2 + \n",
    "        [0]*9 + \n",
    "        [1]*2 + \n",
    "        [0]*8 + \n",
    "        [1]*2 + \n",
    "        [0]*6 + \n",
    "        [1]*3 + \n",
    "        [0]*5 + \n",
    "        [1]*3 + \n",
    "        [0]*3 + \n",
    "        [1]*2 + \n",
    "        [0]*0 + \n",
    "        [1]*2 \n",
    "    )\n",
    "    Plot_Prediction_Wide(y_test, y_proba, 'Test', 'Test')\n",
    "    \n",
    "Test_Plot_Prediction_Wide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e84dc",
   "metadata": {},
   "source": [
    "## Switching between FP/TP and Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee52a47",
   "metadata": {},
   "source": [
    "$$\\text{Precision} = \\frac{TP}{FP+TP}$$\n",
    "\n",
    "$$\\frac{1}{\\text{Precision}} = \\frac{FP+TP}{TP} = \\frac{FP}{TP} + \\frac{TP}{TP} = \\frac{FP}{TP} +  1$$\n",
    "\n",
    "$$\\frac{FP}{TP} + 1 = \\frac{1}{\\text{Precision}}$$\n",
    "\n",
    "$$\\frac{FP}{TP} = \\frac{1}{\\text{Precision}} - 1 = \\frac{1}{\\text{Precision}} - \\frac{\\text{Precision}}{\\text{Precision}}  = \\frac{1 - \\text{Precision}}{\\text{Precision}}$$\n",
    "\n",
    "- In a previous version I had wanted $FP/TP$ to equal either 2.0, 1.0, or 0.5, indicating that we were willing to send 2 unnecessary ambulances for each necessary one, etc.  \n",
    "    - $FP/TP = 2.0$ corresponds to precision = 1/3\n",
    "    - $FP/TP = 1.0$ corresponds to precision = 1/2\n",
    "    - $FP/TP = 0.5$ corresponds to precision = 2/3\n",
    "\n",
    "- Neg/Pos corresponds to marginal precision similarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26ec6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value_Counts_y_proba() for  Test\n"
     ]
    }
   ],
   "source": [
    "def Value_Counts_y_proba(y_proba, filename):\n",
    "    print ('Value_Counts_y_proba() for ', filename)\n",
    "#    print (type(y_proba))\n",
    "    Y_proba = pd.Series(y_proba)\n",
    "    A = Y_proba.value_counts().reset_index(drop=True)\n",
    "    n = len(y_proba)\n",
    "    nA = len(A)\n",
    "#    display(Y_proba)\n",
    "#    display(A)\n",
    "    B = A.cumsum()\n",
    "#    display(B)\n",
    "#    print (B[10])\n",
    "#    print ()\n",
    "    cutoff_95 = B.sub(0.95*n).abs().idxmin() + 1\n",
    "    cutoff_90 = B.sub(0.90*n).abs().idxmin() + 1\n",
    "    cutoff_80 = B.sub(0.80*n).abs().idxmin() + 1\n",
    "    m = Y_proba.min()\n",
    "    M = Y_proba.max()\n",
    "#    print (n, nA)\n",
    "#    print (cutoff_95)\n",
    "#    print ()\n",
    "\n",
    "    n100 = min(100, len(B)-1)\n",
    "    n200 = min(200, len(B)-1)\n",
    "#    print ('n200 = ', n200)\n",
    "    f = open('./Analyze_Proba/Value_Counts_y_proba.csv', 'a')\n",
    "    f.write('%s,%d,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%0.4f,%0.4f\\n' % (\n",
    "        filename, n, nA, nA/n, \n",
    "        cutoff_95, cutoff_95/n,\n",
    "        cutoff_90, cutoff_90/n,\n",
    "        cutoff_80, cutoff_80/n,\n",
    "        B[10], B[10]/n,\n",
    "        B[20], B[20]/n,\n",
    "        B[n100], B[n100]/n,\n",
    "        B[n200], B[n200]/n,\n",
    "        m,M,\n",
    "    ))\n",
    "    f.close()\n",
    "    \n",
    "    H = Y_proba.value_counts().head(100)\n",
    "    Filename = './Analyze_Proba/' + filename + '_Value_Counts_head_100.csv'\n",
    "    H.to_csv(Filename)\n",
    "\n",
    "    return 0\n",
    "    \n",
    "def Create_Files_for_Value_Counts_y_proba():\n",
    "    print ('Create_Files_for_Value_Counts_y_Proba')\n",
    "    f = open('./Analyze_Proba/Value_Counts_y_proba.csv', 'w')\n",
    "    f.write(\"Filename,n,nUnique,nUnique/n,95%,95%/n,90%,90%/n,80%,80%/n,B[10],B[10]/n,B[20],B[20]/n,B[100],B[100]/n,B[200],B[200],min,max,\\n\")\n",
    "    f.close()\n",
    "    \n",
    "#Create_Files_for_Value_Counts_y_proba()\n",
    "\n",
    "def Create_Files_for_Lengths_of_fpr_tpr():\n",
    "    print ('Create_Files_for_Lengths_of_fpr_tpr()')\n",
    "    f = open('./Analyze_Proba/Lengths_of_fpr_tpr.csv', 'w')\n",
    "    f.write(\"Filename,len(y_proba),nUnique(y_proba),len(fpr),nUnique(fpr),len(tpr),nUnique(tpr),len(fpr tpr),nUnique(fpr tpr)\\n\")\n",
    "    f.close()\n",
    "    \n",
    "def Create_Files_for_ROC_AUC():\n",
    "    print ('Create_Files_for_ROC_AUC()')\n",
    "    f = open('./Analyze_Proba/ROC_AUC.csv', 'w')\n",
    "    f.write(\"Filename,ROC_AUC\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "def Test_Value_Counts_y_proba():\n",
    "    A = [5]*50 + [6]*20 + [i for i in range (10,40)]*2 + [i for i in range (100,400)]\n",
    "    Value_Counts_y_proba(A, 'Test')\n",
    "\n",
    "Test_Value_Counts_y_proba()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "753c2dfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef Analyze_Prediction(y_test, y_proba, filename, title):\\n    print (\\'Analyze_Prediction()\\')\\n    print (filename)\\n    \\n#    Value_Counts_y_proba(y_proba, filename)\\n    \\n#    print (y_test)\\n#    print (y_proba)\\n#    return 0\\n#    y_test = y_test.numpy()\\n    A = pd.DataFrame(y_proba, columns=[\\'HOSPITAL\\'])\\n    B = pd.DataFrame(y_test, columns=[\\'HOSPITAL\\'])\\n    B = B.reset_index(drop=True)\\n    C = A[B[\\'HOSPITAL\\']==0]\\n    D = A[B[\\'HOSPITAL\\']==1]\\n#    print (\\'print (len(A), len(C), len(D), len(C) + len(D))\\')\\n#    print (len(A), len(C), len(D), len(C) + len(D))\\n\\n    N = len(C)\\n    P = len(D)\\n    \\n    ##### 10 bins\\n    n = 10\\n    bins= [x/n for x in range (-1, n+1)]\\n#    print (bins)\\n    E = pd.cut(C[\\'HOSPITAL\\'], bins=bins, include_lowest=True)\\n    F = pd.cut(D[\\'HOSPITAL\\'], bins=bins, include_lowest=True)\\n    \\n    G = E.value_counts(sort=False)\\n    H = F.value_counts(sort=False)\\n\\n    Analyze = pd.DataFrame()\\n    Analyze[\\'Neg\\'] = G\\n    Analyze[\\'Pos\\'] = H\\n    Analyze[\\'p\\'] = bins[1:]\\n#    Analyze[\\'Neg/Pos\\'] = Analyze[\\'Neg\\']/Analyze[\\'Pos\\']\\n    Analyze[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\'] = Analyze[\\'Pos\\']/(Analyze[\\'Pos\\'] + Analyze[\\'Neg\\'])\\n    Analyze[\\'TN\\'] = Analyze[\\'Neg\\'].cumsum()\\n    Analyze[\\'FP\\'] = N - Analyze[\\'TN\\']\\n    Analyze[\\'FN\\'] = Analyze[\\'Pos\\'].cumsum()\\n    Analyze[\\'TP\\'] = P - Analyze[\\'FN\\']\\n#    Analyze[\\'FP/TP\\'] = Analyze[\\'FP\\']/Analyze[\\'TP\\']\\n#    Analyze[\\'FP+TP\\'] = Analyze[\\'FP\\'] + Analyze[\\'TP\\']\\n    Analyze[\\'Prec\\'] = Analyze[\\'TP\\']/(Analyze[\\'FP\\'] + Analyze[\\'TP\\'])\\n    Analyze[\\'Rec\\'] =  Analyze[\\'TP\\']/(Analyze[\\'FN\\'] + Analyze[\\'TP\\'])\\n    Analyze[\\'$\\\\frac{\\\\text{FP}}{\\\\text{P}}$\\'] =  Analyze[\\'FP\\']/(Analyze[\\'FN\\'] + Analyze[\\'TP\\'])\\n    \\n    Analyze[\\'Neg\\']=Analyze[\\'Neg\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'Pos\\']=Analyze[\\'Pos\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'TN\\']=Analyze[\\'TN\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'FP\\']=Analyze[\\'FP\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'FN\\']=Analyze[\\'FN\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'TP\\']=Analyze[\\'TP\\'].apply(\\'{:,}\\'.format)\\n#    Analyze[\\'FP+TP\\']=Analyze[\\'FP+TP\\'].apply(\\'{:,}\\'.format)\\n    \\n#    Analyze[\\'Neg/Pos\\']=Analyze[\\'Neg/Pos\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\']=Analyze[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\'].apply(\\'{:.2f}\\'.format)\\n#    Analyze[\\'FP/TP\\']=Analyze[\\'FP/TP\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'Prec\\']=Analyze[\\'Prec\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'Rec\\']=Analyze[\\'Rec\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'$\\\\frac{\\\\text{FP}}{\\\\text{P}}$\\']=Analyze[\\'$\\\\frac{\\\\text{FP}}{\\\\text{P}}$\\'].apply(\\'{:.2f}\\'.format)\\n        \\n#    Analyze.index.name = \\'p\\'\\n    Analyze.set_index(\\'p\\', inplace=True)\\n#    print (\\'./Analyze_Proba/\\' + filename + \\'_10.tex\\')\\n#    print (len(y_proba))\\n#    display(Analyze)\\n    Analyze.to_csv(\\'./Analyze_Proba/\\' + filename + \\'_10.csv\\', index=True)\\n    Analyze.to_latex(\\n        \\'./Analyze_Proba/\\' + filename + \\'_10.tex\\', \\n        index=True, \\n        float_format=\"{:.2f}\".format, \\n        column_format=\\'rrrcrrrrrrrrrrr\\',\\n        escape=False\\n    )\\n\\n\\n\\n    ##### 20 bins\\n    n = 20\\n    bins= [x/n for x in range (-1, n+1)]\\n#    print (bins)\\n    E = pd.cut(C[\\'HOSPITAL\\'], bins=bins, include_lowest=True)\\n    F = pd.cut(D[\\'HOSPITAL\\'], bins=bins, include_lowest=True)\\n    \\n    G = E.value_counts(sort=False)\\n    H = F.value_counts(sort=False)\\n\\n    Analyze = pd.DataFrame()\\n    Analyze[\\'Neg\\'] = G\\n    Analyze[\\'Pos\\'] = H\\n    Analyze[\\'p\\'] = bins[1:]\\n#    Analyze[\\'Neg/Pos\\'] = Analyze[\\'Neg\\']/Analyze[\\'Pos\\']\\n    Analyze[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\'] = Analyze[\\'Pos\\']/(Analyze[\\'Pos\\'] + Analyze[\\'Neg\\'])\\n    Analyze[\\'TN\\'] = Analyze[\\'Neg\\'].cumsum()\\n    Analyze[\\'FP\\'] = N - Analyze[\\'TN\\']\\n    Analyze[\\'FN\\'] = Analyze[\\'Pos\\'].cumsum()\\n    Analyze[\\'TP\\'] = P - Analyze[\\'FN\\']\\n#    Analyze[\\'FP/TP\\'] = Analyze[\\'FP\\']/Analyze[\\'TP\\']\\n#    Analyze[\\'FP+TP\\'] = Analyze[\\'FP\\'] + Analyze[\\'TP\\']\\n    Analyze[\\'Prec\\'] = Analyze[\\'TP\\']/(Analyze[\\'FP\\'] + Analyze[\\'TP\\'])\\n    Analyze[\\'Rec\\'] =  Analyze[\\'TP\\']/(Analyze[\\'FN\\'] + Analyze[\\'TP\\'])\\n    Analyze[\\'$\\\\frac{\\\\text{FP}}{\\\\text{P}}$\\'] =  Analyze[\\'FP\\']/(Analyze[\\'FN\\'] + Analyze[\\'TP\\'])\\n    \\n    Analyze[\\'Neg\\']=Analyze[\\'Neg\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'Pos\\']=Analyze[\\'Pos\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'TN\\']=Analyze[\\'TN\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'FP\\']=Analyze[\\'FP\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'FN\\']=Analyze[\\'FN\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'TP\\']=Analyze[\\'TP\\'].apply(\\'{:,}\\'.format)\\n#    Analyze[\\'FP+TP\\']=Analyze[\\'FP+TP\\'].apply(\\'{:,}\\'.format)\\n    \\n#    Analyze[\\'Neg/Pos\\']=Analyze[\\'Neg/Pos\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\']=Analyze[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\'].apply(\\'{:.2f}\\'.format)\\n#    Analyze[\\'FP/TP\\']=Analyze[\\'FP/TP\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'Prec\\']=Analyze[\\'Prec\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'Rec\\']=Analyze[\\'Rec\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'$\\\\frac{\\\\text{FP}}{\\\\text{P}}$\\']=Analyze[\\'$\\\\frac{\\\\text{FP}}{\\\\text{P}}$\\'].apply(\\'{:.2f}\\'.format)\\n        \\n#    Analyze.index.name = \\'p\\'\\n    Analyze.set_index(\\'p\\', inplace=True)\\n#    print (\\'./Analyze_Proba/\\' + filename + \\'_10.tex\\')\\n#    print (len(y_proba))\\n#    display(Analyze)\\n    Analyze.to_csv(\\'./Analyze_Proba/\\' + filename + \\'_20.csv\\', index=True)\\n    Analyze.to_latex(\\n        \\'./Analyze_Proba/\\' + filename + \\'_20.tex\\', \\n        index=True, \\n        float_format=\"{:.2f}\".format, \\n        column_format=\\'rrrcrrrrrrrrrrr\\',\\n        escape=False\\n    )\\n\\n\\n\\n\\n    ##### 100 bins\\n    n = 100\\n    bins= [x/n for x in range (-1, n+1)]\\n#    print (bins)\\n    E = pd.cut(C[\\'HOSPITAL\\'], bins=bins, include_lowest=True)\\n    F = pd.cut(D[\\'HOSPITAL\\'], bins=bins, include_lowest=True)\\n    \\n    G = E.value_counts(sort=False)\\n    H = F.value_counts(sort=False)\\n\\n    Analyze = pd.DataFrame()\\n    Analyze[\\'Neg\\'] = G\\n    Analyze[\\'Pos\\'] = H\\n    Analyze[\\'p\\'] = bins[1:]\\n#    Analyze[\\'Neg/Pos\\'] = Analyze[\\'Neg\\']/Analyze[\\'Pos\\']\\n    Analyze[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\'] = Analyze[\\'Pos\\']/(Analyze[\\'Pos\\'] + Analyze[\\'Neg\\'])\\n    Analyze[\\'TN\\'] = Analyze[\\'Neg\\'].cumsum()\\n    Analyze[\\'FP\\'] = N - Analyze[\\'TN\\']\\n    Analyze[\\'FN\\'] = Analyze[\\'Pos\\'].cumsum()\\n    Analyze[\\'TP\\'] = P - Analyze[\\'FN\\']\\n#    Analyze[\\'FP/TP\\'] = Analyze[\\'FP\\']/Analyze[\\'TP\\']\\n#    Analyze[\\'FP+TP\\'] = Analyze[\\'FP\\'] + Analyze[\\'TP\\']\\n    Analyze[\\'Prec\\'] = Analyze[\\'TP\\']/(Analyze[\\'FP\\'] + Analyze[\\'TP\\'])\\n    Analyze[\\'Rec\\'] =  Analyze[\\'TP\\']/(Analyze[\\'FN\\'] + Analyze[\\'TP\\'])\\n    Analyze[\\'$\\\\frac{\\\\text{FP}}{\\\\text{P}}$\\'] =  Analyze[\\'FP\\']/(Analyze[\\'FN\\'] + Analyze[\\'TP\\'])\\n    \\n    A = Analyze.copy(deep=True)\\n    \\n    Analyze[\\'Neg\\']=Analyze[\\'Neg\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'Pos\\']=Analyze[\\'Pos\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'TN\\']=Analyze[\\'TN\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'FP\\']=Analyze[\\'FP\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'FN\\']=Analyze[\\'FN\\'].apply(\\'{:,}\\'.format)\\n    Analyze[\\'TP\\']=Analyze[\\'TP\\'].apply(\\'{:,}\\'.format)\\n#    Analyze[\\'FP+TP\\']=Analyze[\\'FP+TP\\'].apply(\\'{:,}\\'.format)\\n    \\n#    Analyze[\\'Neg/Pos\\']=Analyze[\\'Neg/Pos\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\']=Analyze[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\'].apply(\\'{:.2f}\\'.format)\\n#    Analyze[\\'FP/TP\\']=Analyze[\\'FP/TP\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'Prec\\']=Analyze[\\'Prec\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'Rec\\']=Analyze[\\'Rec\\'].apply(\\'{:.2f}\\'.format)\\n    Analyze[\\'$\\\\frac{\\\\text{FP}}{\\\\text{P}}$\\']=Analyze[\\'$\\\\frac{\\\\text{FP}}{\\\\text{P}}$\\'].apply(\\'{:.2f}\\'.format)\\n        \\n#    Analyze.index.name = \\'p\\'\\n    Analyze.set_index(\\'p\\', inplace=True)\\n#    print (\\'./Analyze_Proba/\\' + filename + \\'_10.tex\\')\\n#    print (len(y_proba))\\n#    display(Analyze)\\n    Analyze.to_csv(\\'./Analyze_Proba/\\' + filename + \\'_100.csv\\', index=True)\\n    Analyze.to_latex(\\n        \\'./Analyze_Proba/\\' + filename + \\'_100.tex\\', \\n        index=True, \\n        float_format=\"{:.2f}\".format, \\n        column_format=\\'rrrcrrrrrrrrrrr\\',\\n        escape=False\\n    )\\n\\n\\n    \\n    # Append CSV files with results from multiple models\\n    A.set_index(\\'p\\', inplace=True)\\n    A.insert(0, \\'Filename\\', filename)\\n    \\n    # Remove rows with negligible number of samples\\n    A = A[A[\\'Neg\\'] >= 20]\\n    A = A[A[\\'Pos\\'] >= 20]\\n    \\n    \\n    A_closest = A.iloc[(A[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\'] - 0.333).abs().argsort()[:1]].head(1)\\n    A_closest.to_csv(\\'./Analyze_Proba/mProb_0_333.csv\\', mode=\\'a\\', \\n        index=True, header=False, float_format=\"{:.2f}\".format)\\n    A_closest[\\'Filename\\'] = A_closest[\\'Filename\\'].str.replace(\\'_\\',\\'\\\\_\\')\\n    A_closest.to_csv(\\'./Analyze_Proba/mProb_0_333.tex\\', \\n                     mode=\\'a\\', sep=\\'&\\', lineterminator=\\'\\\\cr\\n\\',\\n                    index=True, header=False, float_format=\"{:.2f}\".format)\\n    \\n    A_closest = A.iloc[(A[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\'] - 0.5).abs().argsort()[:1]].head(1)\\n    A_closest.to_csv(\\'./Analyze_Proba/mProb_0_5.csv\\', mode=\\'a\\', index=True, header=False)\\n    \\n    A_closest[\\'Filename\\'] = A_closest[\\'Filename\\'].str.replace(\\'_\\',\\'\\\\_\\')\\n    A_closest.to_csv(\\'./Analyze_Proba/mProb_0_5.tex\\', \\n                     mode=\\'a\\', sep=\\'&\\', lineterminator=\\'\\\\cr\\n\\',\\n                    index=True, header=False, float_format=\"{:.2f}\".format)\\n    \\n    A_closest = A.iloc[(A[\\'$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$\\'] - 0.667).abs().argsort()[:1]].head(1)\\n    A_closest.to_csv(\\'./Analyze_Proba/mProb_0_667.csv\\', mode=\\'a\\', index=True, header=False)\\n    \\n    A_closest[\\'Filename\\'] = A_closest[\\'Filename\\'].str.replace(\\'_\\',\\'\\\\_\\')\\n    A_closest.to_csv(\\'./Analyze_Proba/mProb_0_667.tex\\', \\n                     mode=\\'a\\', sep=\\'&\\', lineterminator=\\'\\\\cr\\n\\',\\n                    index=True, header=False, float_format=\"{:.2f}\".format)\\n    \\n    A_closest = A.iloc[(A[\\'Prec\\'] - 0.333).abs().argsort()[:1]].head(1)\\n    A_closest.to_csv(\\'./Analyze_Proba/Prec_0_333.csv\\', mode=\\'a\\', index=True, header=False)\\n    \\n    A_closest[\\'Filename\\'] = A_closest[\\'Filename\\'].str.replace(\\'_\\',\\'\\\\_\\')\\n    A_closest.to_csv(\\'./Analyze_Proba/Prec_0_333.tex\\', \\n                     mode=\\'a\\', sep=\\'&\\', lineterminator=\\'\\\\cr\\n\\',\\n                    index=True, header=False, float_format=\"{:.2f}\".format)\\n    \\n    A_closest = A.iloc[(A[\\'Prec\\'] - 0.5).abs().argsort()[:1]].head(1)\\n    A_closest.to_csv(\\'./Analyze_Proba/Prec_0_5.csv\\', mode=\\'a\\', index=True, header=False)\\n    \\n    A_closest[\\'Filename\\'] = A_closest[\\'Filename\\'].str.replace(\\'_\\',\\'\\\\_\\')\\n    A_closest.to_csv(\\'./Analyze_Proba/Prec_0_5.tex\\', \\n                     mode=\\'a\\', sep=\\'&\\', lineterminator=\\'\\\\cr\\n\\',\\n                    index=True, header=False, float_format=\"{:.2f}\".format)\\n    \\n    A_closest = A.iloc[(A[\\'Prec\\'] - 0.667).abs().argsort()[:1]].head(1)\\n    A_closest.to_csv(\\'./Analyze_Proba/Prec_0_667.csv\\', mode=\\'a\\', index=True, header=False)\\n    \\n    A_closest[\\'Filename\\'] = A_closest[\\'Filename\\'].str.replace(\\'_\\',\\'\\\\_\\')\\n    A_closest.to_csv(\\'./Analyze_Proba/Prec_0_667.tex\\', \\n                     mode=\\'a\\', sep=\\'&\\', lineterminator=\\'\\\\cr\\n\\',\\n                    index=True, header=False, float_format=\"{:.2f}\".format)\\n    \\n    A_closest = A.iloc[(A[\\'$\\\\frac{\\\\text{FP}}{\\\\text{P}}$\\'] - 0.05).abs().argsort()[:1]].head(1)\\n    A_closest.to_csv(\\'./Analyze_Proba/FP_P_0_05.csv\\', mode=\\'a\\', index=True, header=False)\\n    \\n    A_closest[\\'Filename\\'] = A_closest[\\'Filename\\'].str.replace(\\'_\\',\\'\\\\_\\')\\n    A_closest.to_csv(\\'./Analyze_Proba/FP_P_0_05.tex\\', \\n                     mode=\\'a\\', sep=\\'&\\', lineterminator=\\'\\\\cr\\n\\',\\n                    index=True, header=False, float_format=\"{:.2f}\".format)\\n    \\n    \\ndef Create_Files_for_Analyze_Prediction():\\n    f = open(\\'./Analyze_Proba/mPrec_0_5.csv\\', \\'w\\')\\n    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\\n    f.close()\\n    g = open(\\'./Analyze_Proba/mPrec_0_5.tex\\', \\'w\\')\\n    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\\n    g.close()\\n    \\n    f = open(\\'./Analyze_Proba/mPrec_0_667.csv\\', \\'w\\')\\n    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\\n    f.close()\\n    g = open(\\'./Analyze_Proba/mPrec_0_667.tex\\', \\'w\\')\\n    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\\n    g.close()\\n    \\n    f = open(\\'./Analyze_Proba/mPrec_0_333.csv\\', \\'w\\')\\n    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\\n    f.close()\\n    g = open(\\'./Analyze_Proba/mPrec_0_333.tex\\', \\'w\\')\\n    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\\n    g.close()\\n    \\n    f = open(\\'./Analyze_Proba/Prec_0_5.csv\\', \\'w\\')\\n    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\\n    f.close()\\n    g = open(\\'./Analyze_Proba/Prec_0_5.tex\\', \\'w\\')\\n    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\\n    g.close()\\n    \\n    f = open(\\'./Analyze_Proba/Prec_0_667.csv\\', \\'w\\')\\n    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\\n    f.close()\\n    g = open(\\'./Analyze_Proba/Prec_0_667.tex\\', \\'w\\')\\n    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\\n    g.close()\\n    \\n    f = open(\\'./Analyze_Proba/Prec_0_333.csv\\', \\'w\\')\\n    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\\n    f.close()\\n    g = open(\\'./Analyze_Proba/Prec_0_333.tex\\', \\'w\\')\\n    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\\n    g.close()\\n    \\n    f = open(\\'./Analyze_Proba/p_hat_0_05.csv\\', \\'w\\')\\n    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\\n    f.close()\\n    g = open(\\'./Analyze_Proba/p_hat_0_05.tex\\', \\'w\\')\\n    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\\n    g.close()\\n    \\n    f = open(\\'./Analyze_Proba/p_hat_0_10.csv\\', \\'w\\')\\n    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\\n    f.close()\\n    g = open(\\'./Analyze_Proba/p_hat_0_10.tex\\', \\'w\\')\\n    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\\n    g.close()\\n    \\n    f = open(\\'./Analyze_Proba/p_hat_0_15.csv\\', \\'w\\')\\n    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\\n    f.close()\\n    g = open(\\'./Analyze_Proba/p_hat_0_15.tex\\', \\'w\\')\\n    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\\n    g.close()\\n    \\n    f = open(\\'./Analyze_Proba/FP_P_0_05.csv\\', \\'w\\')\\n    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\\n    f.close()\\n    g = open(\\'./Analyze_Proba/FP_P_0_05.tex\\', \\'w\\')\\n    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\\n    g.close()\\n\\n\\n\\n#Create_Files_for_Analyze_Prediction()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def Analyze_Prediction(y_test, y_proba, filename, title):\n",
    "    print ('Analyze_Prediction()')\n",
    "    print (filename)\n",
    "    \n",
    "#    Value_Counts_y_proba(y_proba, filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    print ('print (len(A), len(C), len(D), len(C) + len(D))')\n",
    "#    print (len(A), len(C), len(D), len(C) + len(D))\n",
    "\n",
    "    N = len(C)\n",
    "    P = len(D)\n",
    "    \n",
    "    ##### 10 bins\n",
    "    n = 10\n",
    "    bins= [x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    Analyze = pd.DataFrame()\n",
    "    Analyze['Neg'] = G\n",
    "    Analyze['Pos'] = H\n",
    "    Analyze['p'] = bins[1:]\n",
    "#    Analyze['Neg/Pos'] = Analyze['Neg']/Analyze['Pos']\n",
    "    Analyze['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] = Analyze['Pos']/(Analyze['Pos'] + Analyze['Neg'])\n",
    "    Analyze['TN'] = Analyze['Neg'].cumsum()\n",
    "    Analyze['FP'] = N - Analyze['TN']\n",
    "    Analyze['FN'] = Analyze['Pos'].cumsum()\n",
    "    Analyze['TP'] = P - Analyze['FN']\n",
    "#    Analyze['FP/TP'] = Analyze['FP']/Analyze['TP']\n",
    "#    Analyze['FP+TP'] = Analyze['FP'] + Analyze['TP']\n",
    "    Analyze['Prec'] = Analyze['TP']/(Analyze['FP'] + Analyze['TP'])\n",
    "    Analyze['Rec'] =  Analyze['TP']/(Analyze['FN'] + Analyze['TP'])\n",
    "    Analyze['$\\\\frac{\\\\text{FP}}{\\\\text{P}}$'] =  Analyze['FP']/(Analyze['FN'] + Analyze['TP'])\n",
    "    \n",
    "    Analyze['Neg']=Analyze['Neg'].apply('{:,}'.format)\n",
    "    Analyze['Pos']=Analyze['Pos'].apply('{:,}'.format)\n",
    "    Analyze['TN']=Analyze['TN'].apply('{:,}'.format)\n",
    "    Analyze['FP']=Analyze['FP'].apply('{:,}'.format)\n",
    "    Analyze['FN']=Analyze['FN'].apply('{:,}'.format)\n",
    "    Analyze['TP']=Analyze['TP'].apply('{:,}'.format)\n",
    "#    Analyze['FP+TP']=Analyze['FP+TP'].apply('{:,}'.format)\n",
    "    \n",
    "#    Analyze['Neg/Pos']=Analyze['Neg/Pos'].apply('{:.2f}'.format)\n",
    "    Analyze['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$']=Analyze['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'].apply('{:.2f}'.format)\n",
    "#    Analyze['FP/TP']=Analyze['FP/TP'].apply('{:.2f}'.format)\n",
    "    Analyze['Prec']=Analyze['Prec'].apply('{:.2f}'.format)\n",
    "    Analyze['Rec']=Analyze['Rec'].apply('{:.2f}'.format)\n",
    "    Analyze['$\\\\frac{\\\\text{FP}}{\\\\text{P}}$']=Analyze['$\\\\frac{\\\\text{FP}}{\\\\text{P}}$'].apply('{:.2f}'.format)\n",
    "        \n",
    "#    Analyze.index.name = 'p'\n",
    "    Analyze.set_index('p', inplace=True)\n",
    "#    print ('./Analyze_Proba/' + filename + '_10.tex')\n",
    "#    print (len(y_proba))\n",
    "#    display(Analyze)\n",
    "    Analyze.to_csv('./Analyze_Proba/' + filename + '_10.csv', index=True)\n",
    "    Analyze.to_latex(\n",
    "        './Analyze_Proba/' + filename + '_10.tex', \n",
    "        index=True, \n",
    "        float_format=\"{:.2f}\".format, \n",
    "        column_format='rrrcrrrrrrrrrrr',\n",
    "        escape=False\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    ##### 20 bins\n",
    "    n = 20\n",
    "    bins= [x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    Analyze = pd.DataFrame()\n",
    "    Analyze['Neg'] = G\n",
    "    Analyze['Pos'] = H\n",
    "    Analyze['p'] = bins[1:]\n",
    "#    Analyze['Neg/Pos'] = Analyze['Neg']/Analyze['Pos']\n",
    "    Analyze['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] = Analyze['Pos']/(Analyze['Pos'] + Analyze['Neg'])\n",
    "    Analyze['TN'] = Analyze['Neg'].cumsum()\n",
    "    Analyze['FP'] = N - Analyze['TN']\n",
    "    Analyze['FN'] = Analyze['Pos'].cumsum()\n",
    "    Analyze['TP'] = P - Analyze['FN']\n",
    "#    Analyze['FP/TP'] = Analyze['FP']/Analyze['TP']\n",
    "#    Analyze['FP+TP'] = Analyze['FP'] + Analyze['TP']\n",
    "    Analyze['Prec'] = Analyze['TP']/(Analyze['FP'] + Analyze['TP'])\n",
    "    Analyze['Rec'] =  Analyze['TP']/(Analyze['FN'] + Analyze['TP'])\n",
    "    Analyze['$\\\\frac{\\\\text{FP}}{\\\\text{P}}$'] =  Analyze['FP']/(Analyze['FN'] + Analyze['TP'])\n",
    "    \n",
    "    Analyze['Neg']=Analyze['Neg'].apply('{:,}'.format)\n",
    "    Analyze['Pos']=Analyze['Pos'].apply('{:,}'.format)\n",
    "    Analyze['TN']=Analyze['TN'].apply('{:,}'.format)\n",
    "    Analyze['FP']=Analyze['FP'].apply('{:,}'.format)\n",
    "    Analyze['FN']=Analyze['FN'].apply('{:,}'.format)\n",
    "    Analyze['TP']=Analyze['TP'].apply('{:,}'.format)\n",
    "#    Analyze['FP+TP']=Analyze['FP+TP'].apply('{:,}'.format)\n",
    "    \n",
    "#    Analyze['Neg/Pos']=Analyze['Neg/Pos'].apply('{:.2f}'.format)\n",
    "    Analyze['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$']=Analyze['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'].apply('{:.2f}'.format)\n",
    "#    Analyze['FP/TP']=Analyze['FP/TP'].apply('{:.2f}'.format)\n",
    "    Analyze['Prec']=Analyze['Prec'].apply('{:.2f}'.format)\n",
    "    Analyze['Rec']=Analyze['Rec'].apply('{:.2f}'.format)\n",
    "    Analyze['$\\\\frac{\\\\text{FP}}{\\\\text{P}}$']=Analyze['$\\\\frac{\\\\text{FP}}{\\\\text{P}}$'].apply('{:.2f}'.format)\n",
    "        \n",
    "#    Analyze.index.name = 'p'\n",
    "    Analyze.set_index('p', inplace=True)\n",
    "#    print ('./Analyze_Proba/' + filename + '_10.tex')\n",
    "#    print (len(y_proba))\n",
    "#    display(Analyze)\n",
    "    Analyze.to_csv('./Analyze_Proba/' + filename + '_20.csv', index=True)\n",
    "    Analyze.to_latex(\n",
    "        './Analyze_Proba/' + filename + '_20.tex', \n",
    "        index=True, \n",
    "        float_format=\"{:.2f}\".format, \n",
    "        column_format='rrrcrrrrrrrrrrr',\n",
    "        escape=False\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##### 100 bins\n",
    "    n = 100\n",
    "    bins= [x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    Analyze = pd.DataFrame()\n",
    "    Analyze['Neg'] = G\n",
    "    Analyze['Pos'] = H\n",
    "    Analyze['p'] = bins[1:]\n",
    "#    Analyze['Neg/Pos'] = Analyze['Neg']/Analyze['Pos']\n",
    "    Analyze['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] = Analyze['Pos']/(Analyze['Pos'] + Analyze['Neg'])\n",
    "    Analyze['TN'] = Analyze['Neg'].cumsum()\n",
    "    Analyze['FP'] = N - Analyze['TN']\n",
    "    Analyze['FN'] = Analyze['Pos'].cumsum()\n",
    "    Analyze['TP'] = P - Analyze['FN']\n",
    "#    Analyze['FP/TP'] = Analyze['FP']/Analyze['TP']\n",
    "#    Analyze['FP+TP'] = Analyze['FP'] + Analyze['TP']\n",
    "    Analyze['Prec'] = Analyze['TP']/(Analyze['FP'] + Analyze['TP'])\n",
    "    Analyze['Rec'] =  Analyze['TP']/(Analyze['FN'] + Analyze['TP'])\n",
    "    Analyze['$\\\\frac{\\\\text{FP}}{\\\\text{P}}$'] =  Analyze['FP']/(Analyze['FN'] + Analyze['TP'])\n",
    "    \n",
    "    A = Analyze.copy(deep=True)\n",
    "    \n",
    "    Analyze['Neg']=Analyze['Neg'].apply('{:,}'.format)\n",
    "    Analyze['Pos']=Analyze['Pos'].apply('{:,}'.format)\n",
    "    Analyze['TN']=Analyze['TN'].apply('{:,}'.format)\n",
    "    Analyze['FP']=Analyze['FP'].apply('{:,}'.format)\n",
    "    Analyze['FN']=Analyze['FN'].apply('{:,}'.format)\n",
    "    Analyze['TP']=Analyze['TP'].apply('{:,}'.format)\n",
    "#    Analyze['FP+TP']=Analyze['FP+TP'].apply('{:,}'.format)\n",
    "    \n",
    "#    Analyze['Neg/Pos']=Analyze['Neg/Pos'].apply('{:.2f}'.format)\n",
    "    Analyze['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$']=Analyze['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'].apply('{:.2f}'.format)\n",
    "#    Analyze['FP/TP']=Analyze['FP/TP'].apply('{:.2f}'.format)\n",
    "    Analyze['Prec']=Analyze['Prec'].apply('{:.2f}'.format)\n",
    "    Analyze['Rec']=Analyze['Rec'].apply('{:.2f}'.format)\n",
    "    Analyze['$\\\\frac{\\\\text{FP}}{\\\\text{P}}$']=Analyze['$\\\\frac{\\\\text{FP}}{\\\\text{P}}$'].apply('{:.2f}'.format)\n",
    "        \n",
    "#    Analyze.index.name = 'p'\n",
    "    Analyze.set_index('p', inplace=True)\n",
    "#    print ('./Analyze_Proba/' + filename + '_10.tex')\n",
    "#    print (len(y_proba))\n",
    "#    display(Analyze)\n",
    "    Analyze.to_csv('./Analyze_Proba/' + filename + '_100.csv', index=True)\n",
    "    Analyze.to_latex(\n",
    "        './Analyze_Proba/' + filename + '_100.tex', \n",
    "        index=True, \n",
    "        float_format=\"{:.2f}\".format, \n",
    "        column_format='rrrcrrrrrrrrrrr',\n",
    "        escape=False\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # Append CSV files with results from multiple models\n",
    "    A.set_index('p', inplace=True)\n",
    "    A.insert(0, 'Filename', filename)\n",
    "    \n",
    "    # Remove rows with negligible number of samples\n",
    "    A = A[A['Neg'] >= 20]\n",
    "    A = A[A['Pos'] >= 20]\n",
    "    \n",
    "    \n",
    "    A_closest = A.iloc[(A['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] - 0.333).abs().argsort()[:1]].head(1)\n",
    "    A_closest.to_csv('./Analyze_Proba/mProb_0_333.csv', mode='a', \n",
    "        index=True, header=False, float_format=\"{:.2f}\".format)\n",
    "    A_closest['Filename'] = A_closest['Filename'].str.replace('_','\\\\_')\n",
    "    A_closest.to_csv('./Analyze_Proba/mProb_0_333.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.2f}\".format)\n",
    "    \n",
    "    A_closest = A.iloc[(A['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] - 0.5).abs().argsort()[:1]].head(1)\n",
    "    A_closest.to_csv('./Analyze_Proba/mProb_0_5.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    A_closest['Filename'] = A_closest['Filename'].str.replace('_','\\\\_')\n",
    "    A_closest.to_csv('./Analyze_Proba/mProb_0_5.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.2f}\".format)\n",
    "    \n",
    "    A_closest = A.iloc[(A['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] - 0.667).abs().argsort()[:1]].head(1)\n",
    "    A_closest.to_csv('./Analyze_Proba/mProb_0_667.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    A_closest['Filename'] = A_closest['Filename'].str.replace('_','\\\\_')\n",
    "    A_closest.to_csv('./Analyze_Proba/mProb_0_667.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.2f}\".format)\n",
    "    \n",
    "    A_closest = A.iloc[(A['Prec'] - 0.333).abs().argsort()[:1]].head(1)\n",
    "    A_closest.to_csv('./Analyze_Proba/Prec_0_333.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    A_closest['Filename'] = A_closest['Filename'].str.replace('_','\\\\_')\n",
    "    A_closest.to_csv('./Analyze_Proba/Prec_0_333.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.2f}\".format)\n",
    "    \n",
    "    A_closest = A.iloc[(A['Prec'] - 0.5).abs().argsort()[:1]].head(1)\n",
    "    A_closest.to_csv('./Analyze_Proba/Prec_0_5.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    A_closest['Filename'] = A_closest['Filename'].str.replace('_','\\\\_')\n",
    "    A_closest.to_csv('./Analyze_Proba/Prec_0_5.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.2f}\".format)\n",
    "    \n",
    "    A_closest = A.iloc[(A['Prec'] - 0.667).abs().argsort()[:1]].head(1)\n",
    "    A_closest.to_csv('./Analyze_Proba/Prec_0_667.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    A_closest['Filename'] = A_closest['Filename'].str.replace('_','\\\\_')\n",
    "    A_closest.to_csv('./Analyze_Proba/Prec_0_667.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.2f}\".format)\n",
    "    \n",
    "    A_closest = A.iloc[(A['$\\\\frac{\\\\text{FP}}{\\\\text{P}}$'] - 0.05).abs().argsort()[:1]].head(1)\n",
    "    A_closest.to_csv('./Analyze_Proba/FP_P_0_05.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    A_closest['Filename'] = A_closest['Filename'].str.replace('_','\\\\_')\n",
    "    A_closest.to_csv('./Analyze_Proba/FP_P_0_05.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.2f}\".format)\n",
    "    \n",
    "    \n",
    "def Create_Files_for_Analyze_Prediction():\n",
    "    f = open('./Analyze_Proba/mPrec_0_5.csv', 'w')\n",
    "    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "    g = open('./Analyze_Proba/mPrec_0_5.tex', 'w')\n",
    "    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\n",
    "    g.close()\n",
    "    \n",
    "    f = open('./Analyze_Proba/mPrec_0_667.csv', 'w')\n",
    "    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "    g = open('./Analyze_Proba/mPrec_0_667.tex', 'w')\n",
    "    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\n",
    "    g.close()\n",
    "    \n",
    "    f = open('./Analyze_Proba/mPrec_0_333.csv', 'w')\n",
    "    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "    g = open('./Analyze_Proba/mPrec_0_333.tex', 'w')\n",
    "    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\n",
    "    g.close()\n",
    "    \n",
    "    f = open('./Analyze_Proba/Prec_0_5.csv', 'w')\n",
    "    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "    g = open('./Analyze_Proba/Prec_0_5.tex', 'w')\n",
    "    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\n",
    "    g.close()\n",
    "    \n",
    "    f = open('./Analyze_Proba/Prec_0_667.csv', 'w')\n",
    "    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "    g = open('./Analyze_Proba/Prec_0_667.tex', 'w')\n",
    "    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\n",
    "    g.close()\n",
    "    \n",
    "    f = open('./Analyze_Proba/Prec_0_333.csv', 'w')\n",
    "    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "    g = open('./Analyze_Proba/Prec_0_333.tex', 'w')\n",
    "    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\n",
    "    g.close()\n",
    "    \n",
    "    f = open('./Analyze_Proba/p_hat_0_05.csv', 'w')\n",
    "    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "    g = open('./Analyze_Proba/p_hat_0_05.tex', 'w')\n",
    "    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\n",
    "    g.close()\n",
    "    \n",
    "    f = open('./Analyze_Proba/p_hat_0_10.csv', 'w')\n",
    "    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "    g = open('./Analyze_Proba/p_hat_0_10.tex', 'w')\n",
    "    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\n",
    "    g.close()\n",
    "    \n",
    "    f = open('./Analyze_Proba/p_hat_0_15.csv', 'w')\n",
    "    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "    g = open('./Analyze_Proba/p_hat_0_15.tex', 'w')\n",
    "    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\n",
    "    g.close()\n",
    "    \n",
    "    f = open('./Analyze_Proba/FP_P_0_05.csv', 'w')\n",
    "    f.write(\"p,Filename,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "    g = open('./Analyze_Proba/FP_P_0_05.tex', 'w')\n",
    "    g.write(\"p & Filename & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P\\\\cr\\\\hline\\n\")\n",
    "    g.close()\n",
    "\n",
    "\n",
    "\n",
    "#Create_Files_for_Analyze_Prediction()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c58c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rolling_Intervals(y_proba, y_test, filename):\n",
    "    \n",
    "    A = pd.DataFrame(y_proba, columns=['y_proba'])\n",
    "    B = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    C = pd.concat([A,B], axis=1)\n",
    "    n = len(A)\n",
    "    P = C['y_test'].sum()\n",
    "    N = n - P\n",
    "    \n",
    "    # Sort the y_proba values with p==0 at the top.\n",
    "    \n",
    "    C.sort_values(by=['y_proba'], ascending=True, inplace=True)\n",
    "#    C = C.reset_index(drop=False)\n",
    "    \n",
    "    C['Neg'] = 1-C['y_test']\n",
    "    C['Pos'] = C['y_test']\n",
    "\n",
    "    D = C.groupby(['y_proba'], as_index=False).sum()\n",
    "    D['TN'] = D['Neg'].cumsum()\n",
    "    D['FP'] = N - D['TN']\n",
    "    D['FN'] = D['Pos'].cumsum()\n",
    "    D['TP'] = P - D['FN']\n",
    "    D['FP/P'] = D['FP'] / P\n",
    "    D['Prec'] = D['TP'] / (D['FP'] + D['TP'])\n",
    "    \n",
    "    for i in [1,10,20,50,100,200,500,1000,2000]:\n",
    "        tp = 'TP_' + str(i)\n",
    "        fp = 'FP_' + str(i)\n",
    "        prec = 'Prec_' + str(i)\n",
    "        \n",
    "        D[tp] = D['TP'].rolling(i, center=True).mean()\n",
    "        D[fp] = D['FP'].rolling(i, center=True).mean()\n",
    "        D[prec] = D[tp] / (D[fp] + D[tp])\n",
    "\n",
    "        E = D[abs(D[prec]-0.667)<0.01]\n",
    "#        print (i)\n",
    "#        display(E)\n",
    "        a = E['y_proba'].min()\n",
    "        b = E['y_proba'].max()\n",
    "#        print (filename, prec, a, b, b-a)\n",
    "\n",
    "        D_tmp = D[D['y_proba']==a]\n",
    "        D_tmp = D_tmp[['y_proba',prec,'TN','FP','FN','TP','FP/P']]\n",
    "        \n",
    "        D_tmp.insert(loc=0, column='Diff', value=b-a)\n",
    "        D_tmp.insert(loc=0, column='Max', value=b)\n",
    "        D_tmp.insert(loc=0, column='Min', value=a)\n",
    "        D_tmp.insert(loc=0, column='Min/Max', value='Min')\n",
    "        D_tmp.insert(loc=0, column='Roll', value=prec)\n",
    "        D_tmp.insert(loc=0, column='Filename', value=filename)        \n",
    "        D_tmp.to_csv('./Analyze_Proba/Prec_Rolling_0_667.csv', mode='a', index=True, header=False)\n",
    "        \n",
    "        D_tmp = D[D['y_proba']==b]\n",
    "        D_tmp = D_tmp[['y_proba',prec,'TN','FP','FN','TP','FP/P']]\n",
    "        \n",
    "        D_tmp.insert(loc=0, column='Diff', value=b-a)\n",
    "        D_tmp.insert(loc=0, column='Max', value=b)\n",
    "        D_tmp.insert(loc=0, column='Min', value=a)\n",
    "        D_tmp.insert(loc=0, column='Min/Max', value='Max')\n",
    "        D_tmp.insert(loc=0, column='Roll', value=prec)\n",
    "        D_tmp.insert(loc=0, column='Filename', value=filename)        \n",
    "        D_tmp.to_csv('./Analyze_Proba/Prec_Rolling_0_667.csv', mode='a', index=True, header=False)\n",
    "        \n",
    "        \n",
    "#        D_max = D[D['y_proba']==b]\n",
    "#        D_max.insert(loc=0, column='Min/Max', value='Max')\n",
    "#        D_max.insert(loc=0, column='Roll', value=prec)\n",
    "#        D_max.insert(loc=0, column='Filename', value=filename)        \n",
    "#        D_max.to_csv('./Analyze_Proba/Prec_Rolling_0_667.csv', mode='a', index=True, header=False)\n",
    "        \n",
    "\n",
    "    \n",
    "    D['mProb'] = D['Pos'] / (D['Neg'] + D['Pos'])\n",
    "    \n",
    "    for i in [1,10,20,50,100,200,500,1000,2000]:\n",
    "        pos = 'Pos_' + str(i)\n",
    "        neg = 'Neg_' + str(i)\n",
    "        mprob = 'mProb_' + str(i)\n",
    "        \n",
    "        D[pos] = D['Pos'].rolling(i, center=True).sum()\n",
    "        D[neg] = D['Neg'].rolling(i, center=True).sum()\n",
    "        D[mprob] = D[pos] / (D[neg] + D[pos])\n",
    "        \n",
    "        E = D[abs(D[mprob]-0.50)<0.01]\n",
    "#        print (i)\n",
    "#        display(E)\n",
    "        a = E['y_proba'].min()\n",
    "        b = E['y_proba'].max()\n",
    "#        print (filename, mprob, a, b, b-a)\n",
    "        \n",
    "        D_tmp = D[D['y_proba']==a]\n",
    "        D_tmp = D_tmp[['y_proba',neg,pos,mprob,'TN','FP','FN','TP','FP/P']]\n",
    "        \n",
    "        D_tmp.insert(loc=0, column='Diff', value=b-a)\n",
    "        D_tmp.insert(loc=0, column='Max', value=b)\n",
    "        D_tmp.insert(loc=0, column='Min', value=a)\n",
    "        D_tmp.insert(loc=0, column='Min/Max', value='Min')\n",
    "        D_tmp.insert(loc=0, column='Roll', value=mprob)\n",
    "        D_tmp.insert(loc=0, column='Filename', value=filename)        \n",
    "        D_tmp.to_csv('./Analyze_Proba/mProb_Rolling_0_500.csv', mode='a', index=True, header=False)\n",
    "        \n",
    "        D_tmp = D[D['y_proba']==b]\n",
    "        D_tmp = D_tmp[['y_proba',neg,pos,mprob,'TN','FP','FN','TP','FP/P']]\n",
    "        \n",
    "        D_tmp.insert(loc=0, column='Diff', value=b-a)\n",
    "        D_tmp.insert(loc=0, column='Max', value=b)\n",
    "        D_tmp.insert(loc=0, column='Min', value=a)\n",
    "        D_tmp.insert(loc=0, column='Min/Max', value='Max')\n",
    "        D_tmp.insert(loc=0, column='Roll', value=mprob)\n",
    "        D_tmp.insert(loc=0, column='Filename', value=filename)        \n",
    "        D_tmp.to_csv('./Analyze_Proba/mProb_Rolling_0_500.csv', mode='a', index=True, header=False)\n",
    "        \n",
    "    \n",
    "\n",
    "    D.to_csv('./Analyze_Proba/' + filename + '_Rolling_Intervals.csv')\n",
    "    \n",
    "#    display(C)\n",
    "#    display(D)\n",
    "    \n",
    "def Create_File_for_Rolling_Intervals():\n",
    "    f = open('./Analyze_Proba/Prec_Rolling_0_667.csv', 'w')\n",
    "    f.write('Index,Filename,Roll,Min/Max,Min,Max,Diff,y_proba,Prec,TN,FP,FN,TP,FP/P\\n')\n",
    "    f.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/mProb_Rolling_0_500.csv', 'w')\n",
    "    f.write('Index,Filename,Roll,Min/Max,Min,Max,Diff,y_proba,Neg,Pos,mprob,TN,FP,FN,TP,FP/P\\n')\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7887bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FP_P_Locate(y_proba, y_test, filename):\n",
    "    print ('FP_P_Locate() for ', filename)\n",
    "    \n",
    "    A = pd.DataFrame(y_proba, columns=['y_proba'])\n",
    "    B = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    C = pd.concat([A,B], axis=1)\n",
    "    \n",
    "    # Sort the y_proba values with p==1 at the top.\n",
    "    # Make a feature, 'custom_cut'\n",
    "    # Make a cut large enough that it has at least 1000 elements of each class.\n",
    "    # Do not cut between two y_proba of the same value; \n",
    "    #    keep going until you get to a different y_proba value.\n",
    "    # Label that cut \"0,\" and the next cut \"1,\" etc.\n",
    "    \n",
    "    C.sort_values(by=['y_proba'], ascending=False, inplace=True)\n",
    "    C = C.reset_index(drop=True)\n",
    "    C['custom_cut'] = 0\n",
    "    \n",
    "    n0 = 0\n",
    "    n1 = 0\n",
    "    j = 0\n",
    "    C['custom_cut'][0] = j\n",
    "    if C['y_test'][0]==0:\n",
    "        n0 += 1\n",
    "    else:\n",
    "        n1 += 1\n",
    "    for i in range (1,len(C)):\n",
    "#        if i%1000==0:\n",
    "#            print (i, j)\n",
    "        if (\n",
    "            C['y_proba'][i] != C['y_proba'][i-1] \n",
    "        ):\n",
    "            n0 = 0\n",
    "            n1 = 0\n",
    "            j = j+1\n",
    "        if C['y_test'][i]==0:\n",
    "            n0 += 1\n",
    "        else:\n",
    "            n1 += 1\n",
    "        C['custom_cut'][i] = j\n",
    "    print (filename, ' has ', j, ' custom_cut intervals of minCut 0')\n",
    "#    print (C)\n",
    "    \n",
    "\n",
    "    n = len(y_proba)\n",
    "    P = C['y_test'].sum()\n",
    "    N = n - P\n",
    "#    print (n,P)\n",
    "    \n",
    "    C['Neg'] = 1-C['y_test']\n",
    "    C['Pos'] = C['y_test']\n",
    "    C['TN'] = C['Neg'].cumsum()\n",
    "    C['FP'] = N - C['TN']\n",
    "    C['FN'] = C['Pos'].cumsum()\n",
    "    C['TP'] = P - C['FN']\n",
    "    C['FP/P'] = C['FP']/P\n",
    "#    C['Prec'] = C['TP']/(C['FP'] + C['TP'])\n",
    "#    C['Pos/(Neg+Pos)'] = C['Pos']/(C['Neg'] + C['Pos'])\n",
    "\n",
    "    # Count the positive and negative elements in each of the custom_cuts\n",
    "    \n",
    "    D = C[C['y_test']==0]\n",
    "    E = C[C['y_test']==1]\n",
    "\n",
    "    F = D['custom_cut'].value_counts(sort=False).rename(\"Neg\")\n",
    "    G = E['custom_cut'].value_counts(sort=False).rename(\"Pos\")\n",
    "    H = pd.concat([F,G], axis=1, names=['Neg','Pos'])\n",
    "    H = H.fillna(0)\n",
    "    H['Neg'] = H['Neg'].astype(int)\n",
    "    H['Pos'] = H['Pos'].astype(int)\n",
    "\n",
    "    H['index1'] = H.index\n",
    "    H.sort_values(by=['index1'], ascending=False, inplace=True)\n",
    "    H = H.reset_index()\n",
    "    H['TN'] = H['Neg'].cumsum()\n",
    "    H['TN'] = H['TN'].astype(int)\n",
    "    H['FP'] = len(D) - H['TN']\n",
    "    H['FP'] = H['FP'].astype(int)\n",
    "    H['FN'] = H['Pos'].cumsum()\n",
    "    H['FN'] = H['FN'].astype(int)\n",
    "    H['TP'] = len(E) - H['FN']\n",
    "    H['TP'] = H['TP'].astype(int)\n",
    "    H['Prec'] = H['TP']/(H['FP'] + H['TP'])\n",
    "    H['Rec'] = H['TP']/(H['FN'] + H['TP'])\n",
    "    H['FP/P'] = H['FP']/(H['FN'] + H['TP'])\n",
    "    \n",
    "\n",
    "    H['min'] = 0\n",
    "    H['max'] = 0\n",
    "    \n",
    "    for i in range (len(H)):\n",
    "        I = C[C['custom_cut']==H['index1'][i]]\n",
    "        H['min'][i] = I['y_proba'].min()\n",
    "        H['max'][i] = I['y_proba'].max()\n",
    "    \n",
    "    H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] = H['Pos']/(H['Neg']+H['Pos'])\n",
    "    \n",
    "    H = H.drop('index1', axis='columns')\n",
    "    H = H.loc[:,['min','max','Neg','Pos','$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$','TN','FP','FN','TP','Prec','Rec','FP/P']]\n",
    "\n",
    "    \n",
    "    H.insert(0, 'Filename', filename)\n",
    "    H.insert(0, 'len', len(H))\n",
    "    \n",
    "    # Find p value that gives FP/P closest to 5%\n",
    "    H_closest = H.iloc[(H['FP/P'] - 0.05).abs().argsort()[:1]].head(1)\n",
    "#    print (H_closest)\n",
    "    \n",
    "    H_closest.to_csv('./Analyze_Proba/FP_P_0_05.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "#    H_closest['Filename'] = H_closest['Filename'].str.replace('_','\\\\_')\n",
    "#    H_closest.to_csv('./Analyze_Proba/FP_P_0_05.tex', \n",
    "#        mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "#        index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \n",
    "    # Find p value that gives FP/P closest to 10%\n",
    "    H_closest = H.iloc[(H['FP/P'] - 0.10).abs().argsort()[:1]].head(1)\n",
    "#    print (H_closest)\n",
    "    \n",
    "    H_closest.to_csv('./Analyze_Proba/FP_P_0_10.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "#    H_closest['Filename'] = H_closest['Filename'].str.replace('_','\\\\_')\n",
    "#    H_closest.to_csv('./Analyze_Proba/FP_P_0_10.tex', \n",
    "#                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "#                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \n",
    "\n",
    "def Create_Files_for_FP_P():\n",
    "    print ('Create_Files_for_FP_P()')\n",
    "    f = open('./Analyze_Proba/FP_P_0_05.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/FP_P_0_05.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/FP_P_0_10.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/FP_P_0_10.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3f53a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze_Prediction(y_test, y_proba, filename, title):\n",
    "    print ('Analyze_Prediction() for ', filename)\n",
    "    \n",
    "    Value_Counts_y_proba(y_proba, filename)\n",
    "    FP_P_Locate(y_proba, y_test, filename)\n",
    "    \n",
    "#    print ('y_proba: ',y_proba)\n",
    "#    print ('y_test: ', y_test)\n",
    "    A = pd.DataFrame(y_proba, columns=['y_proba'])\n",
    "    B = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    C = pd.concat([A,B], axis=1)\n",
    "    \n",
    "    # Sort the y_proba values with p==1 at the top.\n",
    "    # Make a feature, 'custom_cut'\n",
    "    # Make a cut large enough that it has at least 1000 elements of each class.\n",
    "    # Do not cut between two y_proba of the same value; \n",
    "    #    keep going until you get to a different y_proba value.\n",
    "    # Label that cut \"0,\" and the next cut \"1,\" etc.\n",
    "    \n",
    "    C.sort_values(by=['y_proba'], ascending=False, inplace=True)\n",
    "    C = C.reset_index(drop=True)\n",
    "    C['custom_cut'] = 0\n",
    "    \n",
    "    n0 = 0\n",
    "    n1 = 0\n",
    "    j = 0\n",
    "    C['custom_cut'][0] = j\n",
    "    if C['y_test'][0]==0:\n",
    "        n0 += 1\n",
    "    else:\n",
    "        n1 += 1\n",
    "    for i in range (1,len(C)):\n",
    "#        if i%1000==0:\n",
    "#            print (i, j)\n",
    "        if (\n",
    "            min(n0,n1)>=1000 and \n",
    "            C['y_proba'][i] != C['y_proba'][i-1] \n",
    "        ):\n",
    "            n0 = 0\n",
    "            n1 = 0\n",
    "            j = j+1\n",
    "        if C['y_test'][i]==0:\n",
    "            n0 += 1\n",
    "        else:\n",
    "            n1 += 1\n",
    "        C['custom_cut'][i] = j\n",
    "    print (filename, ' has ', j, ' custom_cut intervals of minCut 1000')\n",
    "#    print (C)\n",
    "    \n",
    "    # Count the positive and negative elements in each of the custom_cuts\n",
    "    \n",
    "    D = C[C['y_test']==0]\n",
    "    E = C[C['y_test']==1]\n",
    "\n",
    "    F = D['custom_cut'].value_counts(sort=False).rename(\"Neg\")\n",
    "    G = E['custom_cut'].value_counts(sort=False).rename(\"Pos\")\n",
    "    H = pd.concat([F,G], axis=1, names=['Neg','Pos'])\n",
    "\n",
    "    H['index1'] = H.index\n",
    "    H.sort_values(by=['index1'], ascending=False, inplace=True)\n",
    "    H = H.reset_index()\n",
    "    H['TN'] = H['Neg'].cumsum()\n",
    "    H['FP'] = len(D) - H['TN']\n",
    "    H['FN'] = H['Pos'].cumsum()\n",
    "    H['TP'] = len(E) - H['FN']\n",
    "    H['Prec'] = H['TP']/(H['FP'] + H['TP'])\n",
    "    H['Rec'] = H['TP']/(H['FN'] + H['TP'])\n",
    "    H['FP/P'] = H['FP']/(H['FN'] + H['TP'])\n",
    "    \n",
    "\n",
    "    H['min'] = 0\n",
    "    H['max'] = 0\n",
    "    \n",
    "    for i in range (len(H)):\n",
    "        I = C[C['custom_cut']==H['index1'][i]]\n",
    "        H['min'][i] = I['y_proba'].min()\n",
    "        H['max'][i] = I['y_proba'].max()\n",
    "    \n",
    "    H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] = H['Pos']/(H['Neg']+H['Pos'])\n",
    "    \n",
    "    H = H.drop('index1', axis='columns')\n",
    "    H = H.loc[:,['min','max','Neg','Pos','$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$','TN','FP','FN','TP','Prec','Rec','FP/P']]\n",
    "\n",
    "    P = H.copy(deep=True)\n",
    "    \n",
    "    R = H['max'] - H['min']\n",
    "    r = R.min()\n",
    "    if r!=0:\n",
    "        s = math.log10(r)\n",
    "    else:\n",
    "        s=-10\n",
    "    t = int(-s)\n",
    "#    print ('R, r, s, t')\n",
    "#    print (R)\n",
    "#    print (r, s, t)\n",
    "    \n",
    "    if t < 2:\n",
    "        H['min']=H['min'].apply('{:.3f}'.format)\n",
    "        H['max']=H['max'].apply('{:.3f}'.format)\n",
    "    if t==2:\n",
    "        H['min']=H['min'].apply('{:.4f}'.format)\n",
    "        H['max']=H['max'].apply('{:.4f}'.format)\n",
    "    if t==3:\n",
    "        H['min']=H['min'].apply('{:.5f}'.format)\n",
    "        H['max']=H['max'].apply('{:.5f}'.format)\n",
    "    if t>4:\n",
    "        H['min']=H['min'].apply('{:.6f}'.format)\n",
    "        H['max']=H['max'].apply('{:.6f}'.format)\n",
    "    \n",
    "    H['Neg']=H['Neg'].apply('{:,}'.format)\n",
    "    H['Pos']=H['Pos'].apply('{:,}'.format)\n",
    "    H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$']=H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'].apply('{:.4f}'.format)\n",
    "    H['TN']=H['TN'].apply('{:,}'.format)\n",
    "    H['FP']=H['FP'].apply('{:,}'.format)\n",
    "    H['FN']=H['FN'].apply('{:,}'.format)\n",
    "    H['TP']=H['TP'].apply('{:,}'.format)\n",
    "    H['Prec']=H['Prec'].apply('{:.4f}'.format)\n",
    "    H['Rec']=H['Rec'].apply('{:.4f}'.format)\n",
    "    H['FP/P']=H['FP/P'].apply('{:.4f}'.format)\n",
    "    \n",
    "    H.to_csv('./Analyze_Proba/' + filename + '_1000_Slices.csv', index=True)\n",
    "\n",
    "    \"\"\"\n",
    "    H.to_latex(\n",
    "        './Analyze_Proba/' + filename + '_1000_Slices.tex', \n",
    "        index=True, \n",
    "#        float_format=\"{:.4f}\".format, \n",
    "        column_format='rrrrrrrrrrrrr',\n",
    "        escape=False\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "#    print (H)\n",
    "    \n",
    "    # Append CSV files with results from multiple models\n",
    "    P.insert(0, 'Filename', filename)\n",
    "    P.insert(0, 'len', len(P))\n",
    "    \n",
    "    P_closest = P.iloc[(P['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] - 0.333).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/mProb_0_333.csv', mode='a', \n",
    "        index=True, header=False, float_format=\"{:.2f}\".format)\n",
    "\n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/mProb_0_333.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, \n",
    "#                     float_format=\"{:.4f}\".format\n",
    "                    )\n",
    "    \"\"\"\n",
    "    \n",
    "    P_closest = P.iloc[(P['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] - 0.5).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/mProb_0_5.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/mProb_0_5.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \"\"\"\n",
    "    \n",
    "    P_closest = P.iloc[(P['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] - 0.667).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/mProb_0_667.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/mProb_0_667.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \"\"\"\n",
    "    \n",
    "    P_closest = P.iloc[(P['Prec'] - 0.333).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/Prec_0_333.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/Prec_0_333.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \"\"\"\n",
    "    \n",
    "    P_closest = P.iloc[(P['Prec'] - 0.5).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/Prec_0_5.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/Prec_0_5.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \"\"\"\n",
    "    \n",
    "    P_closest = P.iloc[(P['Prec'] - 0.667).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/Prec_0_667.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/Prec_0_667.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "def Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, minCut):\n",
    "    filename = filename + '_' + str(minCut)\n",
    "    print ('Analyze_Prediction_Custom_Cut() for ', filename)\n",
    "    \n",
    "#    print ('y_proba: ',y_proba)\n",
    "#    print ('y_test: ', y_test)\n",
    "    A = pd.DataFrame(y_proba, columns=['y_proba'])\n",
    "    B = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    C = pd.concat([A,B], axis=1)\n",
    "    \n",
    "    # Sort the y_proba values with p==1 at the top.\n",
    "    # Make a feature, 'custom_cut'\n",
    "    # Make a cut large enough that it has at least 1000 elements of each class.\n",
    "    # Do not cut between two y_proba of the same value; \n",
    "    #    keep going until you get to a different y_proba value.\n",
    "    # Label that cut \"0,\" and the next cut \"1,\" etc.\n",
    "    \n",
    "    C.sort_values(by=['y_proba'], ascending=False, inplace=True)\n",
    "    C = C.reset_index(drop=True)\n",
    "    C['custom_cut'] = 0\n",
    "    \n",
    "    n0 = 0\n",
    "    n1 = 0\n",
    "    j = 0\n",
    "    C['custom_cut'][0] = j\n",
    "    if C['y_test'][0]==0:\n",
    "        n0 += 1\n",
    "    else:\n",
    "        n1 += 1\n",
    "    for i in range (1,len(C)):\n",
    "#        if i%1000==0:\n",
    "#            print (i, j)\n",
    "        if (\n",
    "            min(n0,n1)>=minCut and \n",
    "            C['y_proba'][i] != C['y_proba'][i-1] \n",
    "        ):\n",
    "            n0 = 0\n",
    "            n1 = 0\n",
    "            j = j+1\n",
    "        if C['y_test'][i]==0:\n",
    "            n0 += 1\n",
    "        else:\n",
    "            n1 += 1\n",
    "        C['custom_cut'][i] = j\n",
    "    print (filename, ' has ', j, ' custom_cut intervals of minCut ', minCut)\n",
    "#    print (C)\n",
    "    \n",
    "    # Count the positive and negative elements in each of the custom_cuts\n",
    "    \n",
    "    D = C[C['y_test']==0]\n",
    "    E = C[C['y_test']==1]\n",
    "\n",
    "    F = D['custom_cut'].value_counts(sort=False).rename(\"Neg\")\n",
    "    G = E['custom_cut'].value_counts(sort=False).rename(\"Pos\")\n",
    "    H = pd.concat([F,G], axis=1, names=['Neg','Pos'])\n",
    "    H = H.fillna(0)\n",
    "    H['Neg'] = H['Neg'].astype(int)\n",
    "    H['Pos'] = H['Pos'].astype(int)\n",
    "\n",
    "    H['index1'] = H.index\n",
    "    H.sort_values(by=['index1'], ascending=False, inplace=True)\n",
    "    H = H.reset_index()\n",
    "    H['TN'] = H['Neg'].cumsum()\n",
    "    H['TN'] = H['TN'].astype(int)\n",
    "    H['FP'] = len(D) - H['TN']\n",
    "    H['FP'] = H['FP'].astype(int)\n",
    "    H['FN'] = H['Pos'].cumsum()\n",
    "    H['FN'] = H['FN'].astype(int)\n",
    "    H['TP'] = len(E) - H['FN']\n",
    "    H['TP'] = H['TP'].astype(int)\n",
    "    H['Prec'] = H['TP']/(H['FP'] + H['TP'])\n",
    "    H['Rec'] = H['TP']/(H['FN'] + H['TP'])\n",
    "    H['FP/P'] = H['FP']/(H['FN'] + H['TP'])\n",
    "    \n",
    "\n",
    "    H['min'] = 0\n",
    "    H['max'] = 0\n",
    "    \n",
    "    for i in range (len(H)):\n",
    "        I = C[C['custom_cut']==H['index1'][i]]\n",
    "        H['min'][i] = I['y_proba'].min()\n",
    "        H['max'][i] = I['y_proba'].max()\n",
    "    \n",
    "    H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] = H['Pos']/(H['Neg']+H['Pos'])\n",
    "    \n",
    "    H = H.drop('index1', axis='columns')\n",
    "    H = H.loc[:,['min','max','Neg','Pos','$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$','TN','FP','FN','TP','Prec','Rec','FP/P']]\n",
    "\n",
    "    P = H.copy(deep=True)\n",
    "    \n",
    "#    R = H['max'] - H['min']\n",
    "    R = H['min'].diff()\n",
    "    r = R.min()\n",
    "    if r!=0:\n",
    "        s = math.log10(r)\n",
    "    else:\n",
    "        s = -10\n",
    "    t = int(-s)\n",
    "#    print (R)\n",
    "#    print ('r, s, t = ', r, s, t)\n",
    "#    print ()\n",
    "    \n",
    "    if t < 2:\n",
    "        H['min']=H['min'].apply('{:.3f}'.format)\n",
    "        H['max']=H['max'].apply('{:.3f}'.format)\n",
    "    if t==2:\n",
    "        H['min']=H['min'].apply('{:.4f}'.format)\n",
    "        H['max']=H['max'].apply('{:.4f}'.format)\n",
    "    if t==3:\n",
    "        H['min']=H['min'].apply('{:.5f}'.format)\n",
    "        H['max']=H['max'].apply('{:.5f}'.format)\n",
    "    if t>4:\n",
    "        H['min']=H['min'].apply('{:.6f}'.format)\n",
    "        H['max']=H['max'].apply('{:.6f}'.format)\n",
    "    \n",
    "    H['Neg']=H['Neg'].apply('{:,}'.format)\n",
    "    H['Pos']=H['Pos'].apply('{:,}'.format)\n",
    "    H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$']=H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'].apply('{:.4f}'.format)\n",
    "    H['TN']=H['TN'].apply('{:,}'.format)\n",
    "    H['FP']=H['FP'].apply('{:,}'.format)\n",
    "    H['FN']=H['FN'].apply('{:,}'.format)\n",
    "    H['TP']=H['TP'].apply('{:,}'.format)\n",
    "    H['Prec']=H['Prec'].apply('{:.4f}'.format)\n",
    "    H['Rec']=H['Rec'].apply('{:.4f}'.format)\n",
    "    H['FP/P']=H['FP/P'].apply('{:.4f}'.format)\n",
    "    \n",
    "    H.to_csv('./Analyze_Proba/' + filename + '_Slices.csv', index=True)\n",
    "\n",
    "    \"\"\"\n",
    "    H.to_latex(\n",
    "        './Analyze_Proba/' + filename + '_Slices.tex', \n",
    "        index=False, \n",
    "#        float_format=\"{:.4f}\".format, \n",
    "        column_format='rrrrrrrrrrrrr',\n",
    "        escape=False\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def Create_Files_for_Analyze_Prediction():\n",
    "    print ('Create_Files_for_Analyze_Prediction()')\n",
    "    f = open('./Analyze_Proba/mProb_0_5.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/mProb_0_5.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/mProb_0_667.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/mProb_0_667.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/mProb_0_333.csv', 'w')\n",
    "    f.write(\"Index,,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/mProb_0_333.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/Prec_0_5.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/Prec_0_5.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/Prec_0_667.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/Prec_0_667.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/Prec_0_333.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/Prec_0_333.tex', 'w')\n",
    "#    g.write(\"Index & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e092785",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Test_Plot_Prediction_Zoom():\n",
    "    print ('Idealized_Results()')\n",
    "    # Set randomness\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow    \n",
    "\n",
    "    shape, scale = 3.7, 0.1 # mean=4, std=2*sqrt(2)\n",
    "    a = np.random.gamma(shape, scale, 150771)\n",
    "    a = np.where(a>1.0, random.random(), a)\n",
    "    \n",
    "    shape, scale = 3.8, 0.1 # mean=4, std=2*sqrt(2)\n",
    "    b = np.random.gamma(shape, scale, 26621)    \n",
    "    b = np.where(b>1.0, random.random(), b)\n",
    "    b = 1-b\n",
    "    \n",
    "    y_proba = np.concatenate((a,b),axis=0)\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)  \n",
    "    \n",
    "    display(y_proba[:20])\n",
    "    display(y_pred[:20])\n",
    "    \n",
    "    Plot_Prediction(y_test, y_proba, 'Test', 'Test')    \n",
    "    Plot_Prediction_Wide(y_test, y_proba, 'Test', 'Test')    \n",
    "    Plot_Prediction_Zoom(y_test, y_proba, 'Test', 'Test', 0.45, 0.55)\n",
    "    Analyze_Prediction(y_test, y_proba, 'Test', 'Test')    \n",
    "    \n",
    "#Test_Plot_Prediction_Zoom()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a04113",
   "metadata": {},
   "source": [
    "## Plot ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e088e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n",
      "[0.437 0.626 0.674 ... 0.609 0.595 0.676]\n",
      "ROC() for  tmp\n",
      "./Images/tmp_ROC.png\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ROC(y_test, y_proba, p_values, filename):\n",
    "    print ('ROC() for ', filename)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    \n",
    "    A = np.asarray((fpr,tpr)).T\n",
    "#    print ()\n",
    "#    print ('len(fpr/tpr) = ', len(A))\n",
    "#    print (A[:10])\n",
    "    A = np.unique(A, axis=0)\n",
    "#    print (A[:10])\n",
    "    nU = len(A)\n",
    "#    print ('Unique fpr/tpr = ', nU)\n",
    "#    print ()\n",
    "    \n",
    "    f = open('./Analyze_Proba/Lengths_of_fpr_tpr.csv', 'a')\n",
    "    f.write('%s,' % (filename))\n",
    "    f.write('%d,' % len(y_proba))\n",
    "    f.write('%d,' % len(np.unique(y_proba)))\n",
    "    f.write('%d,' % len(fpr))\n",
    "    f.write('%d,' % len(np.unique(fpr)))\n",
    "    f.write('%d,' % len(tpr))\n",
    "    f.write('%d,' % len(np.unique(tpr)))\n",
    "    f.write('%d,' % len(np.asarray((fpr,tpr)).T))\n",
    "    f.write('%d,' % len(np.unique(np.asarray((fpr,tpr)).T, axis=0)))\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "#    print ('N_median, P_median = ', N_median, P_median)\n",
    "\n",
    "    m = np.quantile(y_proba,0.50)\n",
    "    p = np.quantile(y_proba,0.25)\n",
    "    q = np.quantile(y_proba,0.75)\n",
    "    \n",
    "    Y = []\n",
    "#    print ('p_values = ', p_values)\n",
    "    for X in p_values:\n",
    "        difference_array = np.absolute(thresholds-X)\n",
    "        index = difference_array.argmin()\n",
    "        F = fpr[index]\n",
    "        T = tpr[index]\n",
    "        Y.append([X,str(round(X,3)),F,T])\n",
    "    \n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_value = round(auc_value,3)\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, color='black', label='AUC={:.3f}'.format(auc_value))\n",
    "    \n",
    "    for y in Y:\n",
    "#        plt.plot([y[2]], [y[3]], marker=\"o\", markersize=20, markeredgecolor=\"white\", markerfacecolor=\"white\")\n",
    "        plt.plot([y[2]], [y[3]], marker=\"o\", markersize=5, markeredgecolor=\"black\", markerfacecolor=\"black\")\n",
    "#        plt.annotate(\n",
    "#            y[1], # this is the text\n",
    "#            (y[2], y[3]), # these are the coordinates to position the label\n",
    "#            ha='center' # horizontal alignment can be left, right or center\n",
    "#        )\n",
    "#        plt.text(\n",
    "#            y[2], y[3], # these are the coordinates to position the label\n",
    "#            y[1], # this is the text\n",
    "#            backgroundcolor='white', # horizontal alignment can be left, right or center\n",
    "#            bbox=dict(facecolor='white', edgecolor='none', boxstyle='square,pad=0.3')\n",
    "#        )\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "#    plt.title('ROC with AUC {:.3f}'.format(auc_value))\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('./Images/' + filename + '_ROC.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + filename + '_ROC.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    print ('./Images/' + filename + '_ROC.png')\n",
    "#    plt.show()\n",
    "#    plt.close()\n",
    "    print ()\n",
    "    return 0\n",
    "\n",
    "def Test_ROC():\n",
    "    y_test = [0,0,0,0,0,1]*10000\n",
    "#    y_proba = [abs(0.45 - y)+round(0.45*random.random(),2) for y in y_test]\n",
    "    y_proba = [abs(0.45 - y)+round(0.45*random.normalvariate(mu=0.2, sigma=0.2),3) for y in y_test]\n",
    "#    random.normalvariate(mu=0.0, sigma=1.0)\n",
    "    y_test = np.array(y_test)\n",
    "    y_proba = np.array(y_proba)\n",
    "    print (y_test)\n",
    "    print (y_proba)\n",
    "    ROC(y_test, y_proba, [0.5], \"tmp\")\n",
    "    \n",
    "Test_ROC()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9c0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_Custom_Cuts(y_test, y_proba, y_pred, filename, title):\n",
    "    print ('Do_Custom_Cuts()')\n",
    "    \n",
    "    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 6400)\n",
    "    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 3200)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 1600)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 800)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 400)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 200)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 100)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 50)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 25)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 10)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 5)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52566066",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72178501",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Analyze_Results():\n",
    "    print ('Analyze_Results()')\n",
    "    \n",
    "    Models = [\n",
    "        'AdaBoost',\n",
    "        'BalBag',\n",
    "        'BRFC_alpha_0_5',\n",
    "        'BRFC_alpha_balanced',\n",
    "        'EEC',\n",
    "        'KBFC_alpha_0_5_gamma_0_0',\n",
    "        'KBFC_alpha_balanced_gamma_0_0',\n",
    "        'KBFC_alpha_0_5_gamma_1_0',\n",
    "        'KBFC_alpha_0_5_gamma_2_0',\n",
    "        'LogReg_alpha_0_5',\n",
    "        'LogReg_alpha_balanced',\n",
    "        'RFC',\n",
    "        'RUSBoost',\n",
    "    ]\n",
    "    \n",
    "    for model in Models:\n",
    "        for features in [\n",
    "            '_Hard_Run_0', \n",
    "            '_Hard_Run_1', \n",
    "            '_Medium_Run_0', \n",
    "            '_Medium_Run_1', \n",
    "            '_Easy_Run_0',\n",
    "            '_Easy_Run_1',\n",
    "        ]:\n",
    "            print ()\n",
    "            print ('-------------------------------------')\n",
    "            print ()\n",
    "            filename = model + features\n",
    "            print (filename)\n",
    "            df = pd.read_csv('../../Big_Files/' + filename + '.csv')\n",
    "            \n",
    "            m = df['y_proba'].min()\n",
    "            M = df['y_proba'].max()\n",
    "            num_prec = 4 - int(math.log10(M-m))\n",
    "            print ('num_prec = ', num_prec)\n",
    "\n",
    "            y_test = df['y_test'].to_numpy()\n",
    "            y_proba = df['y_proba'].to_numpy()\n",
    "            y_pred = df['y_pred'].to_numpy()\n",
    "#            Chart_and_Plots(y_test, y_proba, y_pred, filename, '')\n",
    "#            Do_Custom_Cuts(y_test, y_proba, y_pred, filename, '')\n",
    "#            Rolling_Intervals(y_proba, y_test, filename)\n",
    "            Rolling_Intervals(np.round(y_proba,num_prec), y_test, filename + '_Round_' + str(num_prec))\n",
    "            print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73a86579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out these lines if you just want to append to the files, not recreate them.\n",
    "#Create_Files_for_Value_Counts_y_proba()\n",
    "#Create_Files_for_Analyze_Prediction()\n",
    "#Create_Files_for_Lengths_of_fpr_tpr()\n",
    "#Create_Files_for_ROC_AUC()\n",
    "#Create_Files_for_FP_P()\n",
    "Create_File_for_Rolling_Intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddb852de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze_Results()\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "AdaBoost_Hard_Run_0\n",
      "num_prec =  5\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "AdaBoost_Hard_Run_1\n",
      "num_prec =  5\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "AdaBoost_Medium_Run_0\n",
      "num_prec =  5\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "AdaBoost_Medium_Run_1\n",
      "num_prec =  5\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "AdaBoost_Easy_Run_0\n",
      "num_prec =  6\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "AdaBoost_Easy_Run_1\n",
      "num_prec =  6\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BalBag_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BalBag_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BalBag_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BalBag_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BalBag_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BalBag_Easy_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_0_5_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_0_5_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_0_5_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_0_5_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_0_5_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_0_5_Easy_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_balanced_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_balanced_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_balanced_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_balanced_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_balanced_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "BRFC_alpha_balanced_Easy_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "EEC_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "EEC_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "EEC_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "EEC_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "EEC_Easy_Run_0\n",
      "num_prec =  5\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "EEC_Easy_Run_1\n",
      "num_prec =  5\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_0_0_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_0_0_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_0_0_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_0_0_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_0_0_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_0_0_Easy_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_balanced_gamma_0_0_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_balanced_gamma_0_0_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_balanced_gamma_0_0_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_balanced_gamma_0_0_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_balanced_gamma_0_0_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_balanced_gamma_0_0_Easy_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_1_0_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_1_0_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_1_0_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_1_0_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_1_0_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_1_0_Easy_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_2_0_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_2_0_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_2_0_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_2_0_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_2_0_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_2_0_Easy_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_0_5_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_0_5_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_0_5_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_0_5_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_0_5_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_0_5_Easy_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_balanced_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_balanced_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_balanced_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_balanced_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_balanced_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "LogReg_alpha_balanced_Easy_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RFC_Hard_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RFC_Hard_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RFC_Medium_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RFC_Medium_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RFC_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RFC_Easy_Run_1\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RUSBoost_Hard_Run_0\n",
      "num_prec =  6\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RUSBoost_Hard_Run_1\n",
      "num_prec =  6\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RUSBoost_Medium_Run_0\n",
      "num_prec =  5\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RUSBoost_Medium_Run_1\n",
      "num_prec =  5\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RUSBoost_Easy_Run_0\n",
      "num_prec =  4\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "RUSBoost_Easy_Run_1\n",
      "num_prec =  5\n",
      "\n",
      "CPU times: user 28.7 s, sys: 3.38 s, total: 32.1 s\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Analyze_Results()\n",
    "# 5min 42s for one model\n",
    "# 13 * 6 = 78 models\n",
    "# 4h 42 min total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "276041bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(-5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd846b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_2_11",
   "language": "python",
   "name": "tensorflow_2_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
