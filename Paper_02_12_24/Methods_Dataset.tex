\subsection{Dataset}
\label{dataset}

Ideally, we would use a dataset of crashes that spawned an automated notification, but we have not found such a dataset that is publicly available.  Working with such a private dataset would be an important avenue of future research. (See \S \ref{simplifying_assumptions} for a list of simplifying assumptions and opportunities for future research.)

We will use the Crash Report Sampling System (CRSS) data from 2016 to 2021.  The CRSS is a curated sample of crashes in the US, weighted to more serious crashes such that 17\% of the crash persons needed an ambulance, significantly more than the proportion of all reported crashes needing an ambulance.  Since many low-speed crashes would have a crash profile similar to hard braking, they would not spawn an automated notification, so it is reasonable to assume that the set of crashes with automated notifications would have a higher percentage of persons needing an ambulance.  

We make some simplifying assumptions (see \S\ref{simplifying_assumptions}) using this dataset, including that the class ratio (N:P) in the automated crash notification from cell phones will be close to that in the CRSS data, 5:1, and that the crash persons in the CRSS data are representative of the future crash persons whose cell phones send a crash notification.  We will use the CRSS as a proxy for the set of crashes with automatic crash notifications, acknowledging that we do not know how good of a proxy it is. The primary merit of CRSS for our work is that it is publicly available so that our work can be critiqued, adapted, and expanded by others.  

To prepare the data we had to bin (discretize) some features and to impute missing data.  Some features in CRSS have both the original data with values signifying ``Missing'' or ``Unknown'' and a new feature with missing values imputed using IVEware \citep{IVEware}, but not all of the features we wanted to use had imputed values.  CRSS has a very useful document on the history of its imputation methods going back to 1988 with the predecessors of the current data set \citep{CRSS_Imputation}.  We debated the proper order of operations for binning and imputing, tried both, and decided to bin first, then impute.  We tried several methods of imputation, including the IVEware used by the CRSS authors, but got better results using a round-robin random forest method.  Full details and analysis are in the code, listed below.

We removed all crashes involving a pedestrian because deceleration profile of such a crash would be more like hard braking than hitting a large immovable object like a car or tree, so less likely to trigger an automated notification.  

The dataset is slightly imbalanced, with five elements of the negative class for each element of the positive class.  We considered several methods to handle the imbalance, including resampling, class weights, focal loss \citep{lin2017focal}, and balanced metrics.  We cannot use the popular SMOTE oversampling method because our data is categorical \citep{Chawla_2002}.  We tried undersampling with Tomek Links, but the resulting model results were not significantly different.  The best results came from using the model algorithms from Imbalanced-Learn \citep{Imblearn}, some of which apply bagging on top of algorithms from Scikit-Learn \citep{scikit-learn}.

After removing those pedestrian crashes we had 713,566 samples, each representing a crash person, and 78 relevant features.  For details, see these sections of code in the {\tt Keras} folder at 

\url{www.github.com/bburkman/Ambulance_Dispatch}.

\

\begin{tabular}{l}
	\verb|Ambulance_Dispatch_01_Get_Data.ipynb| \cr
	\verb|Ambulance_Dispatch_02_Correlation.ipynb| \cr
	\verb|Ambulance_Dispatch_03_Bin_Data.ipynb| \cr
	\verb|Ambulance_Dispatch_04_Impute_Missing_Data.ipynb| \cr
	\verb|Ambulance_Dispatch_05_IVEware_Order_of_Operations.ipynb| \cr
	\verb|Ambulance_Dispatch_06_Build_Models_Tomek_Links.ipynb| \cr
\end{tabular}


