\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\csgdef{mark@fnau1}{1}
\csgdef{mark@corau1}{1}
\emailauthor{bradburkman@gmail.com}{J. Bradford Burkman}
\urlauthor{http://www.github.com/bburkman/Ambulance_Dispatch}{J. Bradford Burkman}
\creditauthor{Conceptualization, Investigation, Writing - original draft, Visualization}{J. Bradford Burkman}
\creditauthor{Supervision, Methodology, Writing - review and editing}{Chee-Hung Henry Chu}
\creditauthor{Supervision, Methodology}{Miao Jin}
\creditauthor{Data curation, Writing - review and editing}{Xiaoduan Sun}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Scenario}{1}{subsection.1.1}\protected@file@percent }
\newlabel{intro_scenario}{{1.1}{1}{Scenario}{subsection.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \normalfont  \normalsize  Springfield before implementing immediate dispatch of ambulances. Figure accompanies \S  \ref  {intro_scenario}}}{2}{figure.1}\protected@file@percent }
\newlabel{intro_springfield_before}{{1}{2}{\normalfont \normalsize Springfield before implementing immediate dispatch of ambulances. Figure accompanies \S \ref {intro_scenario}}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \normalfont  \normalsize  Springfield after implementing immediate dispatch of ambulances. Figure accompanies \S  \ref  {intro_scenario}}}{3}{figure.2}\protected@file@percent }
\newlabel{intro_springfield_after}{{2}{3}{\normalfont \normalsize Springfield after implementing immediate dispatch of ambulances. Figure accompanies \S \ref {intro_scenario}}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \normalfont  \normalsize  Confusion matrix for ambulance dispatch. Figure accompanies \S  \ref  {intro_scenario}}}{3}{figure.3}\protected@file@percent }
\newlabel{intro_confusion}{{3}{3}{\normalfont \normalsize Confusion matrix for ambulance dispatch. Figure accompanies \S \ref {intro_scenario}}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \normalfont  \normalsize  Example model test results. Figure accompanies \S  \ref  {intro_scenario}}}{4}{figure.4}\protected@file@percent }
\newlabel{intro_ideal}{{4}{4}{\normalfont \normalsize Example model test results. Figure accompanies \S \ref {intro_scenario}}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Overview}{4}{subsection.1.2}\protected@file@percent }
\newlabel{intro_overview}{{1.2}{4}{Overview}{subsection.1.2}{}}
\citation{LIU2023103949}
\citation{LIU2016120}
\citation{NADAR2023106355}
\citation{13793173920190801}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Literature Review}{5}{subsection.1.3}\protected@file@percent }
\newlabel{lit_review}{{1.3}{5}{Literature Review}{subsection.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Smartphone}{5}{subsubsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Location Allocation}{5}{subsubsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}OnStar}{5}{subsubsection.1.3.3}\protected@file@percent }
\citation{KONONEN2011112}
\citation{13793173920190801}
\citation{15857782520170401}
\citation{BOSE20111048}
\citation{JAGTENBERG201527}
\citation{WEAVER20221057}
\citation{KONG2023106393}
\citation{CANDEFJORD2021101124}
\citation{ZHANG201697}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}AACN, not OnStar}{6}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Injury Prediction Models}{6}{subsubsection.1.4.1}\protected@file@percent }
\citation{BERTSIMAS2019557}
\citation{ZHEN2024103449}
\citation{GEUENS2010385}
\citation{GEUENS2010385}
\citation{SU2023103955}
\citation{QIN20121}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}General Dispatch Algorithms, not particularly for Crashes}{7}{subsection.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.1}Privacy}{7}{subsubsection.1.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.2}Coordinating Traffic Signals}{7}{subsubsection.1.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.3}Other}{7}{subsubsection.1.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{7}{section.2}\protected@file@percent }
\newlabel{sec:Methods}{{2}{7}{Methods}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \normalfont  \normalsize  Methods Graphical Abstract}}{8}{figure.5}\protected@file@percent }
\newlabel{methods_graphical_abstract}{{5}{8}{\normalfont \normalsize Methods Graphical Abstract}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Budgetary Decision Thresholds and Corresponding Metrics}{8}{subsection.2.1}\protected@file@percent }
\newlabel{political_decisions}{{2.1}{8}{Budgetary Decision Thresholds and Corresponding Metrics}{subsection.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \normalfont  \normalsize  Springfield after implementing immediate dispatch of ambulances. Figure accompanies \S  \ref  {intro_scenario}}}{8}{figure.6}\protected@file@percent }
\newlabel{methods_springfield_after}{{6}{8}{\normalfont \normalsize Springfield after implementing immediate dispatch of ambulances. Figure accompanies \S \ref {intro_scenario}}{figure.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Budgetary Decision Metric I: Percent Increased Number of Ambulance Calls}{8}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{political_decisions_percent_increased}{{2.1.1}{8}{Budgetary Decision Metric I: Percent Increased Number of Ambulance Calls}{subsubsection.2.1.1}{}}
\newlabel{eq:budget_1}{{1}{8}{Budgetary Decision Metric I: Percent Increased Number of Ambulance Calls}{equation.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Budgetary Decision Metric II: Percent of Immediately Dispatched Ambulances Actually Needed}{9}{subsubsection.2.1.2}\protected@file@percent }
\newlabel{political_decisions_precision}{{2.1.2}{9}{Budgetary Decision Metric II: Percent of Immediately Dispatched Ambulances Actually Needed}{subsubsection.2.1.2}{}}
\newlabel{eq:budget_2}{{2}{9}{Budgetary Decision Metric II: Percent of Immediately Dispatched Ambulances Actually Needed}{equation.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Budgetary Decision Metric III: Minimum Probability that Each Immediately Dispatched Ambulance is Needed}{9}{subsubsection.2.1.3}\protected@file@percent }
\newlabel{political_decisions_probability}{{2.1.3}{9}{Budgetary Decision Metric III: Minimum Probability that Each Immediately Dispatched Ambulance is Needed}{subsubsection.2.1.3}{}}
\newlabel{eq:budget_3}{{3}{9}{Budgetary Decision Metric III: Minimum Probability that Each Immediately Dispatched Ambulance is Needed}{equation.2.3}{}}
\newlabel{eq:ROC_slope}{{4}{9}{Budgetary Decision Metric III: Minimum Probability that Each Immediately Dispatched Ambulance is Needed}{equation.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Dataset}{9}{subsection.2.2}\protected@file@percent }
\newlabel{dataset}{{2.2}{9}{Dataset}{subsection.2.2}{}}
\citation{IVEware}
\citation{CRSS_Imputation}
\citation{lin2017focal}
\citation{KONG2023106393}
\citation{Chawla_2002}
\citation{Imblearn}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Choosing Features}{10}{subsection.2.3}\protected@file@percent }
\newlabel{features}{{2.3}{10}{Choosing Features}{subsection.2.3}{}}
\citation{KONONEN2011112,13793173920190801}
\citation{KONONEN2011112,13793173920190801}
\newlabel{Features_EMH}{{2.3}{11}{Choosing Features}{subsection.2.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \normalsize  \normalfont  Easy, Medium, and Hard Features. Table accompanies \S  \ref  {features}}}{11}{table.1}\protected@file@percent }
\citation{CRSS}
\citation{lin2017focal}
\newlabel{Features_Compare_He}{{2.3}{12}{Choosing Features}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \normalsize  \normalfont  Comparison with Features in Similar Papers on Vehicle-based Advanced Automatic Collision Notification systems like GM OnStar. \citep  {KONONEN2011112,13793173920190801} Table accompanies \S  \ref  {features}}}{12}{table.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Models}{12}{subsection.2.4}\protected@file@percent }
\newlabel{models}{{2.4}{12}{Models}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Binary Classification Algorithms and Hyperparameters}{12}{subsubsection.2.4.1}\protected@file@percent }
\newlabel{algorithms}{{2.4.1}{12}{Binary Classification Algorithms and Hyperparameters}{subsubsection.2.4.1}{}}
\newlabel{models}{{2.4.1}{13}{Binary Classification Algorithms and Hyperparameters}{subsubsection.2.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \normalsize  \normalfont  Models Tested for Recommendation System. Table accompanies \S  \ref  {algorithms}}}{13}{table.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Hyperparameter Effects}{13}{subsubsection.2.4.2}\protected@file@percent }
\newlabel{hyperparameters}{{2.4.2}{13}{Hyperparameter Effects}{subsubsection.2.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \normalfont  \normalsize  Histograms of $p$ results for KerasClassifier with Different Hyperparameters, with ROC AUC values for Two Model Runs with Different Random Seeds. Figure accompanies \S  \ref  {hyperparameters}}}{13}{figure.7}\protected@file@percent }
\newlabel{hyperparameters_figure}{{7}{13}{\normalfont \normalsize Histograms of $p$ results for KerasClassifier with Different Hyperparameters, with ROC AUC values for Two Model Runs with Different Random Seeds. Figure accompanies \S \ref {hyperparameters}}{figure.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Five-Fold Cross Validation}{14}{subsubsection.2.4.3}\protected@file@percent }
\newlabel{cross_validation}{{2.4.3}{14}{Five-Fold Cross Validation}{subsubsection.2.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}Interpreting Supervised Learning Binary Classification Results}{14}{subsubsection.2.4.4}\protected@file@percent }
\newlabel{interpreting_ideal}{{2.4.4}{14}{Interpreting Supervised Learning Binary Classification Results}{subsubsection.2.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \normalfont  \normalsize  Example Model Results. Figure accompanies \S  \ref  {interpreting_ideal}}}{14}{figure.8}\protected@file@percent }
\newlabel{ideal}{{8}{14}{\normalfont \normalsize Example Model Results. Figure accompanies \S \ref {interpreting_ideal}}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.5}Comparing Outputs of Different Models}{14}{subsubsection.2.4.5}\protected@file@percent }
\newlabel{comparing_outputs}{{2.4.5}{14}{Comparing Outputs of Different Models}{subsubsection.2.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \normalfont  \normalsize  Raw Model Outputs. Figure accompanies \S  \ref  {comparing_outputs}}}{16}{figure.9}\protected@file@percent }
\newlabel{raw_output_figure}{{9}{16}{\normalfont \normalsize Raw Model Outputs. Figure accompanies \S \ref {comparing_outputs}}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Interpreting Model Results}{16}{subsection.2.5}\protected@file@percent }
\newlabel{interpreting}{{2.5}{16}{Interpreting Model Results}{subsection.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Finding $\theta $ for Each Budgetary Decision Metric}{16}{subsubsection.2.5.1}\protected@file@percent }
\newlabel{finding_theta}{{2.5.1}{16}{Finding $\theta $ for Each Budgetary Decision Metric}{subsubsection.2.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces  \normalsize  \normalfont  Metrics on $p$ Output of Random Forest Classifier on the Hard Features. Table accompanies \S  \ref  {finding_theta} }}{17}{table.4}\protected@file@percent }
\newlabel{RFC_Hard_0_Slices}{{4}{17}{\normalsize \normalfont Metrics on $p$ Output of Random Forest Classifier on the Hard Features. Table accompanies \S \ref {finding_theta}}{table.4}{}}
\newlabel{eq:delta_p}{{5}{17}{Finding $\theta $ for Each Budgetary Decision Metric}{equation.2.5}{}}
\newlabel{eq:delta_p_2}{{6}{18}{Finding $\theta $ for Each Budgetary Decision Metric}{equation.2.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces  \normalsize  \normalfont  Metrics on $p$ Output of Random Forest Classifier on the Hard Features with Minimum of 50 Elements of Each Class in Each Band. Table accompanies \S  \ref  {finding_theta} }}{19}{table.5}\protected@file@percent }
\newlabel{RFC_Hard_50_Slices}{{5}{19}{\normalsize \normalfont Metrics on $p$ Output of Random Forest Classifier on the Hard Features with Minimum of 50 Elements of Each Class in Each Band. Table accompanies \S \ref {finding_theta}}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces  \normalsize  \normalfont  Metrics on $p$ Output of Random Forest Classifier on the Hard Features with Minimum of 6400 Elements of Each Class in Each Band. Table accompanies \S  \ref  {finding_theta} }}{20}{table.6}\protected@file@percent }
\newlabel{RFC_Hard_6400_Slices}{{6}{20}{\normalsize \normalfont Metrics on $p$ Output of Random Forest Classifier on the Hard Features with Minimum of 6400 Elements of Each Class in Each Band. Table accompanies \S \ref {finding_theta}}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces  \normalsize  \normalfont  Metrics on $p$ Output of Random Forest Classifier on the Hard Features with Minimum of 100 Elements of Each Class in Each Band. Table accompanies \S  \ref  {finding_theta} }}{21}{table.7}\protected@file@percent }
\newlabel{RFC_Hard_100_Slices}{{7}{21}{\normalsize \normalfont Metrics on $p$ Output of Random Forest Classifier on the Hard Features with Minimum of 100 Elements of Each Class in Each Band. Table accompanies \S \ref {finding_theta}}{table.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces  \normalsize  \normalfont  Smoothing $m$Prob with Rolling Sums of Different Window Sizes. Table accompanies \S  \ref  {finding_theta} }}{22}{table.8}\protected@file@percent }
\newlabel{RFC_Hard_Run_0_Round_4_Rolling_Intervals}{{8}{22}{\normalsize \normalfont Smoothing $m$Prob with Rolling Sums of Different Window Sizes. Table accompanies \S \ref {finding_theta}}{table.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Choosing the Best Model for each Budgetary Decision Metric}{22}{subsubsection.2.5.2}\protected@file@percent }
\newlabel{choosing_model}{{2.5.2}{22}{Choosing the Best Model for each Budgetary Decision Metric}{subsubsection.2.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces \normalfont  \normalsize  Comparing Models: Best results for each algorithm on the Hard features for budgetary criterion $\text  {FP}/\text  {P}$ closest to $0.05$. Table accompanies \S  \ref  {choosing_model}}}{23}{table.9}\protected@file@percent }
\newlabel{FP_P_0_05_hard}{{9}{23}{\normalfont \normalsize Comparing Models: Best results for each algorithm on the Hard features for budgetary criterion $\text {FP}/\text {P}$ closest to $0.05$. Table accompanies \S \ref {choosing_model}}{table.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.3}Detecting Model Failure}{23}{subsubsection.2.5.3}\protected@file@percent }
\newlabel{Methods_Model_Failure}{{2.5.3}{23}{Detecting Model Failure}{subsubsection.2.5.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces \normalfont  \normalsize  Model Failure: Balanced Bagging Algorithm on the Hard Features with FP/P closest to 0.05. Table accompanies \S  \ref  {Methods_Model_Failure}}}{24}{table.10}\protected@file@percent }
\newlabel{BalBag_Hard_0_Slices}{{10}{24}{\normalfont \normalsize Model Failure: Balanced Bagging Algorithm on the Hard Features with FP/P closest to 0.05. Table accompanies \S \ref {Methods_Model_Failure}}{table.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces  \normalsize  \normalfont  Metrics on Partial $p$ Output of Random Forest Classifier on the Medium Features with Minimum of 400 Elements of Each Class in Each Band. Table accompanies \S  \ref  {Methods_Model_Failure} }}{25}{table.11}\protected@file@percent }
\newlabel{RFC_Medium_400_Slices}{{11}{25}{\normalsize \normalfont Metrics on Partial $p$ Output of Random Forest Classifier on the Medium Features with Minimum of 400 Elements of Each Class in Each Band. Table accompanies \S \ref {Methods_Model_Failure}}{table.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \normalfont  \normalsize  Random Forest Classifier on the Medium Features (top) and Example model (bottom). Figure accompanies \S  \ref  {Methods_Model_Failure}}}{25}{figure.10}\protected@file@percent }
\newlabel{RFC_Medium_Zoom_Figure}{{10}{25}{\normalfont \normalsize Random Forest Classifier on the Medium Features (top) and Example model (bottom). Figure accompanies \S \ref {Methods_Model_Failure}}{figure.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.4}Numerical Precision}{25}{subsubsection.2.5.4}\protected@file@percent }
\newlabel{Numerical_Precision}{{2.5.4}{25}{Numerical Precision}{subsubsection.2.5.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces  \normalsize  \normalfont  Comparison of values of $p$, TP, FP, and FP/P between Runs of the Same Model with Different Random Seeds. Table accompanies \S  \ref  {Methods_Model_Failure} }}{26}{table.12}\protected@file@percent }
\newlabel{FP_P_0_05_Numerical_Precision}{{12}{26}{\normalsize \normalfont Comparison of values of $p$, TP, FP, and FP/P between Runs of the Same Model with Different Random Seeds. Table accompanies \S \ref {Methods_Model_Failure}}{table.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{26}{section.3}\protected@file@percent }
\newlabel{Results}{{3}{26}{Results}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data and Image Files}{26}{subsection.3.1}\protected@file@percent }
\newlabel{data_files}{{3.1}{26}{Data and Image Files}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Easy, Medium, and Hard Features}{27}{subsection.3.2}\protected@file@percent }
\newlabel{results_EMH}{{3.2}{27}{Easy, Medium, and Hard Features}{subsection.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \normalfont  \normalsize  Balanced Random Forest Classifier with $\alpha = 0.5$ Model Results for Different Sets of Data Features. Figure accompanies \S  \ref  {results_EMH}}}{27}{figure.11}\protected@file@percent }
\newlabel{EMH_BRFC}{{11}{27}{\normalfont \normalsize Balanced Random Forest Classifier with $\alpha = 0.5$ Model Results for Different Sets of Data Features. Figure accompanies \S \ref {results_EMH}}{figure.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces \normalfont  \normalsize  Best models and transformations for $\text  {FP}/\text  {P} = 0.05$ for each algorithm. Table accompanies \S  \ref  {results_best_model}}}{28}{table.13}\protected@file@percent }
\newlabel{FP_P_0_05_Results}{{13}{28}{\normalfont \normalsize Best models and transformations for $\text {FP}/\text {P} = 0.05$ for each algorithm. Table accompanies \S \ref {results_best_model}}{table.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Best Model for Each Budgetary Criterion and Feature Set}{28}{subsection.3.3}\protected@file@percent }
\newlabel{results_best_model}{{3.3}{28}{Best Model for Each Budgetary Criterion and Feature Set}{subsection.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces \normalfont  \normalsize  Best models and transformations for $\text  {Precision} = \text  {TP} / (\text  {FP} + \text  {TP}) = 2/3$ for each algorithm. Table accompanies \S  \ref  {results_best_model}}}{29}{table.14}\protected@file@percent }
\newlabel{Prec_0_667_Results}{{14}{29}{\normalfont \normalsize Best models and transformations for $\text {Precision} = \text {TP} / (\text {FP} + \text {TP}) = 2/3$ for each algorithm. Table accompanies \S \ref {results_best_model}}{table.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces \normalfont  \normalsize  Best models for $m\text  {Prob}= \text  {Pos}/(\text  {Neg} + \text  {Pos}) \approx 0.5$ for each algorithm with length of rolling sum. Table accompanies \S  \ref  {results_best_model}}}{30}{table.15}\protected@file@percent }
\newlabel{mProb_0_5_Results}{{15}{30}{\normalfont \normalsize Best models for $m\text {Prob}= \text {Pos}/(\text {Neg} + \text {Pos}) \approx 0.5$ for each algorithm with length of rolling sum. Table accompanies \S \ref {results_best_model}}{table.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions and Discussion}{30}{section.4}\protected@file@percent }
\newlabel{conclusions}{{4}{30}{Conclusions and Discussion}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Scenario Reprise}{30}{subsection.4.1}\protected@file@percent }
\newlabel{scenario_reprise}{{4.1}{30}{Scenario Reprise}{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \normalfont  \normalsize  Confusion matrix for ambulance dispatch. Figure accompanies \S  \ref  {intro_scenario}}}{30}{figure.12}\protected@file@percent }
\newlabel{intro_confusion}{{12}{30}{\normalfont \normalsize Confusion matrix for ambulance dispatch. Figure accompanies \S \ref {intro_scenario}}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \normalfont  \normalsize  Springfield after implementing immediate dispatch of ambulances. Figure accompanies \S  \ref  {scenario_reprise}}}{31}{figure.13}\protected@file@percent }
\newlabel{intro_springfield_conclusion}{{13}{31}{\normalfont \normalsize Springfield after implementing immediate dispatch of ambulances. Figure accompanies \S \ref {scenario_reprise}}{figure.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Discussion}{31}{subsection.4.2}\protected@file@percent }
\bibstyle{cas-model2-names}
\bibdata{Ambulance_Dispatch.bib}
\@writefile{toc}{\contentsline {section}{\numberline {5}Simplifying Assumptions and Opportunities for Future Research}{32}{section.5}\protected@file@percent }
\newlabel{simplifying_assumptions}{{5}{32}{Simplifying Assumptions and Opportunities for Future Research}{section.5}{}}
\bibcite{BERTSIMAS2019557}{{1}{2019}{{Bertsimas and Ng}}{{}}}
\bibcite{BOSE20111048}{{2}{2011}{{Bose et~al.}}{{Bose, Crandall, McGwin, Goldman, Foster and Fine}}}
\bibcite{CANDEFJORD2021101124}{{3}{2021}{{Candefjord et~al.}}{{Candefjord, {Sheikh Muhammad}, Bangalore and Buendia}}}
\bibcite{Chawla_2002}{{4}{2002}{{Chawla et~al.}}{{Chawla, Bowyer, Hall and Kegelmeyer}}}
\bibcite{GEUENS2010385}{{5}{2010}{{Geuens and Dumortier}}{{}}}
\bibcite{13793173920190801}{{6}{2019}{{He et~al.}}{{He, Zhang and Wang}}}
\bibcite{CRSS_Imputation}{{7}{2019}{{Herbert}}{{}}}
\bibcite{JAGTENBERG201527}{{8}{2015}{{Jagtenberg et~al.}}{{Jagtenberg, Bhulai and {van der Mei}}}}
\bibcite{KONG2023106393}{{9}{2023}{{Kong et~al.}}{{Kong, Lee, Kim, Lee, Kang, Choi, Kim, Jeong, Kang and Sung}}}
\bibcite{KONONEN2011112}{{10}{2011}{{Kononen et~al.}}{{Kononen, Flannagan and Wang}}}
\bibcite{Imblearn}{{11}{2017}{{Lema{{\^i}}tre et~al.}}{{Lema{{\^i}}tre, Nogueira and Aridas}}}
\bibcite{lin2017focal}{{12}{2017}{{Lin et~al.}}{{Lin, Goyal, Girshick, He and Doll{\'a}r}}}
\bibcite{LIU2023103949}{{13}{2023}{{Liu et~al.}}{{Liu, Racz, Vaillancourt, Michelman, Barnes, Mellem, Eastham, Green, Armstrong, Bal, O’Banion and Guo}}}
\bibcite{LIU2016120}{{14}{2016}{{Liu et~al.}}{{Liu, Li, Liu and Patel}}}
\bibcite{NADAR2023106355}{{15}{2023}{{Nadar et~al.}}{{Nadar, Jha and Thakkar}}}
\bibcite{CRSS}{{16}{2016-2020}{{NHTSA}}{{}}}
\bibcite{scikit-learn}{{17}{2011}{{Pedregosa et~al.}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot and Duchesnay}}}
\bibcite{15857782520170401}{{18}{2017}{{Plevin et~al.}}{{Plevin, Kaufman, Fraade-Blanar and Bulger}}}
\bibcite{QIN20121}{{19}{2012}{{Qin and Khan}}{{}}}
\bibcite{IVEware}{{20}{}{{Raghunathan et~al.}}{{Raghunathan, Solenberger, Berglund and van Hoewyk}}}
\bibcite{SU2023103955}{{21}{2023}{{Su et~al.}}{{Su, Zhong, Chow, Dey and Jin}}}
\bibcite{WEAVER20221057}{{22}{2022}{{Weaver et~al.}}{{Weaver, Talton, Barnard, Gaffley, Doud, Schoell, Petty, Martin, Meredith and Stitzel}}}
\bibcite{ZHANG201697}{{23}{2016}{{Zhang et~al.}}{{Zhang, He, Gou and Li}}}
\csxdef{lastpage}{34}
\gdef \@abspage@last{36}
