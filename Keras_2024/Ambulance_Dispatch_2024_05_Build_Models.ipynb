{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767154e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\tableofcontents\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea489d64",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa423799",
   "metadata": {},
   "source": [
    "- We will build models reflecting three levels of available data\n",
    "    - \"Easy\" is mostly data already available to the emergency dispatcher before the notification comes in, like month, day of week, hour, weather, urban/rural, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e1d2b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7d47d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122b4fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install Packages\n",
      "Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:51:49) [Clang 16.0.6 ]\n",
      "NumPy version: 1.26.4\n",
      "SciPy version:  1.13.1\n",
      "TensorFlow version:  2.16.2\n",
      "Keras version:  3.4.1\n",
      "Pandas version:  2.2.2\n",
      "SciKit-Learn version: 1.5.0\n",
      "Imbalanced-Learn version: 0.12.3\n",
      "random_seed = 123\n",
      "Finished Installing Packages\n"
     ]
    }
   ],
   "source": [
    "print ('Install Packages')\n",
    "\n",
    "import sys, copy, math, time, os\n",
    "\n",
    "print ('Python version: {}'.format(sys.version))\n",
    "\n",
    "#from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import scipy as sc\n",
    "print ('SciPy version:  {}'.format(sc.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print ('TensorFlow version:  {}'.format(tf.__version__))\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "from tensorflow import keras\n",
    "print ('Keras version:  {}'.format(keras.__version__))\n",
    "\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "#from keras.layers import IntegerLookup\n",
    "#from keras.layers import Normalization\n",
    "#from keras.layers import StringLookup\n",
    "#from keras.utils import get_custom_objects\n",
    "#from keras.utils import tf_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import callbacks\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import pandas as pd\n",
    "print ('Pandas version:  {}'.format(pd.__version__))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "#    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Library for reading Microsoft Access files\n",
    "#import pandas_access as mdb\n",
    "\n",
    "import sklearn\n",
    "print ('SciKit-Learn version: {}'.format(sklearn.__version__))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import imblearn\n",
    "print ('Imbalanced-Learn version: {}'.format(imblearn.__version__))\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "#!pip install pydot\n",
    "\n",
    "# Set Randomness.  Copied from https://www.kaggle.com/code/abazdyrev/keras-nn-focal-loss-experiments\n",
    "import random\n",
    "random_seed = 123\n",
    "print ('random_seed =', random_seed)\n",
    "np.random.seed(random_seed) # NumPy\n",
    "random.seed(random_seed) # Python\n",
    "tf.random.set_seed(random_seed) # Tensorflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print ('Finished Installing Packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437f109",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919fb2db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Get_Data(filename):\n",
    "    print ('Get_Data()')\n",
    "    data = pd.read_csv(filename, low_memory=False)\n",
    "        \n",
    "        \n",
    "    print ('data.shape: ', data.shape)\n",
    "    print ('End Get_Data()')\n",
    "    print ()\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3917b",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49200a4f",
   "metadata": {},
   "source": [
    "# Five-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536ee811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Five_Fold_Cross_Validation(data, model, filename, title):\n",
    "    print ()\n",
    "    print ('------------------------')\n",
    "    print ()\n",
    "    print (filename)\n",
    "    print ()\n",
    "    \n",
    "    target = 'HOSPITAL'\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = random.randint(1,100))\n",
    "    target_column = data.loc[:,target]\n",
    "    y_test = []\n",
    "    y_proba = []\n",
    "    y_pred = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for train_index, test_index in skf.split(data, target_column):\n",
    "        print ('K-fold iteration = ', iteration)\n",
    "        iteration += 1\n",
    "        \n",
    "#        print ('len(train_index) = ', len(train_index))\n",
    "#        print (train_index)\n",
    "#        print ('len(test_index) = ', len(test_index))\n",
    "#        print (test_index)\n",
    "        \n",
    "        train_fold = data.iloc[train_index]\n",
    "#        print ()\n",
    "#        print ('train_fold')\n",
    "#        display(train_fold)\n",
    "        \n",
    "        test_fold = data.iloc[test_index]\n",
    "#        print ()\n",
    "#        print ('test_fold')\n",
    "#        display(test_fold)\n",
    "#        print ('type(test_fold) = ', type(test_fold))\n",
    "        \n",
    "        \n",
    "        X_train_fold = train_fold.drop(columns=[target])\n",
    "        X_test_fold = test_fold.drop(columns=[target])\n",
    "        y_train_fold = train_fold[target].squeeze()        \n",
    "        y_test_fold = test_fold[target].squeeze()\n",
    "#        print ('type(y_test_fold) = ', type(y_test_fold))\n",
    "        \n",
    "#        print ()\n",
    "        model.fit(X_train_fold, y_train_fold.values.ravel())\n",
    "        y_proba_fold = model.predict_proba(X_test_fold)\n",
    "        y_proba_fold = [x[1] for x in y_proba_fold]\n",
    "        y_pred_fold = list(np.around(np.array(y_proba_fold),0))\n",
    "        \n",
    "        ###\n",
    "#        print ('X_train_fold')\n",
    "#        display(X_train_fold)\n",
    "#        print ('y_train_fold')\n",
    "#        display(y_train_fold)\n",
    "#        print ('y_train_fold.value_counts()')\n",
    "#        display(y_train_fold.value_counts())\n",
    "#        print ('y_proba_fold')\n",
    "#        print (y_proba_fold)\n",
    "#        ###\n",
    "#        \n",
    "        y_test = y_test + y_test_fold.to_list()\n",
    "        y_proba = y_proba + y_proba_fold\n",
    "#        print ('len(y_proba) = ', len(y_proba))\n",
    "        y_pred = y_pred + y_pred_fold\n",
    "\n",
    "    y_test = np.array(y_test)\n",
    "    y_proba = np.array(y_proba)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    DF = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    DF['y_proba'] = y_proba\n",
    "    DF['y_pred'] = y_pred\n",
    "    DF.to_csv('../../Big_Files/CRSS_05_' + filename + '.csv')\n",
    "#    print (DF)\n",
    "    \n",
    "    \n",
    "#    Chart_and_Plots(y_test, y_proba, y_pred, filename, title)\n",
    "    \n",
    "    \n",
    "    print ()\n",
    "#    return model    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2658775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def BRFC_5_Fold(data, target, alpha, filename):\n",
    "     \n",
    "    title = ''\n",
    "    model = BalancedRandomForestClassifier(\n",
    "        bootstrap = True, ccp_alpha = 0.0, criterion = 'gini', \n",
    "        max_depth = None,\n",
    "#        max_depth = 40, \n",
    "        max_features = 'sqrt', \n",
    "        max_leaf_nodes = None,\n",
    "#        max_leaf_nodes = 10000,  \n",
    "        max_samples = None, \n",
    "        min_impurity_decrease = 0.0, \n",
    "        min_samples_leaf = 1, \n",
    "        min_samples_split = 2, \n",
    "        min_weight_fraction_leaf = 0.0, \n",
    "        n_estimators = 100, \n",
    "#        n_estimators = 1000, \n",
    "        n_jobs = None, \n",
    "        oob_score = False, \n",
    "        random_state = random.randint(1,100), \n",
    "        replacement = False, \n",
    "        sampling_strategy = 'auto', \n",
    "        verbose = 0, \n",
    "        warm_start = False,\n",
    "        class_weight = {0:1-alpha, 1:alpha}\n",
    "    )\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae040db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFC_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    model = RandomForestClassifier(max_depth=2, random_state = random.randint(1,100))\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac53d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    model = AdaBoostClassifier(n_estimators=100, random_state = random.randint(1,100))\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855780c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RUSBoost_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    estimator = DecisionTreeClassifier(\n",
    "        max_depth=1,\n",
    "#        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )    \n",
    "    model = RUSBoostClassifier(\n",
    "        n_estimators=1000, \n",
    "        estimator=estimator,\n",
    "        algorithm='SAMME.R', \n",
    "        random_state = random.randint(1,100)\n",
    "    )\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8dac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BalancedBagging_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    model = BalancedBaggingClassifier(\n",
    "        random_state = random.randint(1,100)\n",
    "    )\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff286004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EasyEnsemble_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    estimator = AdaBoostClassifier(n_estimators=10, random_state = random.randint(1,100))\n",
    "    model = EasyEnsembleClassifier(n_estimators=10, estimator=estimator, random_state = random.randint(1,100))\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a00e6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_5_Fold(data, target, alpha, filename):\n",
    "    title = ''\n",
    "    model = LogisticRegression(\n",
    "#        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)}\n",
    "        class_weight = {0:1-alpha, 1:alpha},\n",
    "        max_iter=1000,\n",
    "        random_state = random.randint(1,100),\n",
    "    )\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f39874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KBFC_5_Fold(data, target, alpha, gamma, filename):\n",
    "    print ()\n",
    "    print ('------------------------')\n",
    "    print ()\n",
    "    print (filename)\n",
    "    print ()\n",
    "    \n",
    "    target = 'HOSPITAL'\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state  = random.randint(1,100))\n",
    "    target_column = data.loc[:,target]\n",
    "    y_test = []\n",
    "    y_proba = []\n",
    "    y_pred = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for train_index, test_index in skf.split(data, target_column):\n",
    "        print ()\n",
    "        print ()\n",
    "        print ('K-fold iteration = ', iteration)\n",
    "        iteration += 1\n",
    "        \n",
    "#        print ('len(train_index) = ', len(train_index))\n",
    "#        print (train_index)\n",
    "#        print ('len(test_index) = ', len(test_index))\n",
    "#        print (test_index)\n",
    "        \n",
    "        train_fold = data.iloc[train_index]\n",
    "#        print ()\n",
    "#        print ('train_fold')\n",
    "#        display(train_fold)\n",
    "        \n",
    "        test_fold = data.iloc[test_index]\n",
    "#        print ()\n",
    "#        print ('test_fold')\n",
    "#        display(test_fold)\n",
    "#        print ('type(test_fold) = ', type(test_fold))\n",
    "        \n",
    "        \n",
    "        X_train_fold = train_fold.drop(columns=[target])\n",
    "        X_test_fold = test_fold.drop(columns=[target])\n",
    "        y_train_fold = train_fold[target].squeeze()        \n",
    "        y_test_fold = test_fold[target].squeeze()\n",
    "#        print ('type(y_test_fold) = ', type(y_test_fold))\n",
    "\n",
    "#        print ('len(X_train_fold) = ', len(X_train_fold))\n",
    "#        print ('len(X_test_fold) = ', len(X_test_fold))\n",
    "#        print ('len(y_train_fold) = ', len(y_train_fold))\n",
    "#        print ('len(y_test_fold) = ', len(y_test_fold))\n",
    "#        print ()\n",
    "        \n",
    "#        print ()\n",
    "\n",
    "        loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "            apply_class_balancing=True,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "    #        from_logits=False,\n",
    "    #        label_smoothing=0.0,\n",
    "    #        axis=-1,\n",
    "    #        reduction=losses_utils.ReductionV2.AUTO,\n",
    "    #        name='binary_focal_crossentropy'\n",
    "        )   \n",
    "    \n",
    "        # create model\n",
    "        model = Sequential()\n",
    "#        print ('data.shape = ', data.shape, data.shape[-1])\n",
    "        model.add(Dense(60, input_shape=(data.shape[-1]-1,), activation='relu'))\n",
    "#        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))    \n",
    "        # Compile model\n",
    "        metrics = [\n",
    "            keras.metrics.Precision(name=\"precision\"),\n",
    "            keras.metrics.Recall(name=\"recall\"),\n",
    "    #        F1_Metric,\n",
    "        ]\n",
    "        model.compile(loss=loss_function, optimizer=tf.keras.optimizers.Adam(), metrics=metrics)\n",
    "        \n",
    "        earlystopping = callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        estimator = KerasClassifier(\n",
    "            model=model, \n",
    "            random_state = random.randint(1,100),\n",
    "            metrics=metrics,\n",
    "            batch_size=128, \n",
    "            verbose=2,\n",
    "            epochs=20,\n",
    "            callbacks=[earlystopping]\n",
    "        )\n",
    "    \n",
    "        estimator.fit(X_train_fold, y_train_fold.values.ravel())\n",
    "        y_proba_fold = estimator.predict_proba(X_test_fold)\n",
    "        y_proba_fold = [x[1] for x in y_proba_fold]\n",
    "        print ('len(y_proba_fold) = ', len(y_proba_fold))\n",
    "        y_pred_fold = list(np.around(np.array(y_proba_fold),0))\n",
    "        \n",
    "        ###\n",
    "#        print ('X_train_fold')\n",
    "#        display(X_train_fold.head())\n",
    "#        print ('y_train_fold')\n",
    "#        display(y_train_fold.head())\n",
    "#        print ('y_train_fold.value_counts()')\n",
    "#        display(y_train_fold.value_counts())\n",
    "#        print ('X_test_fold')\n",
    "#        display(X_test_fold.head())\n",
    "#        print ('y_test_fold')\n",
    "#        display(y_test_fold.head())\n",
    "#        print ('y_test_fold.value_counts()')\n",
    "#        display(y_test_fold.value_counts())\n",
    "#        print ('y_proba_fold')\n",
    "#        print (y_proba_fold[:10])\n",
    "#        ###\n",
    "#        \n",
    "        y_test = y_test + y_test_fold.to_list()\n",
    "        y_proba = y_proba + y_proba_fold\n",
    "#        print ('len(y_proba) = ', len(y_proba))\n",
    "        y_pred = y_pred + y_pred_fold\n",
    "\n",
    "    y_test = np.array(y_test)\n",
    "    y_proba = np.array(y_proba)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    DF = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    DF['y_proba'] = y_proba\n",
    "    DF['y_pred'] = y_pred\n",
    "    print ('Length before dropna(): ',len(DF))\n",
    "    DF.dropna(inplace=True)\n",
    "    print ('Length after dropna(): ',len(DF))\n",
    "    DF.to_csv('../../Big_Files/' + filename + '.csv')\n",
    "    \n",
    "#    Chart_and_Plots(y_test, y_proba, y_pred, filename, '')\n",
    "    \n",
    "    \n",
    "    print ()\n",
    "#    return model    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52566066",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72178501",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Build_Models(Features, run):\n",
    "    read_filename = '../../Big_Files/CRSS_04' + run + '_' + Features + '.csv'\n",
    "    print ('random_seed = %d' % random_seed)\n",
    "    data = Get_Data(read_filename)\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    write_filename_features = run + '_' + Features\n",
    "    \n",
    "    y = data[target]\n",
    "    N = len(y)\n",
    "    n = len(y[y==1])\n",
    "#    p = (N-n)/n\n",
    "#    alpha_balanced = p/(p+1)\n",
    "    alpha_balanced = 1 - n/N\n",
    "#    print ('p = ', p)\n",
    "    print ('alpha_balanced = ', alpha_balanced)    \n",
    "\n",
    "    \"\"\"\n",
    "    filename = 'RFC' + write_filename_features\n",
    "    RFC_5_Fold(data, target, filename)\n",
    "    \"\"\"\n",
    "    \n",
    "    alphas = [\n",
    "#        [0.5, '_0_5'],\n",
    "#        [0.6, '_0_6'],\n",
    "#        [0.7, '_0_7'],\n",
    "#        [0.8, '_0_8'],\n",
    "#        [0.85, '_0_85'],\n",
    "#        [0.90, '_0_9'],\n",
    "#        [0.95, '_0_95'],\n",
    "    ]\n",
    "    for alpha, alpha_string in alphas:\n",
    "        filename = 'BRFC_alpha' + alpha_string + write_filename_features\n",
    "        BRFC_5_Fold(data, target, alpha, filename)\n",
    "    \n",
    "    \"\"\"\n",
    "    alpha = 0.5\n",
    "    filename = 'LogReg_alpha_0_5' + write_filename_features\n",
    "    LogisticRegression_5_Fold(data, target, alpha, filename)\n",
    "\n",
    "    alpha = alpha_balanced\n",
    "    filename = 'LogReg_alpha_balanced' + write_filename_features\n",
    "    LogisticRegression_5_Fold(data, target, alpha, filename)\n",
    "\n",
    "    AdaBoost_5_Fold(data, target, 'AdaBoost' + write_filename_features)\n",
    "    BalancedBagging_5_Fold(data, target, 'BalBag' + write_filename_features)\n",
    "    EasyEnsemble_5_Fold(data, target, 'EEC' + write_filename_features)\n",
    "    RUSBoost_5_Fold(data, target, 'RUSBoost' + write_filename_features)\n",
    "    \"\"\"\n",
    "    \n",
    "    KBFC = [\n",
    "        [0.5, '_alpha_0_5', 0.0, '_gamma_0_0'],\n",
    "#        [alpha_balanced, '_alpha_balanced', 0.0, '_gamma_0_0'],\n",
    "#        [0.5, '_alpha_0_5', 1.0, '_gamma_1_0'],\n",
    "#        [0.5, '_alpha_0_5', 2.0, '_gamma_2_0'],\n",
    "    ]\n",
    "    for alpha, alpha_str, gamma, gamma_str in KBFC:\n",
    "        filename = 'KBFC' + alpha_str + gamma_str + write_filename_features\n",
    "        KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e23c1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "Run =  _0_0_1_0_1\n",
      "random_seed =  0\n",
      "random_seed = 0\n",
      "Get_Data()\n",
      "data.shape:  (802700, 142)\n",
      "End Get_Data()\n",
      "\n",
      "alpha_balanced =  0.8427108508782858\n",
      "\n",
      "------------------------\n",
      "\n",
      "KBFC_alpha_0_5_gamma_0_0_0_0_1_0_1_Hard\n",
      "\n",
      "\n",
      "\n",
      "K-fold iteration =  0\n",
      "Epoch 1/20\n",
      "5017/5017 - 90s - 18ms/step - loss: 0.1880 - precision: 0.6339 - recall: 0.1124\n",
      "Epoch 2/20\n",
      "5017/5017 - 91s - 18ms/step - loss: 0.1837 - precision: 0.6378 - recall: 0.1470\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:34\u001b[0m\n",
      "Cell \u001b[0;32mIn[13], line 59\u001b[0m, in \u001b[0;36mBuild_Models\u001b[0;34m(Features, run)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha, alpha_str, gamma, gamma_str \u001b[38;5;129;01min\u001b[39;00m KBFC:\n\u001b[1;32m     58\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKBFC\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m alpha_str \u001b[38;5;241m+\u001b[39m gamma_str \u001b[38;5;241m+\u001b[39m write_filename_features\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mKBFC_5_Fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 95\u001b[0m, in \u001b[0;36mKBFC_5_Fold\u001b[0;34m(data, target, alpha, gamma, filename)\u001b[0m\n\u001b[1;32m     78\u001b[0m earlystopping \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     79\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     82\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m estimator \u001b[38;5;241m=\u001b[39m KerasClassifier(\n\u001b[1;32m     86\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[1;32m     87\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m100\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[earlystopping]\n\u001b[1;32m     93\u001b[0m )\n\u001b[0;32m---> 95\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m y_proba_fold \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_fold)\n\u001b[1;32m     97\u001b[0m y_proba_fold \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m y_proba_fold]\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/scikeras/wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[1;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/scikeras/wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/scikeras/wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_keras_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/scikeras/wrappers.py:533\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tensorflow_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_state):\n\u001b[0;32m--> 533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:810\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_functions_eagerly:\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, tf_function_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# place.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:121\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m--> 121\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    125\u001b[0m     outputs,\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    127\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    128\u001b[0m )\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1669\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1672\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3263\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4061\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4060\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:810\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_functions_eagerly:\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, tf_function_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# place.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:108\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:70\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_weights:\n\u001b[1;32m     69\u001b[0m     trainable_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_weights\n\u001b[0;32m---> 70\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, trainable_weights))\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1066\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1061\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1062\u001b[0m           output_gradients))\n\u001b[1;32m   1063\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1064\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1066\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1075\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:148\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py:267\u001b[0m, in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;129m@ops\u001b[39m\u001b[38;5;241m.\u001b[39mRegisterGradient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_MeanGrad\u001b[39m(op: ops\u001b[38;5;241m.\u001b[39mOperation, grad):\n\u001b[1;32m    266\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Gradient for Mean.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   sum_grad \u001b[38;5;241m=\u001b[39m \u001b[43m_SumGrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    268\u001b[0m   input_shape \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_shape_tuple()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    269\u001b[0m   output_shape \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_shape_tuple()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py:220\u001b[0m, in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    217\u001b[0m       grad \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mreshape(grad, output_shape_kept_dims)\n\u001b[1;32m    218\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m [array_ops\u001b[38;5;241m.\u001b[39mtile(grad, tile_scaling), \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m--> 220\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeep_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    223\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(input_shape):\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# TODO(apassos) remove this once device placement for eager ops makes\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# more sense.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1254\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iterable_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[0;32m-> 1254\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mapi_dispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1256\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Runs = [\n",
    "    '_0_0_0_0',\n",
    "    '_0_0_0_1',\n",
    "    '_0_0_1_0',\n",
    "    '_0_0_1_1',\n",
    "    '_0_1_0_0',\n",
    "    '_0_1_0_1',\n",
    "    '_0_1_1_0',\n",
    "    '_0_1_1_1',\n",
    "    '_1_0_0_0',\n",
    "    '_1_0_0_1',\n",
    "    '_1_0_1_0',\n",
    "    '_1_0_1_1',\n",
    "    '_1_1_0_0',\n",
    "    '_1_1_0_1',\n",
    "    '_1_1_1_0',\n",
    "    '_1_1_1_1',\n",
    "]\n",
    "\n",
    "Runs = ['_0_0_1_0_1']\n",
    "\n",
    "for run in Runs:\n",
    "    Run = run\n",
    "    print ()\n",
    "    print ('------------------------------------')\n",
    "    print ('Run = ', Run)\n",
    "\n",
    "    random_seed = int(Run[1])\n",
    "    print ('random_seed = ', random_seed)\n",
    "    random.seed(random_seed) # Python\n",
    "    np.random.seed(random_seed) # NumPy\n",
    "    tf.random.set_seed(random_seed) # Tensorflow\n",
    "    \n",
    "    Build_Models('Hard', run)\n",
    "#    Build_Models('Medium', run)\n",
    "#    Build_Models('Easy', run)\n",
    "    \n",
    "# CPU times: user 4h 45min 20s, sys: 7min 22s, total: 4h 52min 43s\n",
    "# Wall time: 4h 30min 47s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb852de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_2_11",
   "language": "python",
   "name": "tensorflow_2_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
