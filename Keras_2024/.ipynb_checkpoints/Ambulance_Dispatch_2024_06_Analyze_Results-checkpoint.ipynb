{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767154e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf5662",
   "metadata": {},
   "source": [
    "# Ambulance_Dispatch_2024_06_Analyze_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352efa7b",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d22ff17",
   "metadata": {},
   "source": [
    "- The previous notebook build models and wrote the results in the \"Big_Files\" folder outside this repository\n",
    "- The name of each results file looks like \"BRFC_alpha_0_5_Hard_Run_0.csv\"\n",
    "- The results are four columns: \n",
    "    - Index (not really relevant)\n",
    "    - y_test, the (binary) value of the target variable, HOSPITAL\n",
    "        - 0 Didn't go to hospital\n",
    "        - 1 Went to hospital\n",
    "    - y_proba, the model's assessment, given the values of the other features in the sample, of the probability  in the real interval $y \\in [0,1]$ that this person went to the hospital\n",
    "    - y_pred, the model's prediction, using threshold $\\theta = 0.5$, that this person went to the hospital.  This value is y_proba rounded.  (also not really relevant)\n",
    "    \n",
    " |  | y_test | y_proba | y_pred |\n",
    " |---|---|---|---|\n",
    " | 0 | 0 | 0.17 | 0 |\n",
    " | 1 | 0 | 0.19 | 0 |\n",
    " | 2 | 0 | 0.44 | 0 |\n",
    " | 3 | 0 | 0.23 | 0 |\n",
    " | 4 | 0 | 0.25 | 0 |\n",
    " | 5 | 0 | 0.31 | 0 |\n",
    " | 6 | 0 | 0.35 | 0 |\n",
    " | 7 | 1 | 0.74 | 1 |\n",
    " | 8 | 0 | 0.13 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8764d033",
   "metadata": {},
   "source": [
    "# Understanding y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4270fe",
   "metadata": {},
   "source": [
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea489d64",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88d34c",
   "metadata": {},
   "source": [
    "- A spreadsheet for each model\n",
    "    - The example table below is from BRFC_alpha_0_7_Hard_Run_0_1000_Slices.csv\n",
    "    - Sorted by increasing y_proba\n",
    "    - $\\theta$ is the value of y_proba that we choose as the decision threshold, so we will use those two terms interchangeably.\n",
    "    - Grouped into bands y_proba $\\in$ [min, max] with at least one thousand samples from the negative class (HOSPITAL==0) and at least one thousand samples from the positive class (HOSPITAL==1).  Grouped from the bottom of the list with the top row perhaps having less than a thousand of each class.  \n",
    "    - The choice of 1000 is rather arbitrary, but after trial and error we chose it to give detail while smoothing out the randomness of the distribution of negative and positive samples.\n",
    "    - Having more than 1000 of both classes in a band indicates that more than one sample had the y_proba==min, because the grouping does not split samples with the same value.  If the min of one band is the max of the previous, that's due to rounding for this table.\n",
    "    - min and max are the y_proba values at the ends of the band\n",
    "    - Neg and Pos are the number of samples of the negative and positive clases in the band\n",
    "    - Pos/(Neg+Pos) is one of our decision threshold metrics, the probability that a sample in this band is in the positive class.  If we set the decision threshold $\\theta$ in this band of y_proba, we call this value the \"marginal probability\" or mProba, of a crash person needing an ambulance.\n",
    "        - Bands 16-21 illustrate that mProb is not always an increasing function of $\\theta$.  \n",
    "        - At band 51, $\\theta \\in [0.77, 0.78)$, mProba = 50%, our target for this decision thresholds.\n",
    "    - TN is the cumulative sum of Neg, and FN is the cumulative sum of Pos.\n",
    "    - Precision = TP/(FP+TP) is another of our decision threshold metrics. \n",
    "        - Precision is the proportion of ambulances sent that are actually needed\n",
    "        - Precision is not necessarily a nondecreasing function of $\\theta$, but with the class imbalance, the distribution of the Neg towards y_proba==0 and Pos towards y_proba==1, and the large bands that smooth the distribution, precision is generally an increasing function of $\\theta$.  \n",
    "        - Index 54 is where Precision is closest to our target, Prec = 0.667.\n",
    "        - This list has length 63 rows.  In index 62, FP and TP are zero, so Prec==NaN.  \n",
    "    - Recall = TP/(FN+TP) = TP/P\n",
    "        - Recall is the proportion of sent ambulances that are needed.\n",
    "        - Recall is a nonincreasing function of $\\theta$.\n",
    "        - For each decision threshold metric, we will find the value of $\\theta$ that gives the target value, then choose the model that give the highest recall.  \n",
    "        - Choosing the highest recall is the same as choosing the highest TP, because N is the same in all of our models.\n",
    "    - FP/P is the last of our decision threshold metrics. \n",
    "        - FP/P is the increase in number of ambulances sent if a locality implements immediate ambulance dispatch.\n",
    "        - FP/P is a nonincreasing function of $\\theta$.  \n",
    "        - At Index 58, FP/P is closest to its target value, 0.05.  Setting $\\theta$ there would cap the cost increase at 5%.\n",
    "    - The length of this list is 63 rows.  \n",
    "    \n",
    "    \n",
    "    | Index | min | max | Neg | Pos | Pos/(Neg+Pos) | TN | FP | FN | TP | Prec | Rec | FP/P\t| \n",
    "    |---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "    | 0 | 0 | 0.0995 | 18729 | 156 | 0.0083 | 18729 | 657715 | 156 | 126100 | 0.1609 | 0.9988 | 5.2094 |\n",
    "    | 1 | 0.1 | 0.1791 | 56799 | 1045 | 0.0181 | 75528 | 600916 | 1201 | 125055 | 0.1723 | 0.9905 | 4.7595 |\n",
    "    | 2 | 0.18 | 0.2194 | 41326 | 1150 | 0.0271 | 116854 | 559590 | 2351 | 123905 | 0.1813 | 0.9814 | 4.4322 |\n",
    "    | 3 | 0.22 | 0.2498 | 35354 | 1216 | 0.0333 | 152208 | 524236 | 3567 | 122689 | 0.1896 | 0.9717 | 4.1522 |\n",
    "    | 4 | 0.25 | 0.2698 | 25635 | 1021 | 0.0383 | 177843 | 498601 | 4588 | 121668 | 0.1962 | 0.9637 | 3.9491 |\n",
    "    | 5 | 0.27 | 0.2896 | 26768 | 1279 | 0.0456 | 204611 | 471833 | 5867 | 120389 | 0.2033 | 0.9535 | 3.7371 |\n",
    "    | ... |  |  |  |  |  |  |  |  |  |  |  |  |\n",
    "    | 16 | 0.42 | 0.4298 | 13318 | 1454 | 0.0984 | 399220 | 277224 | 20630 | 105626 | 0.2759 | 0.8366 | 2.1957 |\n",
    "    | 17 | 0.43 | 0.44 | 13124 | 1579 | 0.1074 | 412344 | 264100 | 22209 | 104047 | 0.2826 | 0.8241 | 2.0918 |\n",
    "    | 18 | 0.44 | 0.4498 | 13054 | 1540 | 0.1055 | 425398 | 251046 | 23749 | 102507 | 0.2899 | 0.8119 | 1.9884 |\n",
    "    | 19 | 0.45 | 0.46 | 12661 | 1721 | 0.1197 | 438059 | 238385 | 25470 | 100786 | 0.2972 | 0.7983 | 1.8881 |\n",
    "    | 20 | 0.46 | 0.4696 | 12252 | 1643 | 0.1182 | 450311 | 226133 | 27113 | 99143 | 0.3048 | 0.7853 | 1.7911 |\n",
    "    | 21 | 0.47 | 0.4798 | 12181 | 1792 | 0.1282 | 462492 | 213952 | 28905 | 97351 | 0.3127 | 0.7711 | 1.6946 |\n",
    "    | ... |  |  |  |  |  |  |  |  |  |  |  |  |\n",
    "    | 50 | 0.76 | 0.7698 | 2364 | 2289 | 0.4919 | 656972 | 19472 | 94826 | 31430 | 0.6175 | 0.2489 | 0.1542 |\n",
    "    | 51 | 0.77 | 0.78 | 2307 | 2372 | 0.5069 | 659279 | 17165 | 97198 | 29058 | 0.6286 | 0.2302 | 0.136 |\n",
    "    | 52 | 0.78 | 0.7898 | 2072 | 2210 | 0.5161 | 661351 | 15093 | 99408 | 26848 | 0.6401 | 0.2126 | 0.1195 |    \n",
    "    | ... |  |  |  |  |  |  |  |  |  |  |  |  |\n",
    "    | 54 | 0.8 | 0.8099 | 1802 | 2157 | 0.5448 | 665048 | 11396 | 103790 | 22466 | 0.6635 | 0.1779 | 0.0903 |\n",
    "    | 55 | 0.81 | 0.8198 | 1626 | 2170 | 0.5717 | 666674 | 9770 | 105960 | 20296 | 0.675 | 0.1608 | 0.0774 |\n",
    "    | ... |  |  |  |  |  |  |  |  |  |  |  |  |\n",
    "    | 56 | 0.82 | 0.8298 | 1429 | 2045 | 0.5887 | 668103 | 8341 | 108005 | 18251 | 0.6863 | 0.1446 | 0.0661 |\n",
    "    | 57 | 0.83 | 0.8398 | 1362 | 1975 | 0.5918 | 669465 | 6979 | 109980 | 16276 | 0.6999 | 0.1289 | 0.0553 |\n",
    "    | 58 | 0.84 | 0.8495 | 1165 | 1929 | 0.6235 | 670630 | 5814 | 111909 | 14347 | 0.7116 | 0.1136 | 0.046 |\n",
    "    | 59 | 0.85 | 0.8696 | 1959 | 3571 | 0.6458 | 672589 | 3855 | 115480 | 10776 | 0.7365 | 0.0854 | 0.0305 |\n",
    "    | 60 | 0.87 | 0.889 | 1462 | 2940 | 0.6679 | 674051 | 2393 | 118420 | 7836 | 0.7661 | 0.0621 | 0.019 |\n",
    "    | 61 | 0.89 | 0.9199 | 1388 | 3566 | 0.7198 | 675439 | 1005 | 121986 | 4270 | 0.8095 | 0.0338 | 0.008 |\n",
    "    | 62 | 0.92 | 1 | 1005 | 4270 | 0.8095 | 676444 | 0 | 126256 | 0 | nan | 0 | 0 |\n",
    "\n",
    "    <br><br>\n",
    "    - This table below is from LogReg_alpha_balanced_Medium_Run_0_1000_Slices.csv.\n",
    "    - Note that the last row has FP=0 and TP=0, because we're not sending any ambulances, so Precision is NaN.\n",
    "    - Precision is a generally increasing function of the decision threshold $\\theta$, so the next to last row gives the maximum value of Prec = 0.5667, telling us that, with this model algorithm with these hyperparameters on the Medium features, there is no decision threshold where the target of Prec = 0.667 is achieved.\n",
    "    - If we cut it into smaller bands, we might get a band with Prec $\\approx$ 0.667, but the model would immediately dispatch so few ambulances that the benefit would not be worth the project overhead.\n",
    "\n",
    "| Index | min | max | Neg | Pos | Pos/(Neg+Pos) | TN | FP | FN | TP | Prec | Rec | FP/P\t| \n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| 0 | 0.0397 | 0.1794 | 24475 | 773 | 0.0306 | 24475 | 651969 | 773 | 125483 | 0.1614 | 0.9939 | 5.1639 |\n",
    "| 1 | 0.1794 | 0.2167 | 23510 | 1000 | 0.0408 | 47985 | 628459 | 1773 | 124483 | 0.1653 | 0.986 | 4.9777 |\n",
    "| 2 | 0.2167 | 0.24 | 18987 | 1000 | 0.05 | 66972 | 609472 | 2773 | 123483 | 0.1685 | 0.978 | 4.8273 |\n",
    "| ... |||||||||||||\n",
    "| 123 | 0.8777 | 0.8893 | 1000 | 1038 | 0.5093 | 674444 | 2000 | 123816 | 2440 | 0.5495 | 0.0193 | 0.0158 |\n",
    "| 124 | 0.8893 | 0.9057 | 1000 | 1132 | 0.531 | 675444 | 1000 | 124948 | 1308 | 0.5667 | 0.0104 | 0.0079 |\n",
    "| 125 | 0.9057 | 0.9606 | 1000 | 1308 | 0.5667 | 676444 | 0 | 126256 | 0 | nan | 0 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa423799",
   "metadata": {},
   "source": [
    "- Three spreadsheets, one spreadsheet for each decision threshold metric, one row for each model, the decision threshold $\\theta$ where the model gets closest to the decision threshold metric.  \n",
    "    - The table below is from ../Analyze_Proba/Run_0/Prec_0_667.csv\n",
    "    - It has been filtered (outside this notebook; we did it in Excel) to only show rows whose Prec is within 0.02 of 0.667, because many models fail to even get close to the target value of the decision threshold metric\n",
    "    - It was then sorted by decreasing recall, Rec = TP/(TP+FN) = TP/P, which is the same as decreasing TP because P is the same in all of these models\n",
    "    - The first row shows that for the Balanced Random Forest Classifier with $\\alpha = 0.7$ on the Hard features, for y_pred $\\in [0.8, 0.8099]$, there were 1.802 negative samples (y_test==0) and 2,157 positive samples (y_test==1).\n",
    "    - If we put the decision threshold here around 0.8, we will \n",
    "        - Correctly not send ambulances to 665,048 people who do no need them (TN), \n",
    "        - Incorrectly send ambulances to 11,396 people who do not need them (FP), \n",
    "        - Incorrectly not immediately send ambulances to 103,790 people who need them (FN), but will send the ambulance later after an eyewitness report, \n",
    "        - Correctly immediately send ambulances to 22,466 people who need them (TP)\n",
    "\n",
    "        Index | len | Filename | min | max | Neg | Pos | Pos/(Neg+Pos) | TN | FP | FN | TP | Prec | Rec | FP/P\t| \n",
    "        |---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "        | 54 | 63 | BRFC_alpha_0_7_Hard_Run_0 | 0.8 | 0.8099 | 1,802 | 2,157 | 0.5448 | 665,048 | 11,396 | 103,790 | 22,466 | 0.6635 | 0.1779 | 0.0903 |\n",
    "        | 53 | 62 | BRFC_alpha_0_5_Hard_Run_0 | 0.8 | 0.8097 | 1,778 | 2,251 | 0.5587 | 665,260 | 11,184 | 104,033 | 22,223 | 0.6652 | 0.176 | 0.0886 |\n",
    "        | 55 | 64 | BRFC_alpha_0_9_Hard_Run_0 | 0.8 | 0.8099 | 1,760 | 2,079 | 0.5415 | 665,328 | 11,116 | 104,539 | 21,717 | 0.6614 | 0.172 | 0.088 |\n",
    "        | 55 | 64 | BRFC_alpha_balanced_Hard_Run_0 | 0.81 | 0.8199 | 1,685 | 2,203 | 0.5666 | 666,074 | 10,370 | 105,504 | 20,752 | 0.6668 | 0.1644 | 0.0821 |\n",
    "        | 54 | 63 | BRFC_alpha_0_6_Hard_Run_0 | 0.81 | 0.82 | 1,696 | 2,169 | 0.5612 | 666,442 | 10,002 | 105,693 | 20,563 | 0.6728 | 0.1629 | 0.0792 |\n",
    "        | 56 | 65 | BRFC_alpha_0_85_Hard_Run_0 | 0.81 | 0.82 | 1,607 | 2,202 | 0.5781 | 666,215 | 10,229 | 105,732 | 20,524 | 0.6674 | 0.1626 | 0.081 |\n",
    "        | 56 | 64 | BRFC_alpha_0_95_Hard_Run_0 | 0.81 | 0.8199 | 1,633 | 2,115 | 0.5643 | 666,391 | 10,053 | 106,101 | 20,155 | 0.6672 | 0.1596 | 0.0796 |\n",
    "        | ... | ||||||||||||||\n",
    "        | 124 | 126 | LogReg_alpha_balanced_Medium_Run_0 | 0.8893 | 0.9057 | 1,000 | 1,132 | 0.531 | 675,444 | 1,000 | 124,948 | 1,308 | 0.5667 | 0.0104 | 0.0079 |![image-4.png](attachment:image-4.png)\n",
    "        <br>\n",
    "        - At this decision threshold, \n",
    "        $$\\text{Precision} = \\frac{\\text{TP}}{\\text{TP}+\\text{FP}} = \\frac{22,466}{11,396 + 22,466} = 0.6635$$\n",
    "        <br>\n",
    "        - In this interval, the marginal probability that crash person goes to the hospital is Pos/(Neg+Pos) = 0.8099 = 81%, so if that were our marginal probability were our decision threshold metric with a target of 50%, we would choose a lower decision threshold.  A different spreadsheet, mProb_0_5.csv, gives for each model the decision threshold $\\theta$ where mProb is closest to 0.5.\n",
    "        - In this interval, the increase in ambulance runs is 0.0903 or 9%. If capping the cost increase at 5% were our goal, we would choose a higher decision threshold.  The spreadsheet FP_P_0_05.csv gives for each model the decision threshold where FP/P is closest to 0.05.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e1d2b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7d47d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b4fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('Install Packages')\n",
    "\n",
    "import sys, copy, math, time, os\n",
    "\n",
    "print ('Python version: {}'.format(sys.version))\n",
    "\n",
    "#from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import scipy as sc\n",
    "print ('SciPy version:  {}'.format(sc.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print ('TensorFlow version:  {}'.format(tf.__version__))\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "from tensorflow import keras\n",
    "print ('Keras version:  {}'.format(keras.__version__))\n",
    "\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "#from keras.layers import IntegerLookup\n",
    "#from keras.layers import Normalization\n",
    "#from keras.layers import StringLookup\n",
    "#from keras.utils import get_custom_objects\n",
    "#from keras.utils import tf_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import scikeras\n",
    "print ('scikeras version:  {}'.format(scikeras.__version__))\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import pandas as pd\n",
    "print ('Pandas version:  {}'.format(pd.__version__))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "#    \"pgf.texsystem\": \"pdflatex\",\n",
    "#    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "    'font.size': 11,\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Library for reading Microsoft Access files\n",
    "#import pandas_access as mdb\n",
    "\n",
    "import sklearn\n",
    "print ('SciKit-Learn version: {}'.format(sklearn.__version__))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import imblearn\n",
    "print ('Imbalanced-Learn version: {}'.format(imblearn.__version__))\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "#!pip install pydot\n",
    "\n",
    "# Set Randomness.  Copied from https://www.kaggle.com/code/abazdyrev/keras-nn-focal-loss-experiments\n",
    "import random\n",
    "random_seed = 0\n",
    "print ('random_seed = %d' % random_seed)\n",
    "random.seed(random_seed) # Python\n",
    "np.random.seed(random_seed) # NumPy\n",
    "#tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print ('Finished Installing Packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d83bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chart_and_Plots(y_test, y_proba, y_pred, filename, run, title):\n",
    "    print ('Charts_and_Plots() for ', filename)\n",
    "    \n",
    "    Analyze_Prediction(y_test, y_proba, filename, run, title)\n",
    "    \n",
    "    Plot_Prediction(y_test, y_proba, filename, run, title)\n",
    "    Plot_Prediction_Wide(y_test, y_proba, filename, run, title)\n",
    "#    print (\"type(y_proba): \", type(y_proba))\n",
    "    left = min(y_proba)\n",
    "    right = max(y_proba)\n",
    "#    print (left, right)\n",
    "    Plot_Prediction_Zoom(y_test, y_proba, filename, run, title, left, right)\n",
    "    Plot_Prediction_Zoom_Legend_Top(y_test, y_proba, filename, run, title, left, right)\n",
    "    Plot_Prediction_Zoom_Medium(y_test, y_proba, filename, run, title, left, right)\n",
    "    Plot_Prediction_Zoom_Wide(y_test, y_proba, filename, run, title, left, right)\n",
    "    Plot_Prediction_Zoom_Wide_Right(y_test, y_proba, filename, run, title, left, right)\n",
    "    \n",
    "    \n",
    "\n",
    "    ROC(y_test, y_proba, [], filename, run)\n",
    "    ROC_Legend_Top(y_test, y_proba, [], filename, run)\n",
    "    Evaluate_Model(y_test, y_proba, y_pred, 0.5, filename, run)\n",
    "    \n",
    "#    print ()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97848247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate_Model(y_test, y_proba, y_pred, center, filename, run):\n",
    "    print ('Evaluate_Model() for ', filename)\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred = [round(x) for x in y_proba]\n",
    "    y_pred = np.array(y_pred)\n",
    "#    print ('np.unique(y_proba) = ', np.unique(y_proba))\n",
    "#    print ('np.unique(y_pred) = ', np.unique(y_pred))\n",
    "    CM = confusion_matrix(y_test, y_pred)\n",
    "#    print(CM)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    f = open('./Analyze_Proba/' + run + '/ROC_AUC.csv', 'a')\n",
    "    f.write('%s,%f\\n' % (filename, auc_value))\n",
    "    f.close()\n",
    "    \n",
    "    CSV = [[filename, CM[0][0], CM[0][1], CM[1][0], CM[1][1], center, auc_value]]\n",
    "    np.savetxt('./Confusion_Matrices/' + filename + '.csv', \n",
    "        CSV,\n",
    "        delimiter =\", \", \n",
    "        fmt ='% s'\n",
    "              )\n",
    "#    print ()\n",
    "    CM = confusion_matrix(y_test, y_pred, normalize='all')\n",
    "#    print(CM)\n",
    "#    print ()\n",
    "\n",
    "#    y_pred = y_pred.ravel()\n",
    "#    y_test = tf.convert_to_tensor(y_test)\n",
    "#    y_pred = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "#    print ('%.3f & Precision \\cr ' %  Precision_Metric(y_test, y_pred).numpy())\n",
    "#    print ('%.3f & Recall \\cr ' %  Recall_Metric(y_test, y_pred).numpy())\n",
    "#    print ('%.3f & F1 \\cr ' %  F1_Metric(y_test, y_pred).numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082fee38",
   "metadata": {},
   "source": [
    "# Plots and Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf928217",
   "metadata": {},
   "source": [
    "## Plot Prediction\n",
    "\n",
    "How to insert a .pgf plot into a \\LaTeX document:\n",
    "\n",
    "\\begin{figure}\n",
    "    \\begin{center}\n",
    "        \\input{Plot.pgf}\n",
    "    \\end{center}\n",
    "    \\caption{A PGF histogram from \\texttt{matplotlib}.}\n",
    "\\end{figure}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3496ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction(y_test, y_proba, filename, run, title):\n",
    "    print ('Plot_Prediction() for ', filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 10\n",
    "    bins= [x/n for x in range (0, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "    \n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "    plt.xticks(\n",
    "        ticks = [0, 2.5, 5, 7.5, 10], \n",
    "        labels = ['0.0', '0.25', '0.5', '0.75', '1.0'],\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Dataset')\n",
    "#    plt.tight_layout()\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b634349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Zoom(y_test, y_proba, filename, run, title, left, right):\n",
    "    print ('Plot_Prediction_Zoom() for ', filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    B = B[A['HOSPITAL'] > left]\n",
    "    B = B[A['HOSPITAL'] < right]\n",
    "    A = A[A['HOSPITAL'] > left]\n",
    "    A = A[A['HOSPITAL'] < right]\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 10\n",
    "    bins= [left + (right-left)*x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "\n",
    "    ticks = [0, 5, 10]\n",
    "    num_prec = int(-(math.log10((right-left)/2)))+2\n",
    "    num_prec = max(num_prec,2)\n",
    "    \n",
    "    if num_prec==2:\n",
    "        labels = [\"{:.2f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    if num_prec==3:\n",
    "        labels = [\"{:.3f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    if num_prec==4:\n",
    "        labels = [\"{:.4f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    if num_prec>4:\n",
    "        labels = [\"{:.5f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    \n",
    "    \n",
    "#    labels = [str(round(left + (right-left) * t/10,3)) for t in ticks]\n",
    "    plt.xticks(\n",
    "        ticks = ticks, \n",
    "        labels = labels,\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Dataset')\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Zoom.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Zoom.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred_Zoom.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128cd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Zoom_Legend_Top(y_test, y_proba, filename, run, title, left, right):\n",
    "    print ('Plot_Prediction_Zoom() for ', filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    B = B[A['HOSPITAL'] > left]\n",
    "    B = B[A['HOSPITAL'] < right]\n",
    "    A = A[A['HOSPITAL'] > left]\n",
    "    A = A[A['HOSPITAL'] < right]\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 10\n",
    "    bins= [left + (right-left)*x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(2.2,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "\n",
    "    ticks = [0, 5, 10]\n",
    "    num_prec = int(-(math.log10((right-left)/2)))+2\n",
    "    num_prec = max(num_prec,2)\n",
    "    \n",
    "    if num_prec==2:\n",
    "        labels = [\"{:.2f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    if num_prec==3:\n",
    "        labels = [\"{:.3f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    if num_prec==4:\n",
    "        labels = [\"{:.4f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    if num_prec>4:\n",
    "        labels = [\"{:.5f}\".format(round(left + (right-left) * t/10,num_prec)) for t in ticks]\n",
    "    \n",
    "    \n",
    "#    labels = [str(round(left + (right-left) * t/10,3)) for t in ticks]\n",
    "    plt.xticks(\n",
    "        ticks = ticks, \n",
    "        labels = labels,\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'], loc='upper center', bbox_to_anchor=(0.5, 1.40), ncol=2)\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Dataset')\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Zoom_Legend_Top.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Zoom_Legend_Top.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred_Zoom.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aba149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Zoom_Medium(y_test, y_proba, filename, run, title, left, right):\n",
    "    print ('Plot_Prediction_Zoom() for ', filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    B = B[A['HOSPITAL'] > left]\n",
    "    B = B[A['HOSPITAL'] < right]\n",
    "    A = A[A['HOSPITAL'] > left]\n",
    "    A = A[A['HOSPITAL'] < right]\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 20\n",
    "    bins= [left + (right-left)*x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(3.0,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "\n",
    "    ticks = [0, 5, 10, 15, 20]\n",
    "    num_prec = int(-(math.log10((right-left)/2)))+2\n",
    "    num_prec = max(num_prec,2)\n",
    "    \n",
    "    if num_prec==2:\n",
    "        labels = [\"{:.2f}\".format(round(left + (right-left) * t/n,num_prec)) for t in ticks]\n",
    "    if num_prec==3:\n",
    "        labels = [\"{:.3f}\".format(round(left + (right-left) * t/n,num_prec)) for t in ticks]\n",
    "    if num_prec==4:\n",
    "        labels = [\"{:.4f}\".format(round(left + (right-left) * t/n,num_prec)) for t in ticks]\n",
    "    if num_prec>4:\n",
    "        labels = [\"{:.5f}\".format(round(left + (right-left) * t/n,num_prec)) for t in ticks]\n",
    "    \n",
    "    \n",
    "#    labels = [str(round(left + (right-left) * t/10,3)) for t in ticks]\n",
    "    plt.xticks(\n",
    "        ticks = ticks, \n",
    "        labels = labels,\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Dataset')\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Zoom_Medium.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Zoom_Medium.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred_Zoom.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Zoom_Wide(y_test, y_proba, filename, run, title, left, right):\n",
    "    print ('Plot_Prediction_Zoom_Wide() for ', filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    B = B[A['HOSPITAL'] > left]\n",
    "    B = B[A['HOSPITAL'] < right]\n",
    "    A = A[A['HOSPITAL'] > left]\n",
    "    A = A[A['HOSPITAL'] < right]\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 20\n",
    "    bins= [left + (right-left)*x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(4.5,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "\n",
    "#    ticks = [0, 2.5, 5, 7.5, 10]\n",
    "    ticks = [0, 4, 8, 12, 16, 20]\n",
    "    num_prec = int(-(math.log10((right-left)/4)))+2\n",
    "    num_prec = max(num_prec,2)\n",
    "#    print (\"left, right, (right-left)/5, -(math.log10((right-left)/5)), num_prec\")\n",
    "#    print (left, right, (right-left)/5, -(math.log10((right-left)/5)), num_prec)\n",
    "    \n",
    "    if num_prec<3:\n",
    "        labels = [\"{:.2f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec==3:\n",
    "        labels = [\"{:.3f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec==4:\n",
    "        labels = [\"{:.4f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec>4:\n",
    "        labels = [\"{:.5f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "#    labels = [str(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    plt.xticks(\n",
    "        ticks = ticks, \n",
    "        labels = labels,\n",
    "        rotation=0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Dataset')\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Zoom_Wide.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Zoom_Wide.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred_Zoom_Wide.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e568ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Zoom_Wide_Right(y_test, y_proba, filename, run, title, left, right):\n",
    "    print ('Plot_Prediction_Zoom_Wide_Right() for ', filename)\n",
    "    \n",
    "#    print (y_test)\n",
    "#    print (y_proba)\n",
    "#    return 0\n",
    "#    y_test = y_test.numpy()\n",
    "\n",
    "    left = (left + right)/2\n",
    "\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    B = B[A['HOSPITAL'] > left]\n",
    "    B = B[A['HOSPITAL'] < right]\n",
    "    A = A[A['HOSPITAL'] > left]\n",
    "    A = A[A['HOSPITAL'] < right]\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    bins = [x*0.05 for x in range (21)]\n",
    "#    bins = [x*0.10 for x in range (11)]\n",
    "    n = 20\n",
    "    bins= [left + (right-left)*x/n for x in range (-1, n+1)]\n",
    "#    print (bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=False)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "\n",
    "    fig = plt.figure(figsize=(4.5,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "\n",
    "#    ticks = [0, 2.5, 5, 7.5, 10]\n",
    "    ticks = [0, 4, 8, 12, 16, 20]\n",
    "    num_prec = int(-(math.log10((right-left)/4)))+2\n",
    "    num_prec = max(num_prec,2)\n",
    "#    print (\"left, right, (right-left)/5, -(math.log10((right-left)/5)), num_prec\")\n",
    "#    print (left, right, (right-left)/5, -(math.log10((right-left)/5)), num_prec)\n",
    "    \n",
    "    if num_prec<3:\n",
    "        labels = [\"{:.2f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec==3:\n",
    "        labels = [\"{:.3f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec==4:\n",
    "        labels = [\"{:.4f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    if num_prec>4:\n",
    "        labels = [\"{:.5f}\".format(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "#    labels = [str(round(left + (right-left) * t/20,num_prec)) for t in ticks]\n",
    "    plt.xticks(\n",
    "        ticks = ticks, \n",
    "        labels = labels,\n",
    "        rotation=0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Dataset')\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Zoom_Wide_Right.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Zoom_Wide_Right.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred_Zoom_Wide.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eda862",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Plot_Prediction_Wide(y_test, y_proba, filename, run, title):\n",
    "    print ('Plot_Prediction_Wide() for ', filename)\n",
    "    \n",
    "#    print ('y_test = ', y_test)\n",
    "#    print ('y_proba = ',y_proba)\n",
    "\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "#    print (\"A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\")\n",
    "#    display(A)\n",
    "#    print (\"B = pd.DataFrame(y_test, columns=['HOSPITAL'])\")\n",
    "#    display(B)\n",
    "#    print (\"C = A[B['HOSPITAL']==0]\")\n",
    "#    display(C)\n",
    "#    print (\"D = A[B['HOSPITAL']==1]\")\n",
    "#    display(D)\n",
    "    n = 20\n",
    "#    bins= [x/n - 1/(2*n) for x in range (-1, n+3)]\n",
    "    bins= [x/n for x in range (-1, n+1)]\n",
    "#    print ('Bins = ', bins)\n",
    "    E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "#    print (\"E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=True)\")\n",
    "#    display(E)\n",
    "#    print (\"F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=True)\")\n",
    "#    display(F)\n",
    "    \n",
    "    G = E.value_counts(sort=False)\n",
    "    H = F.value_counts(sort=False)\n",
    "#    print (\"G = E.value_counts(sort=False)\")\n",
    "#    display(G)\n",
    "#    print (\"H = F.value_counts(sort=False)\")\n",
    "#    display(H)\n",
    "\n",
    "    G = G/len(y_proba)*100\n",
    "    H = H/len(y_proba)*100\n",
    "#    print (\"G = G/len(y_proba)*100\")\n",
    "#    display(G)\n",
    "#    print (\"H = H/len(y_proba)*100\")\n",
    "#    display(H)\n",
    "\n",
    "    fig = plt.figure(figsize=(4.5,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    G.plot(kind='bar', fill=False, ax=ax, width=0.4, position=1)\n",
    "    H.plot(kind='bar', color='black', ax=ax, width=0.4, position=0)\n",
    "    ticks = [n/20*i for i in range (-1,22)]\n",
    "#    print ('ticks = ', ticks)\n",
    "    plt.xticks(\n",
    "        ticks = ticks,\n",
    "        labels = ['','0.0', '', '0.1', '', '0.2', '', '0.3', '', '0.4', '', '0.5', '', '0.6', '', '0.7', '', '0.8', '', '0.9', '', '1.0', ''],\n",
    "        rotation=0\n",
    "    )\n",
    "    ax.legend(['Neg', 'Pos'])\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Dataset')\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Wide.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_Pred_Wide.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "#    print ('./Images/' + filename + '_Pred_Wide.png')\n",
    "#    plt.show()\n",
    "    plt.close()\n",
    "#    print ()\n",
    "    return 0\n",
    "\n",
    "def Test_Plot_Prediction_Wide():\n",
    "    \n",
    "    y_proba = (\n",
    "        [0.0]*5 + \n",
    "        [0.0]*0 + \n",
    "        [0.1]*6 + \n",
    "        [0.1]*1 + \n",
    "        [0.2]*7 + \n",
    "        [0.2]*2 + \n",
    "        [0.3]*6 + \n",
    "        [0.3]*1 + \n",
    "        [0.4]*8 + \n",
    "        [0.4]*2 + \n",
    "        [0.5]*9 + \n",
    "        [0.5]*2 + \n",
    "        [0.6]*8 + \n",
    "        [0.6]*2 + \n",
    "        [0.7]*6 + \n",
    "        [0.7]*3 + \n",
    "        [0.8]*5 + \n",
    "        [0.8]*3 + \n",
    "        [0.9]*3 + \n",
    "        [0.9]*2 + \n",
    "        [1.0]*0 + \n",
    "        [1.0]*2 \n",
    "    )\n",
    "    y_test = (\n",
    "        [0]*5 + \n",
    "        [1]*0 + \n",
    "        [0]*6 + \n",
    "        [1]*1 + \n",
    "        [0]*7 + \n",
    "        [1]*2 + \n",
    "        [0]*6 + \n",
    "        [1]*1 + \n",
    "        [0]*8 + \n",
    "        [1]*2 + \n",
    "        [0]*9 + \n",
    "        [1]*2 + \n",
    "        [0]*8 + \n",
    "        [1]*2 + \n",
    "        [0]*6 + \n",
    "        [1]*3 + \n",
    "        [0]*5 + \n",
    "        [1]*3 + \n",
    "        [0]*3 + \n",
    "        [1]*2 + \n",
    "        [0]*0 + \n",
    "        [1]*2 \n",
    "    )\n",
    "    Plot_Prediction_Wide(y_test, y_proba, 'Test', 'Test')\n",
    "    \n",
    "#Test_Plot_Prediction_Wide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ec6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Value_Counts_y_proba(y_proba, filename, run):\n",
    "    print ('Value_Counts_y_proba() for ', filename)\n",
    "#    print (type(y_proba))\n",
    "    Y_proba = pd.Series(y_proba)\n",
    "    A = Y_proba.value_counts().reset_index(drop=True)\n",
    "    n = len(y_proba)\n",
    "    nA = len(A)\n",
    "#    display(Y_proba)\n",
    "#    display(A)\n",
    "    B = A.cumsum()\n",
    "#    display(B)\n",
    "#    print (B[10])\n",
    "#    print ()\n",
    "    cutoff_95 = B.sub(0.95*n).abs().idxmin() + 1\n",
    "    cutoff_90 = B.sub(0.90*n).abs().idxmin() + 1\n",
    "    cutoff_80 = B.sub(0.80*n).abs().idxmin() + 1\n",
    "    m = Y_proba.min()\n",
    "    M = Y_proba.max()\n",
    "#    print (n, nA)\n",
    "#    print (cutoff_95)\n",
    "#    print ()\n",
    "\n",
    "    n100 = min(100, len(B)-1)\n",
    "    n200 = min(200, len(B)-1)\n",
    "#    print ('n200 = ', n200)\n",
    "    f = open('./Analyze_Proba/' + run + '/Value_Counts_y_proba.csv', 'a')\n",
    "    f.write('%s,%d,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%d,%0.4f,%0.4f,%0.4f\\n' % (\n",
    "        filename, n, nA, nA/n, \n",
    "        cutoff_95, cutoff_95/n,\n",
    "        cutoff_90, cutoff_90/n,\n",
    "        cutoff_80, cutoff_80/n,\n",
    "        B[10], B[10]/n,\n",
    "        B[20], B[20]/n,\n",
    "        B[n100], B[n100]/n,\n",
    "        B[n200], B[n200]/n,\n",
    "        m,M,\n",
    "    ))\n",
    "    f.close()\n",
    "    \n",
    "    H = Y_proba.value_counts().head(100)\n",
    "    Filename = './Analyze_Proba/' + run + '/' + filename + '_Value_Counts_head_100.csv'\n",
    "    H.to_csv(Filename)\n",
    "\n",
    "    return 0\n",
    "    \n",
    "def Create_Files_for_Value_Counts_y_proba(run):\n",
    "    print ('Create_Files_for_Value_Counts_y_Proba')\n",
    "    f = open('./Analyze_Proba/' + run + '/Value_Counts_y_proba.csv', 'w')\n",
    "    f.write(\"Filename,n,nUnique,nUnique/n,95%,95%/n,90%,90%/n,80%,80%/n,B[10],B[10]/n,B[20],B[20]/n,B[100],B[100]/n,B[200],B[200],min,max,\\n\")\n",
    "    f.close()\n",
    "    \n",
    "#Create_Files_for_Value_Counts_y_proba()\n",
    "\n",
    "def Create_Files_for_Lengths_of_fpr_tpr(run):\n",
    "    print ('Create_Files_for_Lengths_of_fpr_tpr')\n",
    "    f = open('./Analyze_Proba/' + run + '/Lengths_of_fpr_tpr.csv', 'w')\n",
    "    f.write(\"Filename,len(y_proba),nUnique(y_proba),len(fpr),nUnique(fpr),len(tpr),nUnique(tpr),len(fpr tpr),nUnique(fpr tpr)\\n\")\n",
    "    f.close()\n",
    "    \n",
    "def Create_Files_for_ROC_AUC(run):\n",
    "    print ('Create_Files_for_ROC_AUC')\n",
    "    f = open('./Analyze_Proba/' + run + '/ROC_AUC.csv', 'w')\n",
    "    f.write(\"Filename,ROC_AUC\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "def Test_Value_Counts_y_proba():\n",
    "    A = [5]*50 + [6]*20 + [i for i in range (10,40)]*2 + [i for i in range (100,400)]\n",
    "    Value_Counts_y_proba(A, 'Test')\n",
    "\n",
    "#Test_Value_Counts_y_proba()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31270ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rolling_Intervals(y_proba, y_test, filename, run):\n",
    "    \n",
    "    A = pd.DataFrame(y_proba, columns=['y_proba'])\n",
    "    B = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    C = pd.concat([A,B], axis=1)\n",
    "    n = len(A)\n",
    "    P = C['y_test'].sum()\n",
    "    N = n - P\n",
    "    \n",
    "    # Sort the y_proba values with p==0 at the top.\n",
    "    \n",
    "    C.sort_values(by=['y_proba'], ascending=True, inplace=True)\n",
    "#    C = C.reset_index(drop=False)\n",
    "    \n",
    "    C['Neg'] = 1-C['y_test']\n",
    "    C['Pos'] = C['y_test']\n",
    "\n",
    "    D = C.groupby(['y_proba'], as_index=False).sum()\n",
    "    D['TN'] = D['Neg'].cumsum()\n",
    "    D['FP'] = N - D['TN']\n",
    "    D['FN'] = D['Pos'].cumsum()\n",
    "    D['TP'] = P - D['FN']\n",
    "    D['FP/P'] = D['FP'] / P\n",
    "    D['Prec'] = D['TP'] / (D['FP'] + D['TP'])\n",
    "\n",
    "    D.to_csv('./Analyze_Proba/' + run + '/' + filename + '.csv')\n",
    "\n",
    "    return 0\n",
    "    \n",
    "    for i in [1,10,20,50,100,200,500,1000,2000]:\n",
    "        tp = 'TP_' + str(i)\n",
    "        fp = 'FP_' + str(i)\n",
    "        prec = 'Prec_' + str(i)\n",
    "        Min = 'Min_' + str(i)\n",
    "        Max = 'Max_' + str(i)\n",
    "        \n",
    "        D[tp] = D['TP'].rolling(i, center=True).mean()\n",
    "        D[fp] = D['FP'].rolling(i, center=True).mean()\n",
    "        D[prec] = D[tp] / (D[fp] + D[tp])\n",
    "        D[Min] = D['y_proba'].where(D[prec] > 0.6567)\n",
    "        D[Max] = D['y_proba'].where(D[prec] < 0.6767)\n",
    "        a = D[Min].min()\n",
    "        b = D[Max].max()\n",
    "\n",
    "#        E = D[abs(D[prec]-0.667)<0.01]\n",
    "#        print (i)\n",
    "#        display(E)\n",
    "#        a = E['y_proba'].min()\n",
    "#        b = E['y_proba'].max()\n",
    "#        print (filename, prec, a, b, b-a)\n",
    "\n",
    "        D_tmp = D[D['y_proba']==a]\n",
    "        D_tmp = D_tmp[['y_proba',prec,'TN','FP','FN','TP','FP/P']]\n",
    "        \n",
    "        D_tmp.insert(loc=0, column='Diff', value=b-a)\n",
    "        D_tmp.insert(loc=0, column='Max', value=b)\n",
    "        D_tmp.insert(loc=0, column='Min', value=a)\n",
    "        D_tmp.insert(loc=0, column='Min/Max', value='Min')\n",
    "        D_tmp.insert(loc=0, column='Roll', value=prec)\n",
    "        D_tmp.insert(loc=0, column='Filename', value=filename)        \n",
    "        D_tmp.to_csv('./Analyze_Proba/' + run + '/Prec_Rolling_0_667.csv', mode='a', index=True, header=False)\n",
    "        \n",
    "        D_tmp = D[D['y_proba']==b]\n",
    "        D_tmp = D_tmp[['y_proba',prec,'TN','FP','FN','TP','FP/P']]\n",
    "        \n",
    "        D_tmp.insert(loc=0, column='Diff', value=b-a)\n",
    "        D_tmp.insert(loc=0, column='Max', value=b)\n",
    "        D_tmp.insert(loc=0, column='Min', value=a)\n",
    "        D_tmp.insert(loc=0, column='Min/Max', value='Max')\n",
    "        D_tmp.insert(loc=0, column='Roll', value=prec)\n",
    "        D_tmp.insert(loc=0, column='Filename', value=filename)        \n",
    "        D_tmp.to_csv('./Analyze_Proba/' + run + '/Prec_Rolling_0_667.csv', mode='a', index=True, header=False)\n",
    "        \n",
    "        \n",
    "#        D_max = D[D['y_proba']==b]\n",
    "#        D_max.insert(loc=0, column='Min/Max', value='Max')\n",
    "#        D_max.insert(loc=0, column='Roll', value=prec)\n",
    "#        D_max.insert(loc=0, column='Filename', value=filename)        \n",
    "#        D_max.to_csv('./Analyze_Proba/Prec_Rolling_0_667.csv', mode='a', index=True, header=False)\n",
    "        \n",
    "#    D.to_csv('./Analyze_Proba/' + run +  '/Test.csv', index=True, header=True)\n",
    "    \n",
    "    D['mProb'] = D['Pos'] / (D['Neg'] + D['Pos'])\n",
    "    \n",
    "    for i in [1,10,20,50,100,200,500,1000,2000]:\n",
    "        pos = 'Pos_' + str(i)\n",
    "        neg = 'Neg_' + str(i)\n",
    "        mprob = 'mProb_' + str(i)\n",
    "        Min = 'p_Min_' + str(i)\n",
    "        Max = 'p_Max_' + str(i)\n",
    "        \n",
    "        D[pos] = D['Pos'].rolling(i, center=True).sum()\n",
    "        D[neg] = D['Neg'].rolling(i, center=True).sum()\n",
    "        D[mprob] = D[pos] / (D[neg] + D[pos])\n",
    "        D[Min] = D['y_proba'].where(D[mprob] >= 0.500)\n",
    "        D[Max] = D['y_proba'].where(D[mprob] <= 0.500)\n",
    "        a = D[Min].min()\n",
    "        b = D[Max].max()\n",
    "        print ('a, b = ', a, b)\n",
    "        \n",
    "    \n",
    "        \n",
    "#        E = D[abs(D[mprob]-0.50)<0.01]\n",
    "#        print (i)\n",
    "#        display(E)\n",
    "#        a = E['y_proba'].min()\n",
    "#        b = E['y_proba'].max()\n",
    "#        print (filename, mprob, a, b, b-a)\n",
    "\n",
    "        if not (math.isnan(a) or math.isnan(b)):\n",
    "        \n",
    "            D_tmp = D[D['y_proba']==a]\n",
    "            D_tmp = D_tmp[['y_proba',neg,pos,mprob,'TN','FP','FN','TP','FP/P']]\n",
    "            display(D_tmp)\n",
    "        \n",
    "            E = D[D['y_proba'] == b]\n",
    "            c = E['TP'].values[0]\n",
    "            d = D_tmp['TP'].values[0]\n",
    "            print ('c, d = ', c, d)\n",
    "        \n",
    "            D_tmp.insert(loc=0, column='TP_Diff', value=d-c)\n",
    "            D_tmp.insert(loc=0, column='TP(Max)', value=c)\n",
    "            D_tmp.insert(loc=0, column='TP(Min)', value=d)\n",
    "            D_tmp.insert(loc=0, column='y_proba_Diff', value=b-a)\n",
    "            D_tmp.insert(loc=0, column='y_proba_Max', value=b)\n",
    "            D_tmp.insert(loc=0, column='y_proba_Min', value=a)\n",
    "            D_tmp.insert(loc=0, column='Min/Max', value='Min')\n",
    "            D_tmp.insert(loc=0, column='Roll', value=mprob)\n",
    "            D_tmp.insert(loc=0, column='Filename', value=filename)        \n",
    "            D_tmp.to_csv('./Analyze_Proba/' + run + '/mProb_Rolling_0_500.csv', mode='a', index=True, header=False)\n",
    "            \n",
    "            D_tmp = D[D['y_proba']==b]\n",
    "            D_tmp = D_tmp[['y_proba',neg,pos,mprob,'TN','FP','FN','TP','FP/P']]\n",
    "        \n",
    "            D_tmp.insert(loc=0, column='TP_Diff', value=d-c)\n",
    "            D_tmp.insert(loc=0, column='TP(Max)', value=c)\n",
    "            D_tmp.insert(loc=0, column='TP(Min)', value=d)\n",
    "            D_tmp.insert(loc=0, column='y_proba_Diff', value=b-a)\n",
    "            D_tmp.insert(loc=0, column='y_proba_Max', value=b)\n",
    "            D_tmp.insert(loc=0, column='y_proba_Min', value=a)\n",
    "            D_tmp.insert(loc=0, column='Min/Max', value='Max')\n",
    "            D_tmp.insert(loc=0, column='Roll', value=mprob)\n",
    "            D_tmp.insert(loc=0, column='Filename', value=filename)        \n",
    "            D_tmp.to_csv('./Analyze_Proba/' + run + '/mProb_Rolling_0_500.csv', mode='a', index=True, header=False)\n",
    "            \n",
    "\n",
    "    D.to_csv('./Analyze_Proba/' + run + '/' + filename + '_Rolling_Intervals.csv')\n",
    "    \n",
    "#    display(C)\n",
    "#    display(D)\n",
    "    \n",
    "def Create_File_for_Rolling_Intervals(run):\n",
    "    f = open('./Analyze_Proba/' + run + '/Prec_Rolling_0_667.csv', 'w')\n",
    "    f.write('Index,Filename,Roll,Min/Max,Min,Max,Diff,y_proba,Prec,TN,FP,FN,TP,FP/P\\n')\n",
    "    f.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/' + run + '/mProb_Rolling_0_500.csv', 'w')\n",
    "    f.write('Index,Filename,Roll,Min/Max,y_proba_Min,y_proba_Max,y_proba_Diff,TP(Min),TP(Max),TP_Diff,y_proba,Neg,Pos,mprob,TN,FP,FN,TP,FP/P\\n')\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FP_P_Locate(y_proba, y_test, filename, run):\n",
    "    print ('FP_P_Locate() for ', filename)\n",
    "\n",
    "    A = pd.DataFrame(y_proba, columns=['y_proba'])\n",
    "    B = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    C = pd.concat([A,B], axis=1)\n",
    "    n = len(A)\n",
    "    P = C['y_test'].sum()\n",
    "    N = n - P\n",
    "    \n",
    "    # Sort the y_proba values with p==0 at the top.\n",
    "    \n",
    "    C.sort_values(by=['y_proba'], ascending=True, inplace=True)\n",
    "#    C = C.reset_index(drop=False)\n",
    "    \n",
    "    C['Neg'] = 1-C['y_test']\n",
    "    C['Pos'] = C['y_test']\n",
    "\n",
    "    D = C.groupby(['y_proba'], as_index=False).sum()\n",
    "    \n",
    "    D['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] = D['Pos']/(D['Neg'] + D['Pos'])\n",
    "    D['TN'] = D['Neg'].cumsum()\n",
    "    D['FP'] = N - D['TN']\n",
    "    D['FN'] = D['Pos'].cumsum()\n",
    "    D['TP'] = P - D['FN']\n",
    "    D['FP/P'] = D['FP'] / P\n",
    "    D['Prec'] = D['TP'] / (D['FP'] + D['TP'])\n",
    "    D = D.loc[:,['y_proba','Neg','Pos','$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$','TN','FP','FN','TP','Prec','FP/P']]\n",
    "\n",
    "\n",
    "    D.insert(0, 'Filename', filename)\n",
    "    D.insert(0, 'len', len(D))\n",
    "    \n",
    "    # Find p value that gives FP/P closest to 5%\n",
    "    D_closest = D.iloc[(D['FP/P'] - 0.05).abs().argsort()[:1]].head(1)\n",
    "#    print (H_closest)\n",
    "    \n",
    "    D_closest.to_csv('./Analyze_Proba/' + run + '/FP_P_0_05.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "#    H_closest['Filename'] = H_closest['Filename'].str.replace('_','\\\\_')\n",
    "#    H_closest.to_csv('./Analyze_Proba/FP_P_0_05.tex', \n",
    "#        mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "#        index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \n",
    "    # Find p value that gives FP/P closest to 10%\n",
    "    D_closest = D.iloc[(D['FP/P'] - 0.10).abs().argsort()[:1]].head(1)\n",
    "#    print (H_closest)\n",
    "    \n",
    "    D_closest.to_csv('./Analyze_Proba/' + run + '/FP_P_0_10.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "#    H_closest['Filename'] = H_closest['Filename'].str.replace('_','\\\\_')\n",
    "#    H_closest.to_csv('./Analyze_Proba/FP_P_0_10.tex', \n",
    "#                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "#                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \n",
    "\n",
    "def Create_Files_for_FP_P(run):\n",
    "    print ('Create_Files_for_FP_P')\n",
    "    f = open('./Analyze_Proba/' + run + '/FP_P_0_05.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,p,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/FP_P_0_05.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/' + run + '/FP_P_0_10.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,p,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/FP_P_0_10.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f53a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze_Prediction(y_test, y_proba, filename, run, title):\n",
    "    print ('Analyze_Prediction() for ', filename)\n",
    "    \n",
    "    Value_Counts_y_proba(y_proba, filename, run)\n",
    "    FP_P_Locate(y_proba, y_test, filename, run)\n",
    "    \n",
    "#    print ('y_proba: ',y_proba)\n",
    "#    print ('y_test: ', y_test)\n",
    "    A = pd.DataFrame(y_proba, columns=['y_proba'])\n",
    "    B = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    C = pd.concat([A,B], axis=1)\n",
    "    \n",
    "    # Sort the y_proba values with p==1 at the top.\n",
    "    # Make a feature, 'custom_cut'\n",
    "    # Make a cut large enough that it has at least 1000 elements of each class.\n",
    "    # Do not cut between two y_proba of the same value; \n",
    "    #    keep going until you get to a different y_proba value.\n",
    "    # Label that cut \"0,\" and the next cut \"1,\" etc.\n",
    "    \n",
    "    C.sort_values(by=['y_proba'], ascending=False, inplace=True)\n",
    "    C = C.reset_index(drop=True)\n",
    "    C['custom_cut'] = 0\n",
    "    \n",
    "    n0 = 0\n",
    "    n1 = 0\n",
    "    j = 0\n",
    "    C['custom_cut'][0] = j\n",
    "    if C['y_test'][0]==0:\n",
    "        n0 += 1\n",
    "    else:\n",
    "        n1 += 1\n",
    "    for i in range (1,len(C)):\n",
    "#        if i%1000==0:\n",
    "#            print (i, j)\n",
    "        if (\n",
    "            min(n0,n1)>=1000 and \n",
    "            C['y_proba'][i] != C['y_proba'][i-1] \n",
    "        ):\n",
    "            n0 = 0\n",
    "            n1 = 0\n",
    "            j = j+1\n",
    "        if C['y_test'][i]==0:\n",
    "            n0 += 1\n",
    "        else:\n",
    "            n1 += 1\n",
    "        C['custom_cut'][i] = j\n",
    "    print (filename, ' has ', j, ' custom_cut intervals of minCut 1000')\n",
    "#    print (C)\n",
    "    \n",
    "    # Count the positive and negative elements in each of the custom_cuts\n",
    "    \n",
    "    D = C[C['y_test']==0]\n",
    "    E = C[C['y_test']==1]\n",
    "\n",
    "    F = D['custom_cut'].value_counts(sort=False).rename(\"Neg\")\n",
    "    G = E['custom_cut'].value_counts(sort=False).rename(\"Pos\")\n",
    "    H = pd.concat([F,G], axis=1, names=['Neg','Pos'])\n",
    "\n",
    "    H['index1'] = H.index\n",
    "    H.sort_values(by=['index1'], ascending=False, inplace=True)\n",
    "    H = H.reset_index()\n",
    "    H['TN'] = H['Neg'].cumsum()\n",
    "    H['FP'] = len(D) - H['TN']\n",
    "    H['FN'] = H['Pos'].cumsum()\n",
    "    H['TP'] = len(E) - H['FN']\n",
    "    H['Prec'] = H['TP']/(H['FP'] + H['TP'])\n",
    "    H['Rec'] = H['TP']/(H['FN'] + H['TP'])\n",
    "    H['FP/P'] = H['FP']/(H['FN'] + H['TP'])\n",
    "    \n",
    "\n",
    "    H['min'] = 0\n",
    "    H['max'] = 0\n",
    "    \n",
    "    for i in range (len(H)):\n",
    "        I = C[C['custom_cut']==H['index1'][i]]\n",
    "        H['min'][i] = I['y_proba'].min()\n",
    "        H['max'][i] = I['y_proba'].max()\n",
    "    \n",
    "    H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] = H['Pos']/(H['Neg']+H['Pos'])\n",
    "    \n",
    "    H = H.drop('index1', axis='columns')\n",
    "    H = H.loc[:,['min','max','Neg','Pos','$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$','TN','FP','FN','TP','Prec','Rec','FP/P']]\n",
    "\n",
    "    P = H.copy(deep=True)\n",
    "    \n",
    "    R = H['max'] - H['min']\n",
    "    r = R.min()\n",
    "    if r!=0:\n",
    "        s = math.log10(r)\n",
    "    else:\n",
    "        s=-10\n",
    "    t = int(-s)\n",
    "#    print ('R, r, s, t')\n",
    "#    print (R)\n",
    "#    print (r, s, t)\n",
    "    \n",
    "    if t < 2:\n",
    "        H['min']=H['min'].apply('{:.3f}'.format)\n",
    "        H['max']=H['max'].apply('{:.3f}'.format)\n",
    "    if t==2:\n",
    "        H['min']=H['min'].apply('{:.4f}'.format)\n",
    "        H['max']=H['max'].apply('{:.4f}'.format)\n",
    "    if t==3:\n",
    "        H['min']=H['min'].apply('{:.5f}'.format)\n",
    "        H['max']=H['max'].apply('{:.5f}'.format)\n",
    "    if t>4:\n",
    "        H['min']=H['min'].apply('{:.6f}'.format)\n",
    "        H['max']=H['max'].apply('{:.6f}'.format)\n",
    "    \n",
    "    H['Neg']=H['Neg'].apply('{:,}'.format)\n",
    "    H['Pos']=H['Pos'].apply('{:,}'.format)\n",
    "    H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$']=H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'].apply('{:.4f}'.format)\n",
    "    H['TN']=H['TN'].apply('{:,}'.format)\n",
    "    H['FP']=H['FP'].apply('{:,}'.format)\n",
    "    H['FN']=H['FN'].apply('{:,}'.format)\n",
    "    H['TP']=H['TP'].apply('{:,}'.format)\n",
    "    H['Prec']=H['Prec'].apply('{:.4f}'.format)\n",
    "    H['Rec']=H['Rec'].apply('{:.4f}'.format)\n",
    "    H['FP/P']=H['FP/P'].apply('{:.4f}'.format)\n",
    "    \n",
    "    H.to_csv('./Analyze_Proba/' + run + '/' + filename + '_1000_Slices.csv', index=True)\n",
    "\n",
    "    \"\"\"\n",
    "    H.to_latex(\n",
    "        './Analyze_Proba/' + filename + '_1000_Slices.tex', \n",
    "        index=True, \n",
    "#        float_format=\"{:.4f}\".format, \n",
    "        column_format='rrrrrrrrrrrrr',\n",
    "        escape=False\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "#    print (H)\n",
    "    \n",
    "    # Append CSV files with results from multiple models\n",
    "    P.insert(0, 'Filename', filename)\n",
    "    P.insert(0, 'len', len(P))\n",
    "    \n",
    "    P_closest = P.iloc[(P['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] - 0.333).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/' + run + '/mProb_0_333.csv', mode='a', \n",
    "        index=True, header=False, float_format=\"{:.2f}\".format)\n",
    "\n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/mProb_0_333.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, \n",
    "#                     float_format=\"{:.4f}\".format\n",
    "                    )\n",
    "    \"\"\"\n",
    "    \n",
    "    P_closest = P.iloc[(P['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] - 0.5).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/' + run + '/mProb_0_5.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/mProb_0_5.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \"\"\"\n",
    "    \n",
    "    P_closest = P.iloc[(P['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] - 0.667).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/' + run + '/mProb_0_667.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/mProb_0_667.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \"\"\"\n",
    "    \n",
    "    P_closest = P.iloc[(P['Prec'] - 0.333).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/' + run + '/Prec_0_333.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/Prec_0_333.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \"\"\"\n",
    "    \n",
    "    P_closest = P.iloc[(P['Prec'] - 0.5).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/' + run + '/Prec_0_5.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/Prec_0_5.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \"\"\"\n",
    "    \n",
    "    P_closest = P.iloc[(P['Prec'] - 0.667).abs().argsort()[:1]].head(1)\n",
    "    P_closest.to_csv('./Analyze_Proba/' + run + '/Prec_0_667.csv', mode='a', index=True, header=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    P_closest['Filename'] = P_closest['Filename'].str.replace('_','\\\\_')\n",
    "    P_closest.to_csv('./Analyze_Proba/Prec_0_667.tex', \n",
    "                     mode='a', sep='&', lineterminator='\\\\cr\\n',\n",
    "                    index=True, header=False, float_format=\"{:.4f}\".format)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "def Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, run, title, minCut):\n",
    "    filename = filename + '_' + str(minCut)\n",
    "    print ('Analyze_Prediction_Custom_Cut() for ', filename)\n",
    "    \n",
    "#    print ('y_proba: ',y_proba)\n",
    "#    print ('y_test: ', y_test)\n",
    "    A = pd.DataFrame(y_proba, columns=['y_proba'])\n",
    "    B = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    C = pd.concat([A,B], axis=1)\n",
    "    \n",
    "    # Sort the y_proba values with p==1 at the top.\n",
    "    # Make a feature, 'custom_cut'\n",
    "    # Make a cut large enough that it has at least 1000 elements of each class.\n",
    "    # Do not cut between two y_proba of the same value; \n",
    "    #    keep going until you get to a different y_proba value.\n",
    "    # Label that cut \"0,\" and the next cut \"1,\" etc.\n",
    "    \n",
    "    C.sort_values(by=['y_proba'], ascending=False, inplace=True)\n",
    "    C = C.reset_index(drop=True)\n",
    "    C['custom_cut'] = 0\n",
    "    \n",
    "    n0 = 0\n",
    "    n1 = 0\n",
    "    j = 0\n",
    "    C['custom_cut'][0] = j\n",
    "    if C['y_test'][0]==0:\n",
    "        n0 += 1\n",
    "    else:\n",
    "        n1 += 1\n",
    "    for i in range (1,len(C)):\n",
    "#        if i%1000==0:\n",
    "#            print (i, j)\n",
    "        if (\n",
    "            min(n0,n1)>=minCut and \n",
    "            C['y_proba'][i] != C['y_proba'][i-1] \n",
    "        ):\n",
    "            n0 = 0\n",
    "            n1 = 0\n",
    "            j = j+1\n",
    "        if C['y_test'][i]==0:\n",
    "            n0 += 1\n",
    "        else:\n",
    "            n1 += 1\n",
    "        C['custom_cut'][i] = j\n",
    "    print (filename, ' has ', j, ' custom_cut intervals of minCut ', minCut)\n",
    "#    print (C)\n",
    "    \n",
    "    # Count the positive and negative elements in each of the custom_cuts\n",
    "    \n",
    "    D = C[C['y_test']==0]\n",
    "    E = C[C['y_test']==1]\n",
    "\n",
    "    F = D['custom_cut'].value_counts(sort=False).rename(\"Neg\")\n",
    "    G = E['custom_cut'].value_counts(sort=False).rename(\"Pos\")\n",
    "    H = pd.concat([F,G], axis=1, names=['Neg','Pos'])\n",
    "    H = H.fillna(0)\n",
    "    H['Neg'] = H['Neg'].astype(int)\n",
    "    H['Pos'] = H['Pos'].astype(int)\n",
    "\n",
    "    H['index1'] = H.index\n",
    "    H.sort_values(by=['index1'], ascending=False, inplace=True)\n",
    "    H = H.reset_index()\n",
    "    H['TN'] = H['Neg'].cumsum()\n",
    "    H['TN'] = H['TN'].astype(int)\n",
    "    H['FP'] = len(D) - H['TN']\n",
    "    H['FP'] = H['FP'].astype(int)\n",
    "    H['FN'] = H['Pos'].cumsum()\n",
    "    H['FN'] = H['FN'].astype(int)\n",
    "    H['TP'] = len(E) - H['FN']\n",
    "    H['TP'] = H['TP'].astype(int)\n",
    "    H['Prec'] = H['TP']/(H['FP'] + H['TP'])\n",
    "    H['Rec'] = H['TP']/(H['FN'] + H['TP'])\n",
    "    H['FP/P'] = H['FP']/(H['FN'] + H['TP'])\n",
    "    \n",
    "\n",
    "    H['min'] = 0\n",
    "    H['max'] = 0\n",
    "    \n",
    "    for i in range (len(H)):\n",
    "        I = C[C['custom_cut']==H['index1'][i]]\n",
    "        H['min'][i] = I['y_proba'].min()\n",
    "        H['max'][i] = I['y_proba'].max()\n",
    "    \n",
    "    H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'] = H['Pos']/(H['Neg']+H['Pos'])\n",
    "    \n",
    "    H = H.drop('index1', axis='columns')\n",
    "    H = H.loc[:,['min','max','Neg','Pos','$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$','TN','FP','FN','TP','Prec','Rec','FP/P']]\n",
    "\n",
    "    P = H.copy(deep=True)\n",
    "    \n",
    "#    R = H['max'] - H['min']\n",
    "    R = H['min'].diff()\n",
    "    r = R.min()\n",
    "    if r!=0:\n",
    "        s = math.log10(r)\n",
    "    else:\n",
    "        s = -10\n",
    "    t = int(-s)\n",
    "#    print (R)\n",
    "#    print ('r, s, t = ', r, s, t)\n",
    "#    print ()\n",
    "    \n",
    "    if t < 2:\n",
    "        H['min']=H['min'].apply('{:.3f}'.format)\n",
    "        H['max']=H['max'].apply('{:.3f}'.format)\n",
    "    if t==2:\n",
    "        H['min']=H['min'].apply('{:.4f}'.format)\n",
    "        H['max']=H['max'].apply('{:.4f}'.format)\n",
    "    if t==3:\n",
    "        H['min']=H['min'].apply('{:.5f}'.format)\n",
    "        H['max']=H['max'].apply('{:.5f}'.format)\n",
    "    if t>4:\n",
    "        H['min']=H['min'].apply('{:.6f}'.format)\n",
    "        H['max']=H['max'].apply('{:.6f}'.format)\n",
    "    \n",
    "    H['Neg']=H['Neg'].apply('{:,}'.format)\n",
    "    H['Pos']=H['Pos'].apply('{:,}'.format)\n",
    "    H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$']=H['$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$'].apply('{:.4f}'.format)\n",
    "    H['TN']=H['TN'].apply('{:,}'.format)\n",
    "    H['FP']=H['FP'].apply('{:,}'.format)\n",
    "    H['FN']=H['FN'].apply('{:,}'.format)\n",
    "    H['TP']=H['TP'].apply('{:,}'.format)\n",
    "    H['Prec']=H['Prec'].apply('{:.4f}'.format)\n",
    "    H['Rec']=H['Rec'].apply('{:.4f}'.format)\n",
    "    H['FP/P']=H['FP/P'].apply('{:.4f}'.format)\n",
    "    \n",
    "    H.to_csv('./Analyze_Proba/' + run + '/' + filename + '_Slices.csv', index=True)\n",
    "\n",
    "    \"\"\"\n",
    "    H.to_latex(\n",
    "        './Analyze_Proba/' + filename + '_Slices.tex', \n",
    "        index=False, \n",
    "#        float_format=\"{:.4f}\".format, \n",
    "        column_format='rrrrrrrrrrrrr',\n",
    "        escape=False\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def Create_Files_for_Analyze_Prediction(run):\n",
    "    print ('Create_Files_for_Analyze_Prediction()')\n",
    "    f = open('./Analyze_Proba/' + run + '/mProb_0_5.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/mProb_0_5.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/' + run + '/mProb_0_667.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/mProb_0_667.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/' + run + '/mProb_0_333.csv', 'w')\n",
    "    f.write(\"Index,,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/mProb_0_333.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/' + run + '/Prec_0_5.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/Prec_0_5.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/' + run + '/Prec_0_667.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/Prec_0_667.tex', 'w')\n",
    "#    g.write(\"Index & len & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "    f = open('./Analyze_Proba/' + run + '/Prec_0_333.csv', 'w')\n",
    "    f.write(\"Index,len,Filename,min,max,Neg,Pos,$\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$,TN,FP,FN,TP,Prec,Rec,FP/P\\n\")\n",
    "    f.close()\n",
    "#    g = open('./Analyze_Proba/Prec_0_333.tex', 'w')\n",
    "#    g.write(\"Index & Filename & min & max & Neg & Pos & $\\\\frac{\\\\text{Pos}}{\\\\text{Neg}+\\\\text{Pos}}$ & TN & FP & FN & TP & Prec & Rec & FP/P \\\\cr\\\\hline\\n\")\n",
    "#    g.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e092785",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Test_Plot_Prediction_Zoom():\n",
    "    print ('Idealized_Results()')\n",
    "    # Set randomness\n",
    "    np.random.seed(42) # NumPy\n",
    "    random.seed(42) # Python\n",
    "    tf.random.set_seed(42) # Tensorflow    \n",
    "\n",
    "    shape, scale = 3.7, 0.1 # mean=4, std=2*sqrt(2)\n",
    "    a = np.random.gamma(shape, scale, 150771)\n",
    "    a = np.where(a>1.0, random.random(), a)\n",
    "    \n",
    "    shape, scale = 3.8, 0.1 # mean=4, std=2*sqrt(2)\n",
    "    b = np.random.gamma(shape, scale, 26621)    \n",
    "    b = np.where(b>1.0, random.random(), b)\n",
    "    b = 1-b\n",
    "    \n",
    "    y_proba = np.concatenate((a,b),axis=0)\n",
    "    y_pred = K.round(y_proba)\n",
    "    y_test = [0]*len(a) + [1]*len(b)  \n",
    "    \n",
    "    display(y_proba[:20])\n",
    "    display(y_pred[:20])\n",
    "    \n",
    "    Plot_Prediction(y_test, y_proba, 'Test', 'Test')    \n",
    "    Plot_Prediction_Wide(y_test, y_proba, 'Test', 'Test')    \n",
    "    Plot_Prediction_Zoom(y_test, y_proba, 'Test', 'Test', 0.45, 0.55)\n",
    "    Analyze_Prediction(y_test, y_proba, 'Test', 'Test')    \n",
    "    \n",
    "#Test_Plot_Prediction_Zoom()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a04113",
   "metadata": {},
   "source": [
    "## Plot ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e088e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC(y_test, y_proba, p_values, filename, run):\n",
    "    print ('ROC() for ', filename)\n",
    "    print (np.isnan(y_test).any())\n",
    "    print (np.isnan(y_proba).any())\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    \n",
    "    A = np.asarray((fpr,tpr)).T\n",
    "#    print ()\n",
    "#    print ('len(fpr/tpr) = ', len(A))\n",
    "#    print (A[:10])\n",
    "    A = np.unique(A, axis=0)\n",
    "#    print (A[:10])\n",
    "    nU = len(A)\n",
    "#    print ('Unique fpr/tpr = ', nU)\n",
    "#    print ()\n",
    "    \n",
    "    f = open('./Analyze_Proba/' + run + '/Lengths_of_fpr_tpr.csv', 'a')\n",
    "    f.write('%s,' % (filename))\n",
    "    f.write('%d,' % len(y_proba))\n",
    "    f.write('%d,' % len(np.unique(y_proba)))\n",
    "    f.write('%d,' % len(fpr))\n",
    "    f.write('%d,' % len(np.unique(fpr)))\n",
    "    f.write('%d,' % len(tpr))\n",
    "    f.write('%d,' % len(np.unique(tpr)))\n",
    "    f.write('%d,' % len(np.asarray((fpr,tpr)).T))\n",
    "    f.write('%d,' % len(np.unique(np.asarray((fpr,tpr)).T, axis=0)))\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "#    print ('N_median, P_median = ', N_median, P_median)\n",
    "\n",
    "    m = np.quantile(y_proba,0.50)\n",
    "    p = np.quantile(y_proba,0.25)\n",
    "    q = np.quantile(y_proba,0.75)\n",
    "    \n",
    "    Y = []\n",
    "#    print ('p_values = ', p_values)\n",
    "    for X in p_values:\n",
    "        difference_array = np.absolute(thresholds-X)\n",
    "        index = difference_array.argmin()\n",
    "        F = fpr[index]\n",
    "        T = tpr[index]\n",
    "        Y.append([X,str(round(X,3)),F,T])\n",
    "    \n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_value = round(auc_value,3)\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, color='black', label='AUC={:.3f}'.format(auc_value))\n",
    "    \n",
    "    for y in Y:\n",
    "#        plt.plot([y[2]], [y[3]], marker=\"o\", markersize=20, markeredgecolor=\"white\", markerfacecolor=\"white\")\n",
    "        plt.plot([y[2]], [y[3]], marker=\"o\", markersize=5, markeredgecolor=\"black\", markerfacecolor=\"black\")\n",
    "#        plt.annotate(\n",
    "#            y[1], # this is the text\n",
    "#            (y[2], y[3]), # these are the coordinates to position the label\n",
    "#            ha='center' # horizontal alignment can be left, right or center\n",
    "#        )\n",
    "#        plt.text(\n",
    "#            y[2], y[3], # these are the coordinates to position the label\n",
    "#            y[1], # this is the text\n",
    "#            backgroundcolor='white', # horizontal alignment can be left, right or center\n",
    "#            bbox=dict(facecolor='white', edgecolor='none', boxstyle='square,pad=0.3')\n",
    "#        )\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "#    plt.title('ROC with AUC {:.3f}'.format(auc_value))\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_ROC.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_ROC.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    print ('./Images/' + run + '/' + filename + '_ROC.png')\n",
    "#    plt.show()\n",
    "#    plt.close()\n",
    "    print ()\n",
    "    return 0\n",
    "\n",
    "def Test_ROC():\n",
    "    y_test = [0,0,0,0,0,1]*10000\n",
    "#    y_proba = [abs(0.45 - y)+round(0.45*random.random(),2) for y in y_test]\n",
    "    y_proba = [abs(0.45 - y)+round(0.45*random.normalvariate(mu=0.2, sigma=0.2),3) for y in y_test]\n",
    "#    random.normalvariate(mu=0.0, sigma=1.0)\n",
    "    y_test = np.array(y_test)\n",
    "    y_proba = np.array(y_proba)\n",
    "    print (y_test)\n",
    "    print (y_proba)\n",
    "    ROC(y_test, y_proba, [0.5], \"tmp\")\n",
    "    \n",
    "#Test_ROC()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_Legend_Top(y_test, y_proba, p_values, filename, run):\n",
    "    print ('ROC() for ', filename)\n",
    "    print (np.isnan(y_test).any())\n",
    "    print (np.isnan(y_proba).any())\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    \n",
    "    A = np.asarray((fpr,tpr)).T\n",
    "#    print ()\n",
    "#    print ('len(fpr/tpr) = ', len(A))\n",
    "#    print (A[:10])\n",
    "    A = np.unique(A, axis=0)\n",
    "#    print (A[:10])\n",
    "    nU = len(A)\n",
    "#    print ('Unique fpr/tpr = ', nU)\n",
    "#    print ()\n",
    "    \n",
    "    \n",
    "    N_median = np.median(y_proba[np.array(y_test)==0])\n",
    "    P_median = np.median(y_proba[np.array(y_test)==1])\n",
    "#    print ('N_median, P_median = ', N_median, P_median)\n",
    "\n",
    "    m = np.quantile(y_proba,0.50)\n",
    "    p = np.quantile(y_proba,0.25)\n",
    "    q = np.quantile(y_proba,0.75)\n",
    "    \n",
    "    Y = []\n",
    "#    print ('p_values = ', p_values)\n",
    "    for X in p_values:\n",
    "        difference_array = np.absolute(thresholds-X)\n",
    "        index = difference_array.argmin()\n",
    "        F = fpr[index]\n",
    "        T = tpr[index]\n",
    "        Y.append([X,str(round(X,3)),F,T])\n",
    "    \n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_value = round(auc_value,3)\n",
    "    fig = plt.figure(figsize=(2.0,1.5)) # Create matplotlib figure\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, color='black', label='AUC={:.3f}'.format(auc_value))\n",
    "    \n",
    "    for y in Y:\n",
    "#        plt.plot([y[2]], [y[3]], marker=\"o\", markersize=20, markeredgecolor=\"white\", markerfacecolor=\"white\")\n",
    "        plt.plot([y[2]], [y[3]], marker=\"o\", markersize=5, markeredgecolor=\"black\", markerfacecolor=\"black\")\n",
    "#        plt.annotate(\n",
    "#            y[1], # this is the text\n",
    "#            (y[2], y[3]), # these are the coordinates to position the label\n",
    "#            ha='center' # horizontal alignment can be left, right or center\n",
    "#        )\n",
    "#        plt.text(\n",
    "#            y[2], y[3], # these are the coordinates to position the label\n",
    "#            y[1], # this is the text\n",
    "#            backgroundcolor='white', # horizontal alignment can be left, right or center\n",
    "#            bbox=dict(facecolor='white', edgecolor='none', boxstyle='square,pad=0.3')\n",
    "#        )\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "#    plt.title('ROC with AUC {:.3f}'.format(auc_value))\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.40))\n",
    "#    plt.legend(loc='best')\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_ROC_Legend_Top.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('./Images/' + run + '/' + filename + '_ROC_Legend_Top.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    print ('./Images/' + run + '/' + filename + '_ROC.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print ()\n",
    "    return 0\n",
    "\n",
    "def Test_ROC():\n",
    "    y_test = [0,0,0,0,0,1]*10000\n",
    "#    y_proba = [abs(0.45 - y)+round(0.45*random.random(),2) for y in y_test]\n",
    "    y_proba = [abs(0.45 - y)+round(0.45*random.normalvariate(mu=0.2, sigma=0.2),3) for y in y_test]\n",
    "#    random.normalvariate(mu=0.0, sigma=1.0)\n",
    "    y_test = np.array(y_test)\n",
    "    y_proba = np.array(y_proba)\n",
    "    print (y_test)\n",
    "    print (y_proba)\n",
    "    ROC(y_test, y_proba, [0.5], \"tmp\")\n",
    "    \n",
    "#Test_ROC()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_Custom_Cuts(y_test, y_proba, y_pred, filename, title, run):\n",
    "    print ('Do_Custom_Cuts()')\n",
    "    \n",
    "    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 6400)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 3200)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 1600)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 800)\n",
    "    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 400)\n",
    "    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 200)\n",
    "    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 100)\n",
    "    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 50)\n",
    "    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 25)\n",
    "    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 10)\n",
    "    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 5)\n",
    "#    Analyze_Prediction_Custom_Cut(y_test, y_proba, filename, title, run, 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52566066",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72178501",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Analyze_Results(run):\n",
    "    print ('Analyze_Results()')\n",
    "    \n",
    "    Models = [\n",
    "#        'AdaBoost',\n",
    "#        'BalBag',\n",
    "        'BRFC_alpha_0_5',\n",
    "        'BRFC_alpha_0_6',\n",
    "        'BRFC_alpha_0_7',\n",
    "        'BRFC_alpha_0_8',\n",
    "        'BRFC_alpha_0_85',\n",
    "        'BRFC_alpha_0_9',\n",
    "        'BRFC_alpha_0_95',\n",
    "#        'BRFC_alpha_balanced',\n",
    "#        'EEC',\n",
    "#        'KBFC_alpha_0_5_gamma_0_0',\n",
    "#        'KBFC_alpha_balanced_gamma_0_0',\n",
    "#        'KBFC_alpha_0_5_gamma_1_0',\n",
    "#        'KBFC_alpha_0_5_gamma_2_0',\n",
    "#        'LogReg_alpha_0_5',\n",
    "#        'LogReg_alpha_balanced',\n",
    "#        'RFC',\n",
    "#        'RUSBoost',\n",
    "    ]\n",
    "    \n",
    "    for model in Models:\n",
    "        for features in [\n",
    "            '_Hard_Run_0', \n",
    "#            '_Hard_Run_1', \n",
    "#            '_Hard_Run_2',\n",
    "#            '_Hard_Run_3',\n",
    "            '_Medium_Run_0', \n",
    "#            '_Medium_Run_1', \n",
    "#            '_Medium_Run_3', \n",
    "            '_Easy_Run_0',\n",
    "#            '_Easy_Run_1',\n",
    "#            '_Easy_Run_3',\n",
    "        ]:\n",
    "            print ()\n",
    "            print ('-------------------------------------')\n",
    "            print ()\n",
    "            filename = model + features\n",
    "            print (filename)\n",
    "            df = pd.read_csv('../../Big_Files/' + filename + '.csv')\n",
    "            \n",
    "            print (len(df))\n",
    "            df.dropna(inplace=True)\n",
    "            print (len(df))\n",
    "            \n",
    "            m = df['y_proba'].min()\n",
    "            M = df['y_proba'].max()\n",
    "            num_prec = 4 - int(math.log10(M-m))\n",
    "            print ('num_prec = ', num_prec)\n",
    "\n",
    "            y_test = df['y_test'].to_numpy()\n",
    "            y_proba = df['y_proba'].to_numpy()\n",
    "            y_pred = df['y_pred'].to_numpy()\n",
    "            Chart_and_Plots(y_test, y_proba, y_pred, filename, run, '')\n",
    "#            Do_Custom_Cuts(y_test, y_proba, y_pred, filename, run, '')\n",
    "\n",
    "            ### Danger, Will Robinson!  Creates files ~ 400 M, which will make GitHub panic\n",
    "            ### I put a \"return 0\" in the function to just have it go \n",
    "            ### to the point where it gives the full results file without rolling\n",
    "#            Rolling_Intervals(y_proba, y_test, filename, run)\n",
    "\n",
    "#            Rolling_Intervals(np.round(y_proba,num_prec), y_test, filename + '_Round_' + str(num_prec), run)\n",
    "            print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a86579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comment out these lines if you just want to append to the files, not recreate them.\n",
    "run = 'Run_0'\n",
    "Create_Files_for_Value_Counts_y_proba(run)\n",
    "Create_Files_for_Analyze_Prediction(run)\n",
    "Create_Files_for_Lengths_of_fpr_tpr(run)\n",
    "Create_Files_for_ROC_AUC(run)\n",
    "Create_Files_for_FP_P(run)\n",
    "Create_File_for_Rolling_Intervals(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb852de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "run = 'Run_0'\n",
    "Analyze_Results(run)\n",
    "# 5min 42s for one model\n",
    "# 13 * 6 = 78 models\n",
    "# 4h 42 min total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f061bd30",
   "metadata": {},
   "source": [
    "## Dissertation Illustrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c20a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Prediction_Wide_Threshold_Dissertation(y_test, y_proba, threshold, filename, title):\n",
    "    print ('Plot_Prediction()')\n",
    "    print (filename)\n",
    "    \n",
    "#    print ('y_test = ', y_test)\n",
    "#    print ('y_proba = ',y_proba)\n",
    "\n",
    "#    y_test = y_test.numpy()\n",
    "    A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\n",
    "    B = pd.DataFrame(y_test, columns=['HOSPITAL'])\n",
    "    B = B.reset_index(drop=True)\n",
    "    C = A[B['HOSPITAL']==0]\n",
    "    D = A[B['HOSPITAL']==1]\n",
    "    TN = C[A['HOSPITAL'] <= threshold]\n",
    "    FP = C[A['HOSPITAL'] > threshold]\n",
    "    FN = D[A['HOSPITAL'] <= threshold]\n",
    "    TP = D[A['HOSPITAL'] > threshold]\n",
    "    print (\"len(C), len(D), len(TN), len(FP), len(FN), len(TP)\")\n",
    "    print (len(C), len(D), len(TN), len(FP), len(FN), len(TP))\n",
    "    print ()\n",
    "#    print (\"A = pd.DataFrame(y_proba, columns=['HOSPITAL'])\")\n",
    "#    display(A)\n",
    "#    print (\"B = pd.DataFrame(y_test, columns=['HOSPITAL'])\")\n",
    "#    display(B)\n",
    "#    print (\"C = A[B['HOSPITAL']==0]\")\n",
    "#    display(C)\n",
    "#    print (\"D = A[B['HOSPITAL']==1]\")\n",
    "#    display(D)\n",
    "    n = 20\n",
    "#    bins= [x/n - 1/(2*n) for x in range (-1, n+3)]\n",
    "    bins= [x/n for x in range (-1, n+1)]\n",
    "#    print ('Bins = ', bins)\n",
    "    TN_cut = pd.cut(TN['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    FP_cut = pd.cut(FP['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    FN_cut = pd.cut(FN['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "    TP_cut = pd.cut(TP['HOSPITAL'], bins=bins, include_lowest=True)\n",
    "#    print (\"E = pd.cut(C['HOSPITAL'], bins=bins, include_lowest=True)\")\n",
    "#    display(E)\n",
    "#    print (\"F = pd.cut(D['HOSPITAL'], bins=bins, include_lowest=True)\")\n",
    "#    display(F)\n",
    "    \n",
    "    TN_vc = TN_cut.value_counts(sort=False)\n",
    "    FP_vc = FP_cut.value_counts(sort=False)\n",
    "    FN_vc = FN_cut.value_counts(sort=False)\n",
    "    TP_vc = TP_cut.value_counts(sort=False)\n",
    "\n",
    "    TN_vc = TN_vc/len(y_proba)*100\n",
    "    FP_vc = FP_vc/len(y_proba)*100\n",
    "    FN_vc = FN_vc/len(y_proba)*100\n",
    "    TP_vc = TP_vc/len(y_proba)*100\n",
    "    print (\"len(TP_vc) = \", len(TP_vc))\n",
    "\n",
    "    fig = plt.figure(figsize=(4.5,1.5)) # Create matplotlib figure\n",
    "    ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "    \n",
    "    Fake = [0.0]*21\n",
    "    Fake = pd.Series(Fake)\n",
    "    \n",
    "    tn_p = round(len(TN)/len(y_proba)*100,1)\n",
    "    fp_p = round(len(FP)/len(y_proba)*100,1)\n",
    "    fn_p = round(len(FN)/len(y_proba)*100,1)\n",
    "    tp_p = round(len(TP)/len(y_proba)*100,1)\n",
    "#    tns = '\\\\begin{tabular}{@{}p{.45in}p{.5in}}TN & \\\\hfill ' + str(tn) + '\\\\%\\\\cr\\\\end{tabular}'\n",
    "#    fps = '\\\\begin{tabular}{@{}p{.45in}p{.5in}}FP & \\\\hfill ' + str(fp) + '\\\\%\\\\cr\\\\end{tabular}'\n",
    "#    fns = '\\\\begin{tabular}{@{}p{.45in}p{.5in}}FN & \\\\hfill ' + str(fn) + '\\\\%\\\\cr\\\\end{tabular}'\n",
    "#    tps = '\\\\begin{tabular}{@{}p{.45in}p{.5in}}TP & \\\\hfill ' + str(tp) + '\\\\%\\\\cr\\\\end{tabular}'\n",
    "    \n",
    "    tn = '{:,}'.format(len(TN))\n",
    "    fp = '{:,}'.format(len(FP))\n",
    "    fn = '{:,}'.format(len(FN))\n",
    "    tp = '{:,}'.format(len(TP))\n",
    "    tns = '\\\\begin{tabular}{@{}p{.25in}@{}p{.7in}@{}p{.6in}}TN & \\\\hfill ' + str(tn) + ' & \\\\hfill ' + str(tn_p) + '\\\\%\\\\cr\\\\end{tabular}'\n",
    "    fps = '\\\\begin{tabular}{@{}p{.25in}@{}p{.7in}@{}p{.6in}}FP & \\\\hfill ' + str(fp) + ' & \\\\hfill ' + str(fp_p) + '\\\\%\\\\cr\\\\end{tabular}'\n",
    "    fns = '\\\\begin{tabular}{@{}p{.25in}@{}p{.7in}@{}p{.6in}}FN & \\\\hfill ' + str(fn) + ' & \\\\hfill ' + str(fn_p) + '\\\\%\\\\cr\\\\end{tabular}'\n",
    "    tps = '\\\\begin{tabular}{@{}p{.25in}@{}p{.7in}@{}p{.6in}}TP & \\\\hfill ' + str(tp) + ' & \\\\hfill ' + str(tp_p) + '\\\\%\\\\cr\\\\end{tabular}'\n",
    "    \n",
    "    \n",
    "    precision = len(TP)/(len(FP)+len(TP))\n",
    "    recall = len(TP)/(len(FN)+len(TP))\n",
    "    fp_p = len(FP)/(len(FN)+len(TP))\n",
    "    f1 = 2/(1/precision + 1/recall)\n",
    "\n",
    "    precision = round(precision,3)\n",
    "    recall = round(recall, 3)\n",
    "    fp_p = round(fp_p,3)   \n",
    "    f1 = round(f1,3)   \n",
    "\n",
    "    precision = '{:<05}'.format(precision)\n",
    "    recall = '{:<05}'.format(recall)\n",
    "    fp_p = '{:<05}'.format(fp_p)\n",
    "    f1 = '{:<05}'.format(f1)\n",
    "\n",
    "    prs = '\\\\begin{tabular}{@{}p{.45in}p{.5in}}Precision & \\\\hfill ' + str(precision) + ' \\\\cr\\\\end{tabular}'\n",
    "    res = '\\\\begin{tabular}{@{}p{.45in}p{.5in}}Recall & \\\\hfill ' + str(recall) + ' \\\\cr\\\\end{tabular}'\n",
    "    fp_p = '\\\\begin{tabular}{@{}p{.45in}p{.5in}}FP/P & \\\\hfill ' + str(fp_p) + ' \\\\cr\\\\end{tabular}'\n",
    "    f1s = '\\\\begin{tabular}{@{}p{.45in}p{.5in}}F1 & \\\\hfill ' + str(f1) + ' \\\\cr\\\\end{tabular}'\n",
    "    \n",
    "    p = TN_vc.plot(kind='bar', edgecolor='k', fill=False, ax=ax, width=0.35, position=0)\n",
    "    q = FP_vc.plot(kind='bar', edgecolor='#ce181e', fill=False, ax=ax, width=0.35, position=0)\n",
    "    r = FN_vc.plot(kind='bar', color='#ce181e', fill=True, ax=ax, width=0.35, position=1)\n",
    "    s = TP_vc.plot(kind='bar', color='k', fill=True, ax=ax, width=0.35, position=1)\n",
    "    t = Fake.plot(kind='bar', edgecolor='w', color='w', fill=False, ax=ax, width=0.0, position=1)\n",
    "    u = Fake.plot(kind='bar', edgecolor='w', color='w', fill=False, ax=ax, width=0.0, position=1)\n",
    "    v = Fake.plot(kind='bar', edgecolor='w', color='w', fill=False, ax=ax, width=0.0, position=1)\n",
    "#    t = plt.axhline(y = 0.0, color = 'k', linestyle = '-', linewidth=0.0) \n",
    "    ticks = [n/20*i for i in range (-1,22)]\n",
    "#    print ('ticks = ', ticks)\n",
    "    plt.xticks(\n",
    "        ticks = ticks,\n",
    "        labels = ['','0.0', '', '0.1', '', '0.2', '', '0.3', '', '0.4', '', '0.5', '', '0.6', '', '0.7', '', '0.8', '', '0.9', '', '1.0', ''],\n",
    "        rotation=0\n",
    "    )\n",
    "\n",
    "\n",
    "    ax.legend(\n",
    "        [\n",
    "            tns,\n",
    "            fps,\n",
    "            fns,\n",
    "            tps,\n",
    "            prs,\n",
    "            res,\n",
    "#            f1s,\n",
    "            fp_p\n",
    "        ], \n",
    "         loc='upper left', ncol=1, bbox_to_anchor=(1, 1.1),\n",
    "        labelspacing=0.15,\n",
    "        frameon = False\n",
    "         )\n",
    "#    plt.title(title)\n",
    "    plt.xlabel('$p$')\n",
    "    plt.ylabel('Percent of Dataset')\n",
    "    ax.yaxis.set_label_coords(-0.1,0.4)    \n",
    "    \n",
    "    if threshold>0:\n",
    "        plt.axvline(20*threshold, color='k', linestyle='dashed', linewidth=1)\n",
    "\n",
    "        min_ylim, max_ylim = plt.ylim()\n",
    "        if (threshold<0.8):\n",
    "            plt.text(threshold*21, max_ylim*0.825, '$\\\\theta =  {}$'.format(threshold), horizontalalignment='left')\n",
    "        else:\n",
    "            plt.text(threshold*19, max_ylim*0.825, '$\\\\theta =  {}$'.format(threshold), horizontalalignment='right')\n",
    "    \n",
    "        patch_indices = [x for x in range (21) if x/20 >= threshold]\n",
    "        for patch_index in patch_indices:\n",
    "            p.patches[patch_index].set_color('#ce181e')\n",
    "\n",
    "    \n",
    "    \n",
    "#    plt.savefig('../../Dissertation_03_26_24/Figures/' + filename + '_Pred_Wide_Threshold.png', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.savefig('../../Dissertation_03_26_24/Figures/' + filename + '_Pred_Wide_Threshold.pgf', bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    print ('../../Dissertation_03_26_24/Figures/' + filename + '_Pred_Wide_Threshold.pgf')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print ()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ac348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dissertation_Illustrations(filename, threshold):\n",
    "    matplotlib.rcParams.update({\n",
    "    #    \"pgf.texsystem\": \"pdflatex\",\n",
    "        'font.family': 'serif',\n",
    "        'text.usetex': True,\n",
    "        'pgf.rcfonts': False,\n",
    "        'font.size': 12,\n",
    "    })\n",
    "    \n",
    "    title = ''\n",
    "    \n",
    "    df = pd.read_csv('../../Big_Files/' + filename + '.csv')\n",
    "    \n",
    "    print (len(df))\n",
    "    df.dropna(inplace=True)\n",
    "    print (len(df))\n",
    "            \n",
    "    m = df['y_proba'].min()\n",
    "    M = df['y_proba'].max()\n",
    "    num_prec = 4 - int(math.log10(M-m))\n",
    "    print ('min = ', m, ', max = ', M, ', num_prec = ', num_prec)\n",
    "\n",
    "    y_test = df['y_test'].to_numpy()\n",
    "    y_proba = df['y_proba'].to_numpy()\n",
    "    y_pred = df['y_pred'].to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    Plot_Prediction_Wide_Threshold_Dissertation(y_test, y_proba, threshold, filename, title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0726f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for filename, threshold in [\n",
    "    ['BRFC_alpha_0_5_Hard_Run_3', 0.86],\n",
    "    ['BRFC_alpha_0_5_Medium_Run_3', 0.89],\n",
    "    ['BRFC_alpha_0_5_Easy_Run_3', 0.8873],\n",
    "    ['KBFC_alpha_0_5_gamma_2_0_Hard_Run_3', 0.5446],\n",
    "]:\n",
    "    Dissertation_Illustrations(filename, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907c22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023920e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c3ecf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_2_11",
   "language": "python",
   "name": "tensorflow_2_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
