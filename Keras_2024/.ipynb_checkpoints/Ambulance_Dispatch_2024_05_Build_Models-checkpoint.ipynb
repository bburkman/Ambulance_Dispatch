{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767154e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\tableofcontents\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea489d64",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa423799",
   "metadata": {},
   "source": [
    "- We will build models reflecting three levels of available data\n",
    "    - \"Easy\" is mostly data already available to the emergency dispatcher before the notification comes in, like month, day of week, hour, weather, urban/rural, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e2353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97e1d2b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7d47d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122b4fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install Packages\n",
      "Python version: 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:26:08) [Clang 14.0.6 ]\n",
      "NumPy version: 1.24.2\n",
      "SciPy version:  1.7.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bburkman/miniforge3/envs/Tensorflow_2_11/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.11.0\n",
      "Keras version:  2.11.0\n",
      "Pandas version:  1.5.3\n",
      "SciKit-Learn version: 1.2.2\n",
      "Imbalanced-Learn version: 0.10.1\n",
      "Finished Installing Packages\n"
     ]
    }
   ],
   "source": [
    "print ('Install Packages')\n",
    "\n",
    "import sys, copy, math, time, os\n",
    "\n",
    "print ('Python version: {}'.format(sys.version))\n",
    "\n",
    "#from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import scipy as sc\n",
    "print ('SciPy version:  {}'.format(sc.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print ('TensorFlow version:  {}'.format(tf.__version__))\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "from tensorflow import keras\n",
    "print ('Keras version:  {}'.format(keras.__version__))\n",
    "\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "#from keras.layers import IntegerLookup\n",
    "#from keras.layers import Normalization\n",
    "#from keras.layers import StringLookup\n",
    "#from keras.utils import get_custom_objects\n",
    "#from keras.utils import tf_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import pandas as pd\n",
    "print ('Pandas version:  {}'.format(pd.__version__))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "#    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Library for reading Microsoft Access files\n",
    "#import pandas_access as mdb\n",
    "\n",
    "import sklearn\n",
    "print ('SciKit-Learn version: {}'.format(sklearn.__version__))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import imblearn\n",
    "print ('Imbalanced-Learn version: {}'.format(imblearn.__version__))\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "#!pip install pydot\n",
    "\n",
    "# Set Randomness.  Copied from https://www.kaggle.com/code/abazdyrev/keras-nn-focal-loss-experiments\n",
    "import random\n",
    "#np.random.seed(42) # NumPy\n",
    "#random.seed(42) # Python\n",
    "#tf.random.set_seed(42) # Tensorflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print ('Finished Installing Packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437f109",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919fb2db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Get_Data(Features):\n",
    "    print ('Get_Data()')\n",
    "    if Features==1:\n",
    "        data = pd.read_csv(\n",
    "        '../../Big_Files/CRSS_Imputed.csv',\n",
    "        low_memory=False\n",
    "    )\n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Get_Data()')\n",
    "    print ()\n",
    "    return data\n",
    "\n",
    "def Test_Get_Data():\n",
    "    data = Get_Data()\n",
    "    display (data.head())\n",
    "    \n",
    "#Test_Get_Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146091c",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb9dce",
   "metadata": {},
   "source": [
    "## Engineer Features\n",
    "- AGE_x_SEX\n",
    "    - We had found that the correlation between age and hospitalization varied by sex, so we made a new feature that captured the complexities\n",
    "- AGE_x_SCH_BUS\n",
    "    - We also found that those on a school bus had different rates of hospitalization based on age, so we created this more complex feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85fa858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Engineering_Cross_Two(data):\n",
    "    print ('Feature_Engineering_Cross_Two')\n",
    "    Pairs = [\n",
    "        ['AGE', 'SEX', 'AGE_x_SEX'],\n",
    "        ['AGE', 'SCH_BUS', 'AGE_x_SCH_BUS']\n",
    "    ]\n",
    "    for P in Pairs:\n",
    "        data[P[2]] = data[P[0]].map(str) + '_x_' + data[P[1]].map(str)\n",
    "    \n",
    "    print ()\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b900000",
   "metadata": {},
   "source": [
    "## Thin Features \n",
    "### Thin Features to only \"Hard\" Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a0c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Thin_to_Hard_Features(data):\n",
    "    print ('Thin_to_Hard_Features()')\n",
    "\n",
    "    Merge = [\n",
    "        'CASENUM',\n",
    "        'VEH_NO',\n",
    "        'PER_NO',        \n",
    "    ]\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "        'INT_HWY',\n",
    "        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "        'PERMVIT',\n",
    "#        'PERNOTMVIT', # Pedestrians, which we have taken out\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "        'PVH_INVL',\n",
    "        'REGION',\n",
    "        'REL_ROAD',\n",
    "        'RELJCT1',\n",
    "        'RELJCT2',\n",
    "        'SCH_BUS',\n",
    "        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "        'VE_FORMS',\n",
    "        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "        'BODY_TYP',\n",
    "        'BUS_USE',\n",
    "        'EMER_USE',\n",
    "        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "        'MODEL',\n",
    "        'NUMOCCS',\n",
    "        'VALIGN',\n",
    "        'VNUM_LAN',\n",
    "        'VPROFILE',\n",
    "        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "        'VTRAFCON',\n",
    "        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "        'AGE',\n",
    "#        'LOCATION', # Pedestrian location; taken out\n",
    "        'PER_TYP',\n",
    "        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "        'VEH_AGE',\n",
    "        'AGE_x_SEX',\n",
    "        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_to_Hard_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Thin_to_Hard_Features():\n",
    "    data = Get_Data()\n",
    "    data = Thin_to_Hard_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "#Test_Thin_to_Hard_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e759eda",
   "metadata": {},
   "source": [
    "### Thin Features to \"Medium\" Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4202cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Thin_to_Medium_Features(data):\n",
    "    print ('Thin_to_Medium_Features()')\n",
    "\n",
    "    Merge = [\n",
    "        'CASENUM',\n",
    "        'VEH_NO',\n",
    "        'PER_NO',        \n",
    "    ]\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "        'INT_HWY',\n",
    "#        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "#        'PERMVIT',\n",
    "#        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "#        'PVH_INVL',\n",
    "        'REGION',\n",
    "        'REL_ROAD',\n",
    "        'RELJCT1',\n",
    "#        'RELJCT2',\n",
    "#        'SCH_BUS',\n",
    "        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "#        'VE_FORMS',\n",
    "#        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "#        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "#        'BODY_TYP',\n",
    "#        'BUS_USE',\n",
    "#        'EMER_USE',\n",
    "#        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "#        'MODEL',\n",
    "#        'NUMOCCS',\n",
    "        'VALIGN',\n",
    "        'VNUM_LAN',\n",
    "        'VPROFILE',\n",
    "        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "        'VTRAFCON',\n",
    "        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "        'AGE',\n",
    "#        'LOCATION',\n",
    "#        'PER_TYP',\n",
    "        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "#        'VEH_AGE',\n",
    "        'AGE_x_SEX',\n",
    "#        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_to_Medium_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Thin_to_Medium_Features():\n",
    "    data = Get_Data()\n",
    "    data = Thin_to_Medium_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "#Test_Thin_to_Medium_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc4855",
   "metadata": {},
   "source": [
    "### Thin Features to \"Easy\" Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11264ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Thin_to_Easy_Features(data):\n",
    "    print ('Thin_to_Easy_Features()')\n",
    "\n",
    "    Accident = [\n",
    "        'DAY_WEEK',\n",
    "        'HOUR',\n",
    "#        'INT_HWY',\n",
    "#        'LGT_COND',\n",
    "        'MONTH',\n",
    "#        'PEDS',\n",
    "#        'PERMVIT',\n",
    "#        'PERNOTMVIT',\n",
    "        'PJ',\n",
    "        'PSU',\n",
    "#        'PVH_INVL',\n",
    "        'REGION',\n",
    "#        'REL_ROAD',\n",
    "#        'RELJCT1',\n",
    "#        'RELJCT2',\n",
    "#        'SCH_BUS',\n",
    "#        'TYP_INT',\n",
    "        'URBANICITY',\n",
    "#        'VE_FORMS',\n",
    "#        'VE_TOTAL',\n",
    "        'WEATHER',\n",
    "#        'WRK_ZONE',\n",
    "        'YEAR',\n",
    "    ]\n",
    "    \n",
    "    Vehicle = [\n",
    "#        'BODY_TYP',\n",
    "#        'BUS_USE',\n",
    "#        'EMER_USE',\n",
    "#        'MAKE',\n",
    "#        'MOD_YEAR',\n",
    "#        'MODEL',\n",
    "#        'NUMOCCS',\n",
    "#        'VALIGN',\n",
    "#        'VNUM_LAN',\n",
    "#        'VPROFILE',\n",
    "#        'VSPD_LIM',\n",
    "#        'VSURCOND',\n",
    "#        'VTRAFCON',\n",
    "#        'VTRAFWAY',\n",
    "    ]\n",
    "    \n",
    "    Person = [\n",
    "#        'AGE',\n",
    "#        'LOCATION',\n",
    "#        'PER_TYP',\n",
    "#        'SEX',\n",
    "        'HOSPITAL',    \n",
    "    ]\n",
    "\n",
    "    Engineered = [\n",
    "#        'VEH_AGE',\n",
    "#        'AGE_x_SEX',\n",
    "#        'AGE_x_SCH_BUS'\n",
    "    ]\n",
    "    \n",
    "    # Put features in alphabetical order\n",
    "    Features = Accident + Vehicle + Person + Engineered\n",
    "    Features = sorted(Features)\n",
    "#    Features = Merge + Features\n",
    "    \n",
    "    data = data.filter(Features, axis=1)\n",
    "    \n",
    "    print ('data.shape: ', data.shape)\n",
    "    \n",
    "    print ('End Thin_to_Easy_Features()')\n",
    "    print ()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def Test_Thin_to_Easy_Features():\n",
    "    data = Get_Data()\n",
    "    data = Thin_to_Easy_Features(data)\n",
    "    for feature in data:\n",
    "        display(data[feature].value_counts())\n",
    "        \n",
    "#Test_Thin_to_Easy_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52366e1a",
   "metadata": {},
   "source": [
    "## Get Dummies\n",
    "- Transform categorical data into one-hot-encoded features\n",
    "- For each value in the category, make a new feature that is \"1\" when the feature has that value, \"0\" otherwise.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47cefa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Dummies(data, target):\n",
    "    print ('Get_Dummies')\n",
    "    data = data.astype('category')\n",
    "    Target = data.pop(target)\n",
    "    data_Dummies = pd.get_dummies(data, prefix = data.columns)\n",
    "    data_Dummies = data_Dummies.join(Target)\n",
    "#    for feature in data_Dummies:\n",
    "#        print (feature)\n",
    "    print ()\n",
    "\n",
    "    return data_Dummies\n",
    "\n",
    "def Test_Get_Dummies():\n",
    "    print ('Test_Get_Dummies')\n",
    "    A = pd.DataFrame({\n",
    "        'A': ['a', 'b', 'a'], \n",
    "        'B': ['b', 'a', 'c'], \n",
    "        'C': [1, 2, 3]})\n",
    "    C = Get_Dummies(A, 'C')\n",
    "    display(C)\n",
    "    print ()\n",
    "\n",
    "#Test_Get_Dummies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3917b",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49200a4f",
   "metadata": {},
   "source": [
    "# Five-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "536ee811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Five_Fold_Cross_Validation(data, model, filename, title):\n",
    "    print ()\n",
    "    print ('------------------------')\n",
    "    print ()\n",
    "    print (filename)\n",
    "    print ()\n",
    "    \n",
    "    target = 'HOSPITAL'\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = random.randint(1,100))\n",
    "    target_column = data.loc[:,target]\n",
    "    y_test = []\n",
    "    y_proba = []\n",
    "    y_pred = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for train_index, test_index in skf.split(data, target_column):\n",
    "        print ('K-fold iteration = ', iteration)\n",
    "        iteration += 1\n",
    "        \n",
    "#        print ('len(train_index) = ', len(train_index))\n",
    "#        print (train_index)\n",
    "#        print ('len(test_index) = ', len(test_index))\n",
    "#        print (test_index)\n",
    "        \n",
    "        train_fold = data.iloc[train_index]\n",
    "#        print ()\n",
    "#        print ('train_fold')\n",
    "#        display(train_fold)\n",
    "        \n",
    "        test_fold = data.iloc[test_index]\n",
    "#        print ()\n",
    "#        print ('test_fold')\n",
    "#        display(test_fold)\n",
    "#        print ('type(test_fold) = ', type(test_fold))\n",
    "        \n",
    "        \n",
    "        X_train_fold = train_fold.drop(columns=[target])\n",
    "        X_test_fold = test_fold.drop(columns=[target])\n",
    "        y_train_fold = train_fold[target].squeeze()        \n",
    "        y_test_fold = test_fold[target].squeeze()\n",
    "#        print ('type(y_test_fold) = ', type(y_test_fold))\n",
    "        \n",
    "#        print ()\n",
    "        model.fit(X_train_fold, y_train_fold.values.ravel())\n",
    "        y_proba_fold = model.predict_proba(X_test_fold)\n",
    "        y_proba_fold = [x[1] for x in y_proba_fold]\n",
    "        y_pred_fold = list(np.around(np.array(y_proba_fold),0))\n",
    "        \n",
    "        ###\n",
    "#        print ('X_train_fold')\n",
    "#        display(X_train_fold)\n",
    "#        print ('y_train_fold')\n",
    "#        display(y_train_fold)\n",
    "#        print ('y_train_fold.value_counts()')\n",
    "#        display(y_train_fold.value_counts())\n",
    "#        print ('y_proba_fold')\n",
    "#        print (y_proba_fold)\n",
    "#        ###\n",
    "#        \n",
    "        y_test = y_test + y_test_fold.to_list()\n",
    "        y_proba = y_proba + y_proba_fold\n",
    "#        print ('len(y_proba) = ', len(y_proba))\n",
    "        y_pred = y_pred + y_pred_fold\n",
    "\n",
    "    y_test = np.array(y_test)\n",
    "    y_proba = np.array(y_proba)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    DF = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    DF['y_proba'] = y_proba\n",
    "    DF['y_pred'] = y_pred\n",
    "    DF.to_csv('../../Big_Files/' + filename + '.csv')\n",
    "#    print (DF)\n",
    "    \n",
    "    \n",
    "#    Chart_and_Plots(y_test, y_proba, y_pred, filename, title)\n",
    "    \n",
    "    \n",
    "    print ()\n",
    "#    return model    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2658775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def BRFC_5_Fold(data, target, alpha, filename):\n",
    "     \n",
    "    title = ''\n",
    "    model = BalancedRandomForestClassifier(\n",
    "        bootstrap = True, ccp_alpha = 0.0, criterion = 'gini', \n",
    "        max_depth = None,\n",
    "#        max_depth = 40, \n",
    "        max_features = 'sqrt', \n",
    "        max_leaf_nodes = None,\n",
    "#        max_leaf_nodes = 10000,  \n",
    "        max_samples = None, \n",
    "        min_impurity_decrease = 0.0, \n",
    "        min_samples_leaf = 1, \n",
    "        min_samples_split = 2, \n",
    "        min_weight_fraction_leaf = 0.0, \n",
    "        n_estimators = 100, \n",
    "#        n_estimators = 1000, \n",
    "        n_jobs = None, \n",
    "        oob_score = False, \n",
    "        random_state = random.randint(1,100), \n",
    "        replacement = False, \n",
    "        sampling_strategy = 'auto', \n",
    "        verbose = 0, \n",
    "        warm_start = False,\n",
    "        class_weight = {0:1-alpha, 1:alpha}\n",
    "    )\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae040db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFC_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    model = RandomForestClassifier(max_depth=2, random_state = random.randint(1,100))\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac53d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    model = AdaBoostClassifier(n_estimators=100, random_state = random.randint(1,100))\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "855780c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RUSBoost_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    estimator = DecisionTreeClassifier(\n",
    "        max_depth=1,\n",
    "#        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)},\n",
    "    )    \n",
    "    model = RUSBoostClassifier(\n",
    "        n_estimators=1000, \n",
    "        estimator=estimator,\n",
    "        algorithm='SAMME.R', \n",
    "        random_state = random.randint(1,100)\n",
    "    )\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f8dac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BalancedBagging_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    model = BalancedBaggingClassifier(\n",
    "        random_state = random.randint(1,100)\n",
    "    )\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff286004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EasyEnsemble_5_Fold(data, target, filename):\n",
    "    title = ''\n",
    "    estimator = AdaBoostClassifier(n_estimators=10, random_state = random.randint(1,100))\n",
    "    model = EasyEnsembleClassifier(n_estimators=10, estimator=estimator, random_state = random.randint(1,100))\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a00e6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_5_Fold(data, target, alpha, filename):\n",
    "    title = ''\n",
    "    model = LogisticRegression(\n",
    "#        class_weight={0:(1+r_target)/(2*r_target), 1:(1+r_target)/(2*1)}\n",
    "        class_weight = {0:1-alpha, 1:alpha},\n",
    "        max_iter=1000,\n",
    "        random_state = random.randint(1,100),\n",
    "    )\n",
    "    Five_Fold_Cross_Validation(data, model, filename, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f39874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KBFC_5_Fold(data, target, alpha, gamma, filename):\n",
    "    print ()\n",
    "    print ('------------------------')\n",
    "    print ()\n",
    "    print (filename)\n",
    "    print ()\n",
    "    \n",
    "    target = 'HOSPITAL'\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state  = random.randint(1,100))\n",
    "    target_column = data.loc[:,target]\n",
    "    y_test = []\n",
    "    y_proba = []\n",
    "    y_pred = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for train_index, test_index in skf.split(data, target_column):\n",
    "        print ()\n",
    "        print ()\n",
    "        print ('K-fold iteration = ', iteration)\n",
    "        iteration += 1\n",
    "        \n",
    "#        print ('len(train_index) = ', len(train_index))\n",
    "#        print (train_index)\n",
    "#        print ('len(test_index) = ', len(test_index))\n",
    "#        print (test_index)\n",
    "        \n",
    "        train_fold = data.iloc[train_index]\n",
    "#        print ()\n",
    "#        print ('train_fold')\n",
    "#        display(train_fold)\n",
    "        \n",
    "        test_fold = data.iloc[test_index]\n",
    "#        print ()\n",
    "#        print ('test_fold')\n",
    "#        display(test_fold)\n",
    "#        print ('type(test_fold) = ', type(test_fold))\n",
    "        \n",
    "        \n",
    "        X_train_fold = train_fold.drop(columns=[target])\n",
    "        X_test_fold = test_fold.drop(columns=[target])\n",
    "        y_train_fold = train_fold[target].squeeze()        \n",
    "        y_test_fold = test_fold[target].squeeze()\n",
    "#        print ('type(y_test_fold) = ', type(y_test_fold))\n",
    "\n",
    "#        print ('len(X_train_fold) = ', len(X_train_fold))\n",
    "#        print ('len(X_test_fold) = ', len(X_test_fold))\n",
    "#        print ('len(y_train_fold) = ', len(y_train_fold))\n",
    "#        print ('len(y_test_fold) = ', len(y_test_fold))\n",
    "#        print ()\n",
    "        \n",
    "#        print ()\n",
    "\n",
    "        loss_function = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "            apply_class_balancing=True,\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "    #        from_logits=False,\n",
    "    #        label_smoothing=0.0,\n",
    "    #        axis=-1,\n",
    "    #        reduction=losses_utils.ReductionV2.AUTO,\n",
    "    #        name='binary_focal_crossentropy'\n",
    "        )   \n",
    "    \n",
    "        # create model\n",
    "        model = Sequential()\n",
    "#        print ('data.shape = ', data.shape, data.shape[-1])\n",
    "        model.add(Dense(60, input_shape=(data.shape[-1]-1,), activation='relu'))\n",
    "#        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))    \n",
    "        # Compile model\n",
    "        metrics = [\n",
    "            keras.metrics.Precision(name=\"precision\"),\n",
    "            keras.metrics.Recall(name=\"recall\"),\n",
    "    #        F1_Metric,\n",
    "        ]\n",
    "        model.compile(loss=loss_function, optimizer=tf.keras.optimizers.Adam(), metrics=metrics)\n",
    "        estimator = KerasClassifier(\n",
    "            model=model, \n",
    "            random_state = random.randint(1,100),\n",
    "            metrics=metrics,\n",
    "            batch_size=128, \n",
    "            verbose=0,\n",
    "            epochs=20,\n",
    "        )\n",
    "    \n",
    "\n",
    "\n",
    "        estimator.fit(X_train_fold, y_train_fold.values.ravel())\n",
    "        y_proba_fold = estimator.predict_proba(X_test_fold)\n",
    "        y_proba_fold = [x[1] for x in y_proba_fold]\n",
    "        print ('len(y_proba_fold) = ', len(y_proba_fold))\n",
    "        y_pred_fold = list(np.around(np.array(y_proba_fold),0))\n",
    "        \n",
    "        ###\n",
    "#        print ('X_train_fold')\n",
    "#        display(X_train_fold.head())\n",
    "#        print ('y_train_fold')\n",
    "#        display(y_train_fold.head())\n",
    "#        print ('y_train_fold.value_counts()')\n",
    "#        display(y_train_fold.value_counts())\n",
    "#        print ('X_test_fold')\n",
    "#        display(X_test_fold.head())\n",
    "#        print ('y_test_fold')\n",
    "#        display(y_test_fold.head())\n",
    "#        print ('y_test_fold.value_counts()')\n",
    "#        display(y_test_fold.value_counts())\n",
    "#        print ('y_proba_fold')\n",
    "#        print (y_proba_fold[:10])\n",
    "#        ###\n",
    "#        \n",
    "        y_test = y_test + y_test_fold.to_list()\n",
    "        y_proba = y_proba + y_proba_fold\n",
    "#        print ('len(y_proba) = ', len(y_proba))\n",
    "        y_pred = y_pred + y_pred_fold\n",
    "\n",
    "    y_test = np.array(y_test)\n",
    "    y_proba = np.array(y_proba)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    DF = pd.DataFrame(y_test, columns=['y_test'])\n",
    "    DF['y_proba'] = y_proba\n",
    "    DF['y_pred'] = y_pred\n",
    "    print ('Length before dropna(): ',len(DF))\n",
    "    DF.dropna(inplace=True)\n",
    "    print ('Length after dropna(): ',len(DF))\n",
    "    DF.to_csv('../../Big_Files/' + filename + '.csv')\n",
    "    \n",
    "#    Chart_and_Plots(y_test, y_proba, y_pred, filename, '')\n",
    "    \n",
    "    \n",
    "    print ()\n",
    "#    return model    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52566066",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72178501",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Run_with_Hard_Features(run):\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "    data = Thin_to_Hard_Features(data)\n",
    "    write_filename_features = '_Hard' + run\n",
    "    data = Get_Dummies(data, target)\n",
    "    \n",
    "    y = data[target]\n",
    "    N = len(y)\n",
    "    n = len(y[y==1])\n",
    "    p = (N-n)/n\n",
    "    alpha_balanced = p/(p+1)\n",
    "    print ('p = ', p)\n",
    "    print ('alpha_balanced = ', alpha_balanced)    \n",
    "\n",
    "    \"\"\"\n",
    "    filename = 'RFC' + write_filename_features\n",
    "    RFC_5_Fold(data, target, filename)\n",
    "    \n",
    "    alpha = 0.5\n",
    "    filename = 'BRFC_alpha_0_5' + write_filename_features\n",
    "    BRFC_5_Fold(data, target, alpha, filename)\n",
    "    \n",
    "    alpha = alpha_balanced\n",
    "    filename = 'BRFC_alpha_balanced' + write_filename_features\n",
    "    BRFC_5_Fold(data, target, alpha, filename)\n",
    "    \n",
    "\n",
    "    alpha = 0.5\n",
    "    filename = 'LogReg_alpha_0_5' + write_filename_features\n",
    "    LogisticRegression_5_Fold(data, target, alpha, filename)\n",
    "\n",
    "    alpha = alpha_balanced\n",
    "    filename = 'LogReg_alpha_balanced' + write_filename_features\n",
    "    LogisticRegression_5_Fold(data, target, alpha, filename)\n",
    "\n",
    "    AdaBoost_5_Fold(data, target, 'AdaBoost' + write_filename_features)\n",
    "    BalancedBagging_5_Fold(data, target, 'BalBag' + write_filename_features)\n",
    "    EasyEnsemble_5_Fold(data, target, 'EEC' + write_filename_features)\n",
    "    RUSBoost_5_Fold(data, target, 'RUSBoost' + write_filename_features)\n",
    "    \n",
    "    alpha = 0.5\n",
    "    gamma = 0.0\n",
    "    filename = 'KBFC_alpha_0_5_gamma_0_0' + write_filename_features\n",
    "    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "\n",
    "    \"\"\"\n",
    "    alpha = alpha_balanced\n",
    "    gamma = 0.0\n",
    "    filename = 'KBFC_alpha_balanced_gamma_0_0' + write_filename_features\n",
    "    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "\n",
    "    alpha = 0.5\n",
    "    gamma = 1.0\n",
    "    filename = 'KBFC_alpha_0_5_gamma_1_0' + write_filename_features\n",
    "#    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "\n",
    "    alpha = 0.5\n",
    "    gamma = 2.0\n",
    "    filename = 'KBFC_alpha_0_5_gamma_2_0' + write_filename_features\n",
    "#    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eafbf6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_with_Medium_Features(run):\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "    data = Thin_to_Medium_Features(data)\n",
    "    write_filename_features = '_Medium' + run\n",
    "    data = Get_Dummies(data, target)\n",
    "\n",
    "    y = data[target]\n",
    "    N = len(y)\n",
    "    n = len(y[y==1])\n",
    "    p = (N-n)/n\n",
    "    alpha_balanced = p/(p+1)\n",
    "    print ('p = ', p)\n",
    "    print ('alpha_balanced = ', alpha_balanced)    \n",
    "\n",
    "    filename = 'RFC' + write_filename_features\n",
    "    RFC_5_Fold(data, target, filename)\n",
    "    \n",
    "    alpha = 0.5\n",
    "    filename = 'BRFC_alpha_0_5' + write_filename_features\n",
    "    BRFC_5_Fold(data, target, alpha, filename)\n",
    "    \n",
    "    alpha = alpha_balanced\n",
    "    filename = 'BRFC_alpha_balanced' + write_filename_features\n",
    "    BRFC_5_Fold(data, target, alpha, filename)\n",
    "    \n",
    "\n",
    "    alpha = 0.5\n",
    "    filename = 'LogReg_alpha_0_5' + write_filename_features\n",
    "    LogisticRegression_5_Fold(data, target, alpha, filename)\n",
    "\n",
    "    alpha = alpha_balanced\n",
    "    filename = 'LogReg_alpha_balanced' + write_filename_features\n",
    "    LogisticRegression_5_Fold(data, target, alpha, filename)\n",
    "\n",
    "    AdaBoost_5_Fold(data, target, 'AdaBoost' + write_filename_features)\n",
    "    BalancedBagging_5_Fold(data, target, 'BalBag' + write_filename_features)\n",
    "    EasyEnsemble_5_Fold(data, target, 'EEC' + write_filename_features)\n",
    "    RUSBoost_5_Fold(data, target, 'RUSBoost' + write_filename_features)\n",
    "    \n",
    "    alpha = 0.5\n",
    "    gamma = 0.0\n",
    "    filename = 'KBFC_alpha_0_5_gamma_0_0' + write_filename_features\n",
    "    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "\n",
    "    alpha = alpha_balanced\n",
    "    gamma = 0.0\n",
    "    filename = 'KBFC_alpha_balanced_gamma_0_0' + write_filename_features\n",
    "    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "\n",
    "    alpha = 0.5\n",
    "    gamma = 1.0\n",
    "    filename = 'KBFC_alpha_0_5_gamma_1_0' + write_filename_features\n",
    "    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "\n",
    "    alpha = 0.5\n",
    "    gamma = 2.0\n",
    "    filename = 'KBFC_alpha_0_5_gamma_2_0' + write_filename_features\n",
    "    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1213be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_with_Easy_Features(run):\n",
    "    data = Get_Data()\n",
    "    data = data.astype('int64')\n",
    "    target = 'HOSPITAL'\n",
    "    data = Feature_Engineering_Cross_Two(data)\n",
    "    data = Thin_to_Easy_Features(data)\n",
    "    write_filename_features = '_Easy' + run\n",
    "    data = Get_Dummies(data, target)\n",
    "\n",
    "    y = data[target]\n",
    "    N = len(y)\n",
    "    n = len(y[y==1])\n",
    "    p = (N-n)/n\n",
    "    alpha_balanced = p/(p+1)\n",
    "    print ('p = ', p)\n",
    "    print ('alpha_balanced = ', alpha_balanced)    \n",
    "\n",
    "    filename = 'RFC' + write_filename_features\n",
    "    RFC_5_Fold(data, target, filename)\n",
    "    \n",
    "    alpha = 0.5\n",
    "    filename = 'BRFC_alpha_0_5' + write_filename_features\n",
    "    BRFC_5_Fold(data, target, alpha, filename)\n",
    "    \n",
    "    alpha = alpha_balanced\n",
    "    filename = 'BRFC_alpha_balanced' + write_filename_features\n",
    "    BRFC_5_Fold(data, target, alpha, filename)\n",
    "    \n",
    "\n",
    "    alpha = 0.5\n",
    "    filename = 'LogReg_alpha_0_5' + write_filename_features\n",
    "    LogisticRegression_5_Fold(data, target, alpha, filename)\n",
    "\n",
    "    alpha = alpha_balanced\n",
    "    filename = 'LogReg_alpha_balanced' + write_filename_features\n",
    "    LogisticRegression_5_Fold(data, target, alpha, filename)\n",
    "\n",
    "    AdaBoost_5_Fold(data, target, 'AdaBoost' + write_filename_features)\n",
    "    BalancedBagging_5_Fold(data, target, 'BalBag' + write_filename_features)\n",
    "    EasyEnsemble_5_Fold(data, target, 'EEC' + write_filename_features)\n",
    "    RUSBoost_5_Fold(data, target, 'RUSBoost' + write_filename_features)\n",
    "    \n",
    "    alpha = 0.5\n",
    "    gamma = 0.0\n",
    "    filename = 'KBFC_alpha_0_5_gamma_0_0' + write_filename_features\n",
    "    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "\n",
    "    alpha = alpha_balanced\n",
    "    gamma = 0.0\n",
    "    filename = 'KBFC_alpha_balanced_gamma_0_0' + write_filename_features\n",
    "    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "\n",
    "    alpha = 0.5\n",
    "    gamma = 1.0\n",
    "    filename = 'KBFC_alpha_0_5_gamma_1_0' + write_filename_features\n",
    "    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "\n",
    "    alpha = 0.5\n",
    "    gamma = 2.0\n",
    "    filename = 'KBFC_alpha_0_5_gamma_2_0' + write_filename_features\n",
    "    KBFC_5_Fold(data, target, alpha, gamma, filename)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6e23c1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get_Data()\n",
      "data.shape:  (713566, 78)\n",
      "End Get_Data()\n",
      "\n",
      "Feature_Engineering_Cross_Two\n",
      "\n",
      "Thin_to_Hard_Features()\n",
      "data.shape:  (713566, 39)\n",
      "End Thin_to_Hard_Features()\n",
      "\n",
      "Get_Dummies\n",
      "\n",
      "p =  5.609785468153692\n",
      "alpha_balanced =  0.84870915934896\n",
      "\n",
      "------------------------\n",
      "\n",
      "KBFC_alpha_balanced_gamma_0_0_Hard_Run_3\n",
      "\n",
      "\n",
      "\n",
      "K-fold iteration =  0\n",
      "len(y_proba_fold) =  142714\n",
      "\n",
      "\n",
      "K-fold iteration =  1\n",
      "len(y_proba_fold) =  142713\n",
      "\n",
      "\n",
      "K-fold iteration =  2\n",
      "len(y_proba_fold) =  142713\n",
      "\n",
      "\n",
      "K-fold iteration =  3\n",
      "len(y_proba_fold) =  142713\n",
      "\n",
      "\n",
      "K-fold iteration =  4\n",
      "len(y_proba_fold) =  142713\n",
      "Length before dropna():  713566\n",
      "Length after dropna():  713566\n",
      "\n",
      "CPU times: user 58min 54s, sys: 49.5 s, total: 59min 43s\n",
      "Wall time: 1h 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Run_with_Hard_Features('_Run_3')\n",
    "# CPU times: user 4h 45min 20s, sys: 7min 22s, total: 4h 52min 43s\n",
    "# Wall time: 4h 30min 47s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebb76860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Run_with_Medium_Features('_Run_3')\n",
    "# CPU times: user 2h 21min 16s, sys: 3min 36s, total: 2h 24min 52s\n",
    "# Wall time: 2h 19min 48s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6534ca51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1 µs, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Run_with_Easy_Features('_Run_3')\n",
    "# CPU times: user 2h 2min 53s, sys: 1min 36s, total: 2h 4min 29s\n",
    "# Wall time: 2h 3min 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb852de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_2_11",
   "language": "python",
   "name": "tensorflow_2_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
