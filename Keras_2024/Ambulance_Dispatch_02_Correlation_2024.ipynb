{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1edb2407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\tableofcontents\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92c54b",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941fba9",
   "metadata": {},
   "source": [
    "- This second piece of the code gives us guidance in how to bin each of the categorical features into fewer categories.  Binary classification algorithms generally work best with fewer than ten categories per feature, but some of our features have hundreds of unique values.  \n",
    "\n",
    "- Running this code is not necessary for running the next notebook, Ambulance_Dispatch_03_Bin_Data.ipynb, which starts with the output from the previous notebook, Ambulance_Dispatch_01_Get_Data.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e2f96",
   "metadata": {},
   "source": [
    "## Binning by Human Understanding of Meaning of Codes:  HOSPITAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae879ec7",
   "metadata": {},
   "source": [
    "Some of the features, like HOSPITAL, we can bin by looking at what each value signifies and putting them together using human understanding of what the codes signify.  We are only interested in whether the crash person went to the hospital; we do not really care how the person got to the hospital, but the CRSS codes differentiate six ways a person might have gone to the hospital and two ways the information can be unknown.  We will bin CRSS codes 1-6 together as \"Yes\" and codes 8-9 as 'Unknown,' to be imputed later.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c25751",
   "metadata": {},
   "source": [
    "| CRSS Attribute Code | Meaning | Our Bin |\n",
    "|---|---|---|\n",
    "| 0  | Not Transported for Treatment  | 0 |\n",
    "| 1  | EMS Air  | 1 |\n",
    "| 2  | Law Enforcement  | 1 |\n",
    "| 3  | EMS Unknown Mode  | 1 |\n",
    "| 4  | Transported Unknown Source  | 1 |\n",
    "| 5  | EMS Ground  | 1 |\n",
    "| 6  | Other  | 1 |\n",
    "| 8  | Not Reported  | 'Unknown' |\n",
    "| 9  | Reported as Unknown  | 'Unknown' |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668751f",
   "metadata": {},
   "source": [
    "## Binning of Ordered Codes:  HOUR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df6b8ba",
   "metadata": {},
   "source": [
    "The crash hours are discrete but ordered.  When binning \"similar\" times together, we look for \"similar\" in terms of the likelihood that, at that time of day, a crash person will go to the hospital.  In the table below, crashes at midnight (HOUR = 0) account for 1.5% of crash persons, and 23% of those crash persons went to the hospital.  We see a significant drop between 4 and 7 am in the likelihood that a crash person will go to the hospital, about a 4% drop each hour.  The percentage of crash person going to the hospital stays about the same until 6pm, when it starts to rise again.  Where exactly to cut the bins is a somewhat arbitrary decision.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77abd31",
   "metadata": {},
   "source": [
    "| HOUR | % of Crash Persons | % to Hospital | Our Bin | Meaning |\n",
    "|---|---|---|---|---|\n",
    "| 0 | 1.344 | 23.0705 | 6 | Late Night |\n",
    "| 1 | 1.0665 | 26.5419 | 6 | Late Night |\n",
    "| 2 | 0.9483 | 26.6044 | 6 | Late Night |\n",
    "| 3 | 0.7306 | 26.8372 | 6 | Late Night |\n",
    "| 4 | 0.7089 | 25.6741 | 6 | Late Night |\n",
    "| 5 | 1.1962 | 21.2548 | 0 | Early Morning |\n",
    "| 6 | 2.4013 | 17.1788 | 0 | Early Morning |\n",
    "| 7 | 4.6948 | 13.1665 | 1 | Morning |\n",
    "| 8 | 4.5183 | 13.3792 | 1 | Morning |\n",
    "| 9 | 3.8258 | 14.3828 | 1 | Morning |\n",
    "| 10 | 4.079 | 14.8444 | 1 | Morning |\n",
    "| 11 | 5.0904 | 14.1232 | 2 | Mid-Day |\n",
    "| 12 | 6.2797 | 13.4761 | 2 | Mid-Day |\n",
    "| 13 | 6.2852 | 14.0212 | 2 | Mid-Day |\n",
    "| 14 | 7.0741 | 14.1841 | 2 | Mid-Day |\n",
    "| 15 | 8.6077 | 12.9617 | 3 | Rush Hour |\n",
    "| 16 | 8.6935 | 13.3526 | 3 | Rush Hour |\n",
    "| 17 | 9.3121 | 12.6166 | 3 | Rush Hour |\n",
    "| 18 | 7.0147 | 14.0458 | 4 | Early Evening |\n",
    "| 19 | 4.8031 | 16.2731 | 4 | Early Evening |\n",
    "| 20 | 3.7818 | 17.9284 | 5 | Evening |\n",
    "| 21 | 3.2342 | 18.7128 | 5 | Evening |\n",
    "| 22 | 2.4795 | 20.4524 | 5 | Evening |\n",
    "| 23 | 1.8303 | 22.846 | 6 | Late Night |![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7943321",
   "metadata": {},
   "source": [
    "## Automated Binning:  BODY_TYP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395810a5",
   "metadata": {},
   "source": [
    "The CRSS dataset in these six years differentiates 68 different vehicle body types.  Some of them, like \"4: 4-Door Sedan, Hardtop\" and \"14: Compact Utility\" are common, with 36% and 16% of crash persons, respectively.  Some like \"21: Large Van\" are less common (1%), and some are rare, like \"32: Pickup With Slide-in Camper (2016-2017 Only)\" (0.0007%).  \n",
    "\n",
    "We want to put the 68 codes into about five bins by likelihood of going to the hospital.\n",
    "\n",
    "To bin a feature like BODY_TYP, the code in this notebook orders the CRSS codes by proportion of crash persons going to the hospital, then assigns the codes to about five bins so that approximately the same number of crash persons are in each bin.  Large categories like \"4: 4-Door Sedan, Hardtop\" will be their own bin.  \n",
    "\n",
    "Unsurprisingly, many of the codes in the most dangerous bin are motorcycles, and many of the codes in the least dangerous bin are large trucks.  \n",
    "\n",
    "The table below shows some of the data that the code below considers when cutting the bins.  CRSS codes 4 and 14 are large enough to get their own bins.  Codes 20 and 34 are not large enough to get their own bins, but too large to be in the same bin.  This notebook ouputs such a table for each feature in $\\LaTeX$ format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb556b",
   "metadata": {},
   "source": [
    "| BODY_TYP | % of Crash Persons | % to Hospital | Our Bin |\n",
    "|---|---|---|---|\n",
    "| 86 | 0.0003 | 100.0000 | 0 |\n",
    "| ... | | | |\n",
    "| 1 | 0.6528 | 16.2667 | 0 |\n",
    "| 2 | 3.0509 | 16.085 | 0 |\n",
    "| 19 | 0.9264 | 15.9881 | 0 |\n",
    "| 52 | 0.1562 | 15.9703 | 0 |\n",
    "| 59 | 0.0309 | 15.9624 | 0 |\n",
    "|||||\n",
    "| 4 | 36.1961 | 15.9386 | 1 |\n",
    "|||||\n",
    "| 30 | 0.3609 | 15.7154 | 2 |\n",
    "| 5 | 2.5745 | 14.8298 | 2 |\n",
    "| 9 | 2.8609 | 14.6233 | 2 |\n",
    "| 10 | 0.0142 | 14.2857 | 2 |\n",
    "| 91 | 0.001 | 14.2857 | 2 |\n",
    "| 6 | 5.2201 | 14.1666 | 2 |\n",
    "| 16 | 0.2965 | 14.09 | 2 |\n",
    "|||||\n",
    "| 14 | 16.1724 | 13.823 | 3 |\n",
    "|||||\n",
    "| 22 | 0.0132 | 13.1868 | 4 |\n",
    "| 20 | 4.1037 | 12.9021 | 4 |\n",
    "| 40 | 0.0717 | 12.5506 | 4 |\n",
    "|||||\n",
    "| 34 | 9.824 | 11.7167 | 5 |\n",
    "| 29 | 0.2 | 11.4576 | 5 |\n",
    "| 15 | 5.4602 | 11.2749 | 5 |\n",
    "| 31 | 1.4085 | 11.2358 | 5 |\n",
    "| 17 | 0.0149 | 10.6796 | 5 |\n",
    "| ... | | | |\n",
    "| 41 | 0.0001 | 0.0000 | 5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900c67cd",
   "metadata": {},
   "source": [
    "The cell below is actual output from this notebook, in a format we could cut and paste into the next notebook.  The comments show the percentage of crash persons in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f46e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [\n",
    "        ['0', [86,87,82,83,89,81,84,80,88,85,90,11,96,95,97,45,58,12,32,8,42,3,1,2,19,52,59,]], #  9.0438 %\n",
    "        ['1', [4,]], #  36.1961 %\n",
    "        ['2', [30,5,9,10,91,6,16,]], #  11.3281 %\n",
    "        ['3', [14,]], #  16.1724 %\n",
    "        ['4', [22,20,40,]], #  14.0126 %\n",
    "        ['5', [34,29,15,31,17,39,55,28,21,93,92,48,50,7,51,61,67,63,62,66,65,78,64,72,60,71,73,94,41,]], #  13.2471 %\n",
    "        ['Unknowns', [98, 99, 49, 79, ]]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd6971",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9db3b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:26:08) [Clang 14.0.6 ]\n",
      "NumPy version: 1.24.2\n",
      "Pandas version:  1.5.3\n",
      "JSON version:  2.0.9\n",
      "Finished Importing Libraries\n"
     ]
    }
   ],
   "source": [
    "import sys, copy, math, time\n",
    "\n",
    "print ('Python version: {}'.format(sys.version))\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import pandas as pd\n",
    "print ('Pandas version:  {}'.format(pd.__version__))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import json # We will use json ('JavaScript Object Notation') to write and read dictionaries to/from files\n",
    "print ('JSON version:  {}'.format(json.__version__))\n",
    "\n",
    "\n",
    "print ('Finished Importing Libraries')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f41d34",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "- Read the data file \n",
    "- Take out the NAME files and the IMputed files\n",
    "- Read in the dictionary of feature values signifying \"Missing\" or \"Unknown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "475eed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Import_Stuff():\n",
    "    print ('Import_Stuff()')\n",
    "#    filename = '../../Big_Files/CRSS_Merged_Raw_Data.csv'\n",
    "    filename = '../../Big_Files/CRSS_Merged_Raw_Data_Sample.csv'\n",
    "    data = pd.read_csv(filename, index_col=None, low_memory=False)\n",
    "    print ('data.shape: ', data.shape)\n",
    "\n",
    "    for feature in data:\n",
    "        if 'NAME' in feature or '_IM' in feature:\n",
    "            data.drop(columns=[feature], inplace=True)\n",
    "\n",
    "    data.drop(columns=['CASENUM'], inplace=True)\n",
    "        \n",
    "    print ('data.shape: ', data.shape)\n",
    "    print ()\n",
    "    \n",
    "    print ('Reading in Missing/Unknown Dictionary')\n",
    "    filename = '../../Big_Files/Missing_Unknown.json'\n",
    "    with open(filename) as json_file:\n",
    "        Missing_Unknown = json.load(json_file)\n",
    "    print ()\n",
    "\n",
    "    \n",
    "    return data, Missing_Unknown\n",
    "\n",
    "#Import_Data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1f01a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_Unknowns_in_Feature(data, Missing_Unknown, feature):\n",
    "    print ('Remove_Unknowns_in_Feature()')\n",
    "#    print (feature)\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    if feature in Missing_Unknown.keys():\n",
    "        A = Missing_Unknown[feature]\n",
    "#        print (A)\n",
    "#        print (data.shape)\n",
    "#        print (data[feature].unique())\n",
    "        for a in A:\n",
    "            data = data[~data[feature].isin(Missing_Unknown[feature])]\n",
    "#        print (data.shape)\n",
    "#        print (data[feature].unique())\n",
    "#        print ()\n",
    "#    print ()\n",
    "    return data\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff19734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Contingency(data, target, feature):\n",
    "    contingency_matrix = pd.crosstab(data[target], data[feature])\n",
    "    cm = contingency_matrix.values.tolist()\n",
    "\n",
    "    if len(cm)==2 and len(cm[0])==2:\n",
    "        corr = cm[1][1] / (cm[0][1] + cm[1][1])\n",
    "        per = (cm[0][1] + cm[1][1])/(cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])\n",
    "    else:\n",
    "        corr = 0\n",
    "        per = 0\n",
    "        print ('Error in Contingency Matrix Dimensions')\n",
    "        print ('data[feature].unique()')\n",
    "        print (data[feature].unique())\n",
    "\n",
    "    per = round(per*100,4)\n",
    "    corr = round(corr*100,4)\n",
    "\n",
    "    return per, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb90236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correlation(data, target, Missing_Unknown):\n",
    "    print (\"Correlation()\")\n",
    "    data = data.reindex(sorted(data.columns), axis=1)\n",
    "    data = data[ [target] + [col for col in data.columns if col != target]]\n",
    "    \n",
    "    Correlation_Dictionary = {}\n",
    "    \n",
    "    for feature in data:\n",
    "        print (feature)\n",
    "        A = []\n",
    "        D = {}\n",
    "        if feature not in [target]:\n",
    "            A = data[[target,feature]].copy()\n",
    "            A = Remove_Unknowns_in_Feature(A, Missing_Unknown, feature)\n",
    "            U = np.sort(A[feature].unique())\n",
    "#            print (U)\n",
    "#            print ()\n",
    "            \n",
    "            C = []\n",
    "            for value in U:\n",
    "#                print (value)\n",
    "                B = A[[target]].copy()\n",
    "                B[feature] = A[feature].apply(lambda x: 1 if x==value else 0)\n",
    "#                display (B.head())\n",
    "#                print ()\n",
    "                per, corr = Contingency(B, target, feature)\n",
    "#                print ('    ', value, per, corr)        \n",
    "                C.append([value, per, corr])\n",
    "            C.sort(key=lambda x:x[2], reverse=True)\n",
    "#            display(C)\n",
    "\n",
    "            E = []\n",
    "            j = 0\n",
    "            s = 0.0\n",
    "            for i, c in enumerate(C):\n",
    "                E.append(c[0])\n",
    "                s += c[1]\n",
    "#                print (len(C), i, c, j, E, s)\n",
    "                if (\n",
    "                    c[1] > 10 or \n",
    "                    (i<len(C)-1 and s + C[i+1][1] > 21) or \n",
    "                    i==len(C)-1\n",
    "                ):\n",
    "                    D.update({j:E})\n",
    "#                    print (D)\n",
    "#                    print (s)\n",
    "#                    print ()\n",
    "                    j += 1\n",
    "                    E = []\n",
    "                    s = 0.0\n",
    "#            print ()\n",
    "        Correlation_Dictionary.update({feature:D})\n",
    "            \n",
    "    return Correlation_Dictionary\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec66590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import_Stuff()\n",
      "data.shape:  (83380, 222)\n",
      "data.shape:  (83380, 89)\n",
      "\n",
      "Reading in Missing/Unknown Dictionary\n",
      "\n",
      "Correlation()\n",
      "HOSPITAL\n",
      "ACC_TYPE\n",
      "Remove_Unknowns_in_Feature()\n",
      "AGE\n",
      "Remove_Unknowns_in_Feature()\n",
      "AIR_BAG\n",
      "Remove_Unknowns_in_Feature()\n",
      "ALCOHOL\n",
      "Remove_Unknowns_in_Feature()\n",
      "ALC_RES\n",
      "Remove_Unknowns_in_Feature()\n",
      "ALC_STATUS\n",
      "Remove_Unknowns_in_Feature()\n",
      "BODY_TYP\n",
      "Remove_Unknowns_in_Feature()\n",
      "BUS_USE\n",
      "Remove_Unknowns_in_Feature()\n",
      "CARGO_BT\n",
      "Remove_Unknowns_in_Feature()\n",
      "DAY_WEEK\n",
      "Remove_Unknowns_in_Feature()\n",
      "DEFORMED\n",
      "Remove_Unknowns_in_Feature()\n",
      "DRINKING\n",
      "Remove_Unknowns_in_Feature()\n",
      "DRUGS\n",
      "Remove_Unknowns_in_Feature()\n",
      "DR_PRES\n",
      "Remove_Unknowns_in_Feature()\n",
      "DR_ZIP\n",
      "Remove_Unknowns_in_Feature()\n",
      "EJECTION\n",
      "Remove_Unknowns_in_Feature()\n",
      "EMER_USE\n",
      "Remove_Unknowns_in_Feature()\n",
      "FIRE_EXP\n",
      "Remove_Unknowns_in_Feature()\n",
      "HARM_EV\n",
      "Remove_Unknowns_in_Feature()\n",
      "HAZ_CNO\n",
      "Remove_Unknowns_in_Feature()\n",
      "HAZ_INV\n",
      "Remove_Unknowns_in_Feature()\n",
      "HAZ_PLAC\n",
      "Remove_Unknowns_in_Feature()\n",
      "HAZ_REL\n",
      "Remove_Unknowns_in_Feature()\n",
      "HIT_RUN\n",
      "Remove_Unknowns_in_Feature()\n",
      "HOUR\n",
      "Remove_Unknowns_in_Feature()\n",
      "IMPACT1\n",
      "Remove_Unknowns_in_Feature()\n",
      "INJ_SEV\n",
      "Remove_Unknowns_in_Feature()\n",
      "INT_HWY\n",
      "Remove_Unknowns_in_Feature()\n",
      "J_KNIFE\n",
      "Remove_Unknowns_in_Feature()\n",
      "LGT_COND\n",
      "Remove_Unknowns_in_Feature()\n",
      "MAKE\n",
      "Remove_Unknowns_in_Feature()\n",
      "MAK_MOD\n",
      "Remove_Unknowns_in_Feature()\n",
      "MAN_COLL\n",
      "Remove_Unknowns_in_Feature()\n",
      "MAX_SEV\n",
      "Remove_Unknowns_in_Feature()\n",
      "MAX_VSEV\n",
      "Remove_Unknowns_in_Feature()\n",
      "MODEL\n",
      "Remove_Unknowns_in_Feature()\n",
      "MOD_YEAR\n",
      "Remove_Unknowns_in_Feature()\n",
      "MONTH\n",
      "Remove_Unknowns_in_Feature()\n",
      "M_HARM\n",
      "Remove_Unknowns_in_Feature()\n",
      "NUMOCCS\n",
      "Remove_Unknowns_in_Feature()\n",
      "NUM_INJ\n",
      "Remove_Unknowns_in_Feature()\n",
      "NUM_INJV\n",
      "Remove_Unknowns_in_Feature()\n",
      "PCRASH4\n",
      "Remove_Unknowns_in_Feature()\n",
      "PCRASH5\n",
      "Remove_Unknowns_in_Feature()\n",
      "PERMVIT\n",
      "Remove_Unknowns_in_Feature()\n",
      "PERNOTMVIT\n",
      "Remove_Unknowns_in_Feature()\n",
      "PER_NO\n",
      "Remove_Unknowns_in_Feature()\n",
      "PER_TYP\n",
      "Remove_Unknowns_in_Feature()\n",
      "PJ\n",
      "Remove_Unknowns_in_Feature()\n"
     ]
    }
   ],
   "source": [
    "def Main():\n",
    "    target = 'HOSPITAL'\n",
    "    data, Missing_Unknown = Import_Stuff()\n",
    "    Correlation_Dictionary = Correlation(data, target, Missing_Unknown)\n",
    "    \n",
    "    with open(\"../../Big_Files/Correlation_Dictionary.json\", \"w\") as outfile: \n",
    "        json.dump(Correlation_Dictionary, outfile, default=str)\n",
    "        \n",
    "    print ('Reading in Correlation Dictionary')\n",
    "    with open('../../Big_Files/Correlation_Dictionary.json') as json_file:\n",
    "        C = json.load(json_file)\n",
    "    print (C)\n",
    "    \n",
    "Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743aa960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_2_11",
   "language": "python",
   "name": "tensorflow_2_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
