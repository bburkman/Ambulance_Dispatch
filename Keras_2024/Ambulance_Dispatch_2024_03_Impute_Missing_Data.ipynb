{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb2407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa289b",
   "metadata": {},
   "source": [
    "# readme\n",
    "- Most of our other Jupyter Notebooks have a main() function at the bottom that runs everything.  \n",
    "- This notebook is structured differently, with several functions that run in sequence.  \n",
    "- The reason for the difference is that part of the work has to be done outside this notebook.  \n",
    "- The IVEware imputation software is available in several languages, but not Python.  We ran it in R using scrlib.  \n",
    "- This notebook prepares the data for the Mode, Random Forest, and IVEware imputations, and does the first two.  Then the user must separately run the IVEware software.  Finally, this notebook pulls in those results and compares the three methods.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14b7cd9",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eada507",
   "metadata": {},
   "source": [
    "- We have the discretized CRSS dataset in '../../Big_Files/CRSS_Binned_Data.csv'\n",
    "- MissForest is a round-robin imputation method most commonly implemented in R, generally considered one of the best imputation methods.  It has several Python implementations.\n",
    "- The Python implementation we found most current and referenced, at https://pypi.org/project/MissForest/ , was not appropriate for our work because all of our data is categorical.  The MissForest algorithm starts from some imputed state, and we wanted to start with imputation to mode, but that implementation only offered imputation to mean or median, which are appropriate for continuous variables but not for categorical, so we wrote our own implementation.  \n",
    "- We compare here four methods:\n",
    "    - Round-Robin Random Forest \n",
    "        - Our own implementation of Round Robin, using scikit-learn's random forest\n",
    "        - Using imputation by mode as the starting point\n",
    "    - Imputation by mode\n",
    "    - Random Imputation\n",
    "    - IVEware, using the hyperparameters in the CRSS Imputation report\n",
    "- To compare, we followed the example for MissForest.\n",
    "    - We dropped all samples with a missing value, so we would have ground truth, going from 817,623 samples to 232,333 samples to make a Pandas dataframe data_Ground_Truth\n",
    "    - We erased ~15% of the values in each sample to make data_NaN\n",
    "    - We used each imputation method to impute the missing values.\n",
    "    - To compare methods, we counted:\n",
    "        - For each method, what percentage of imputed values did not match ground truth (28-44%)\n",
    "        - For each pair of methods, which method did a better job on how many features\n",
    "        - For each pair of methods, how many values are different\n",
    "- Our round-robin method\n",
    "    - In data_NaN, change all of the 'Unknown' to np.NaN.\n",
    "    - In each feature, count the number of unknown samples.\n",
    "    - In another copy, data_Mode, impute by mode in all of the features.\n",
    "    - Starting with the feature with the least (nonzero) number of missing samples:\n",
    "        - Copy that feature from data_NaN into data_Mode, so that only that feature has missing values.\n",
    "        - Separate the dataframe into two, one with known values in the target variable (X) and one with unknown values (Z).\n",
    "        - From the dataframe with known values (X), separate out the target variable (call it 'y')\n",
    "        - Using Random Forest, build a model that maps X to y.  \n",
    "        - Use the model to impute the missing values\n",
    "    - At each iteration we replace the mode-imputed values with RF-imputed values.\n",
    "- Our Random Imputation method\n",
    "    - We did not choose randomly from the unique values in the feature, because some values may be much more common than others.  We wanted (approximately) the same distribution of values.\n",
    "    - We started with 232,333 samples with 67 features.\n",
    "    - We erased values with a probability of 15%, but that doesn't mean that exactly 34,849.95 values are missing from each feature, but we did erase *about* 35,000 values from each feature.  The exact number erased from each feature is printed out when the code runs.\n",
    "    - For each feature:\n",
    "        - Create a temporary copy of the feature, which will have 232,333 samples, about 35,000 of which are NaN.\n",
    "        - Drop the NaN samples in the temp feature, leaving about 200,000 samples.\n",
    "        - Resample the temp feature to have 232,333 samples.  The resampling will change the order of the values but keep about the same distribution.\n",
    "        - In the original feature, replace the NaN values with the non-NaN corresponding values in the temporary feature.\n",
    "- The IVEware implementation is available in several platforms, but Python is not one of them.  We run it in R outside this notebook.  Be aware that the random selection of values to erase is different for each run, so the IVEware imputation must be run anew. \n",
    "\n",
    "- Once we had analyzed the results and decided that the Random Forest method is best for our work, we implemented it and saved the results to CRSS_Imputed_Data.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ee00c",
   "metadata": {},
   "source": [
    "## What is going on with IVEware using \"seed 0;\" ?\n",
    "- When we set the random seed to 0, the accuracy of IVEware jumps from about 70% to about 80%, from slightly worse than Random Forest to MUCH better.  WHAT ???\n",
    "\n",
    "- These runs have the same random seed for Python and NumPy, have the five multicollinear features used in the imputation but dropped for the evaluation.  \n",
    "\n",
    "- Having the same Python and NumPy random seed means that the input datasets for the IVEware imputation have the same samples have the same missing feature values.  \n",
    "\n",
    "- \"seed 0;\" in IVEware_CRSS_Imputation.xml\n",
    "\n",
    "\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,006,143  | 100% | \n",
    "    | RF |  558,626  |  27.85 % | \n",
    "    | Mode |  681,514  |  33.97 % | \n",
    "    | Random |  888,663  |  44.3 % | \n",
    "    | IVEware |  438,072  |  21.84 % | \n",
    "\n",
    "- \"seed 1;\"\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,006,143  | 100% | \n",
    "    | RF |  558,626  |  27.85 % | \n",
    "    | Mode |  681,514  |  33.97 % | \n",
    "    | Random |  888,663  |  44.3 % | \n",
    "    | IVEware |  592,313  |  29.52 % | \n",
    "\n",
    "- \"seed 2;\"\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,006,143  | 100% | \n",
    "    | RF |  558,626  |  27.85 % | \n",
    "    | Mode |  681,514  |  33.97 % | \n",
    "    | Random |  888,663  |  44.3 % | \n",
    "    | IVEware |  568,719  |  28.35 % | \n",
    "    \n",
    "    \n",
    "<br><br>\n",
    "- Found what was going on. \"seed 1;\" in IVEware is setting the random seed in R, but \"seed 0;\" is something different.\n",
    "- Cite IVEware_User_Guide, page 17\n",
    "\n",
    "\"SEED number;\n",
    "\n",
    "Specifies a seed for the random draws from the posterior predictive distribution. Number should be greater than zero. A zero seed will result in no perturbations of the predicted values or the regression coefficients. If the SEED keyword is missing from the setup file then the seed will be determined by your computerâ€™s internal clock.\"\n",
    "\n",
    "- set.seed(int) in R does not have this behavior at int=0.  I tried set.seed(0) in R and it worked just fine.  \n",
    "- SAS requires that the random seed be a positive integer, and SAS is one of the implementations of IVEware, so that may be why the IVEware authors thought to implement this functionality for their seed.\n",
    "\n",
    "- According to this ~2017 scraping of GitHub Python code to count the choices of random seeds,\n",
    "    - https://www.kaggle.com/code/residentmario/kernel16e284dcb7\n",
    "    - 0 is the most common (19%)\n",
    "    - 1 and 42 are next(9% and 4%, respectively)\n",
    "    \n",
    "- According to this 2014 scraping of 100 top R repositories owned by 27 people, \n",
    "    - https://www.r-bloggers.com/2014/03/what-are-the-most-common-rng-seeds-used-in-r-scripts-on-github/\n",
    "    - 1 is by far the most common (60 examples)\n",
    "    - 123 is next (about 25)\n",
    "    - 0 is not on the list\n",
    "    \n",
    "### Is this just an anomaly, or might \"seed 0;\" be useful?\n",
    "\n",
    "- Test Method\n",
    "    - Test with all 67 features, not dropping five multicollinear features\n",
    "    - We have results with seeds 1 and 42\n",
    "    - Test with seed 0 in IVEware, Python, and NumPy\n",
    "\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,167,826  | 100% | \n",
    "    | RF |  591,364  |  27.28 % | \n",
    "    | Mode |  739,696  |  34.12 % | \n",
    "    | Random |  971,759  |  44.83 % | \n",
    "    | IVEware |  447,881  |  20.66 % | \n",
    "    \n",
    "    <br><br>\n",
    "    - Test with seed 0 in IVEware but seed 42 in Python and NumPy in the Binning and Imputation\n",
    "\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,168,989  | 100% | \n",
    "    | RF |  587,221  |  27.07 % | \n",
    "    | Mode |  739,903  |  34.11 % | \n",
    "    | Random |  971,670  |  44.8 % | \n",
    "    | IVEware |  445,195  |  20.53 % | \n",
    "    \n",
    "- Another test method\n",
    "    - Randomly sample from 67 to 40 features and test again\n",
    "    - Note that dropping features will increase the number of samples that have no missing values, so data_Ground_Truth and data_NaN will have fewer features but more samples, so having about the same number of total missing values over the 40 features is not a problem.\n",
    "    - Do it twice with two random seeds.  \n",
    "    - The same random seed for Python and NumPy will preserve, but different random seeds will change:\n",
    "        - Which features get dropped\n",
    "        - Which 15% of the samples will get dropped to make data_NaN for testing the imputation\n",
    "    - Seed 0 in Python and Numpy, seed 0 in IVEware:\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,071,755  | 100% | \n",
    "    | RF |  652,983  |  31.52 % | \n",
    "    | Mode |  774,049  |  37.36 % | \n",
    "    | Random |  997,759  |  48.16 % | \n",
    "    | IVEware |  556,618  |  26.87 % | \n",
    "\n",
    "    - Seed 0 in Python and NumPy, seed 1 in IVEware:\n",
    "\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,071,755  | 100% | \n",
    "    | RF |  652,983  |  31.52 % | \n",
    "    | Mode |  774,049  |  37.36 % | \n",
    "    | Random |  997,759  |  48.16 % | \n",
    "    | IVEware |  738,201  |  35.63 % | \n",
    "    \n",
    "    \n",
    "    - Seed 1 in Python and Numpy, seed 0 in IVEware:\n",
    "\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  1,861,972  | 100% | \n",
    "    | RF |  449,626  |  24.15 % | \n",
    "    | Mode |  547,876  |  29.42 % | \n",
    "    | Random |  737,527  |  39.61 % | \n",
    "    | IVEware |  370,546  |  19.9 % | \n",
    "\n",
    "    - Seed 1 in Python and Numpy, seed 1 in IVEware:\n",
    "    \n",
    "   | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  1,861,972  | 100% | \n",
    "    | RF |  449,626  |  24.15 % | \n",
    "    | Mode |  547,876  |  29.42 % | \n",
    "    | Random |  737,527  |  39.61 % | \n",
    "    | IVEware |  486,820  |  26.15 % | \n",
    "    \n",
    "    - Analysis\n",
    "        - Seed 1 (compared with seed 0) for Python and NumPy appears to have chosen features that are easier to impute\n",
    "        - Within each seed for Python and Numpy, choosing seed 0 for IVEware gave much better results.  \n",
    "    \n",
    "### Conclusion\n",
    "- Setting the IVEware seed to zero is not recommended in the manual, and we think it shouldn't work well, but it works dramatically well with our test methods.  \n",
    "- Use two sets of data from here on, one imputed with Random Forest and another imputed with IVEware with random seed zero.  See which gives best results at the end.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ec94a",
   "metadata": {},
   "source": [
    "# Results of Comparison of Four Imputation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614afad2",
   "metadata": {},
   "source": [
    "- We start with the binned (discretized) data, CRSS_Binned_Data.csv, with 817,623 samples in 67 features.\n",
    "<br><br>\n",
    "- Dropping any sample with a missing value, we have 232,333 samples of Ground Truth.\n",
    "\n",
    "<br><br>\n",
    "- First run with random seed  42 in Python, NumPy, and R:\n",
    "    <br><br>\n",
    "    - Samples Incorrectly Imputed\n",
    "    \n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,168,989  | 100% | \n",
    "    | RF |  589,714  |  27.19 % | \n",
    "    | Mode |  739,903  |  34.11 % | \n",
    "    | Random |  971,670  |  44.8 % | \n",
    "    | IVEware |  622,622  |  28.71 % | \n",
    "\n",
    "    <br><br>\n",
    "    - Comparison of number of errors in the 67 features.  For instance, comparing Random Forest to Mode, in 50 features RF had fewer errors than Mode, in 17 features the two methods had the same number of errors, and in no features did RF have more errors than Mode.  \n",
    "\n",
    "    |  | Fewer | Equal | More | Total | \n",
    "    | --- | --- | --- | --- | --- | \n",
    "    | Compare RF to Mode |  50  |  17  |  0  | 67  |\n",
    "    | Compare RF to Random |  67  |  0  |  0  | 67  |\n",
    "    | Compare RF to IVEware |  34  |  0  |  33  | 67  |\n",
    "    | Compare Mode to Random |  67  |  0  |  0  | 67  |\n",
    "    | Compare Mode to IVEware |  24  |  0  |  43  | 67  |\n",
    "    | Compare Random to IVEware |  5  |  0  |  62  | 67  |\n",
    "\n",
    "    <br><br>\n",
    "     - Number of NaN Imputed Differently by Different Methods\n",
    "\n",
    "    |  | Number |  Percentage |\n",
    "    | --- | --- | -- |\n",
    "    | Total NaN |  2,168,989  | 100% |\n",
    "    | RF Different from Mode |  260,334  |  12.0 % |\n",
    "    | RF Different from Random |  805,376  |  37.13 % |\n",
    "    | RF Different from IVEware |  649,467  |  29.94 % |\n",
    "    | Mode Different from Random |  739,564  |  34.1 % |\n",
    "    | Mode Different from IVEware |  780,385  |  35.98 % |\n",
    "    | Random Different from IVEware |  1,003,065  |  46.25 % |    \n",
    "    \n",
    "<br><br>\n",
    "- Second Run, Same random seed (42) to make sure the random seed is implemented correctly.  Same results. \n",
    "\n",
    "    <br><br>\n",
    "     - Percentage of Samples Incorrectly Imputed\n",
    "     \n",
    "\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,168,989  | 100% | \n",
    "    | RF |  589,714  |  27.19 % | \n",
    "    | Mode |  739,903  |  34.11 % | \n",
    "    | Random |  971,670  |  44.8 % | \n",
    "    | IVEware |  622,622  |  28.71 % | \n",
    "\n",
    "    <br><br>\n",
    "     - Comparison of number of errors in the 67 features:\n",
    "\n",
    "    |  | Fewer | Equal | More | Total | \n",
    "    | --- | --- | --- | --- | --- | \n",
    "    | Compare RF to Mode |  50  |  17  |  0  | 67  |\n",
    "    | Compare RF to Random |  67  |  0  |  0  | 67  |\n",
    "    | Compare RF to IVEware |  34  |  0  |  33  | 67  |\n",
    "    | Compare Mode to Random |  67  |  0  |  0  | 67  |\n",
    "    | Compare Mode to IVEware |  24  |  0  |  43  | 67  |\n",
    "    | Compare Random to IVEware |  5  |  0  |  62  | 67  |\n",
    "\n",
    "    <br><br>\n",
    "     - Number of NaN Imputed Differently by Different Methods\n",
    "\n",
    "    |  | Number |  Percentage |\n",
    "    | --- | --- | -- |\n",
    "    | Total NaN |  2,168,989  | 100% |\n",
    "    | RF Different from Mode |  260,334  |  12.0 % |\n",
    "    | RF Different from Random |  805,376  |  37.13 % |\n",
    "    | RF Different from IVEware |  649,467  |  29.94 % |\n",
    "    | Mode Different from Random |  739,564  |  34.1 % |\n",
    "    | Mode Different from IVEware |  780,385  |  35.98 % |\n",
    "    | Random Different from IVEware |  1,003,065  |  46.25 % |\n",
    "\n",
    "<br><br>\n",
    "- Third run, with random seed 1:\n",
    "\n",
    "    <br><br>\n",
    "    - Samples Incorrectly Imputed by Method\n",
    "\n",
    "   | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,167,935  | 100% | \n",
    "    | RF |  587,894  |  27.12 % | \n",
    "    | Mode |  738,676  |  34.07 % | \n",
    "    | Random |  970,865  |  44.78 % | \n",
    "    | IVEware |  595,206  |  27.45 % | \n",
    "\n",
    "    <br><br>\n",
    "- Comparison of number of errors in the 67 features:\n",
    "\n",
    "    |  | Fewer | Equal | More | Total | \n",
    "    | --- | --- | --- | --- | --- | \n",
    "    | Compare RF to Mode |  51  |  16  |  0  | 67  |\n",
    "    | Compare RF to Random |  67  |  0  |  0  | 67  |\n",
    "    | Compare RF to IVEware |  35  |  0  |  32  | 67  |\n",
    "    | Compare Mode to Random |  67  |  0  |  0  | 67  |\n",
    "    | Compare Mode to IVEware |  22  |  0  |  45  | 67  |\n",
    "    | Compare Random to IVEware |  5  |  0  |  62  | 67  |\n",
    "\n",
    "    <br><br>\n",
    "- Number of NaN Imputed Differently by Pairs of Methods\n",
    "\n",
    "    |  | Number |  Percentage |\n",
    "    | --- | --- | -- |\n",
    "    | Total NaN |  2,167,935  | 100% |\n",
    "    | RF Different from Mode |  252,911  |  11.67 % |\n",
    "    | RF Different from Random |  802,733  |  37.03 % |\n",
    "    | RF Different from IVEware |  620,312  |  28.61 % |\n",
    "    | Mode Different from Random |  738,742  |  34.08 % |\n",
    "    | Mode Different from IVEware |  751,752  |  34.68 % |\n",
    "    | Random Different from IVEware |  978,679  |  45.14 % |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e79629",
   "metadata": {},
   "source": [
    "## Drop Multicollinear Features before Imputing?  Compare two methods\n",
    "- First Method\n",
    "    - After Binning, reduce dimensionality\n",
    "        - Removes MAX_VSEV, VE_FORMS, VTCONT_F, MAX_SEV, NUM_INJV\n",
    "        - Reduces from 67 to 62 features\n",
    "    - Impute\n",
    "- Second Method\n",
    "    - Impute with all 67 features\n",
    "    - Before evaluating the imputation, remove the five features and only evaluate the results on the 62 features used in the comparison above\n",
    "- We used random seed 42 for both methods\n",
    "- First Method Results\n",
    "\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,007,463  | 100% | \n",
    "    | RF |  569,509  |  28.37 % | \n",
    "    | Mode |  681,753  |  33.96 % | \n",
    "    | Random |  889,794  |  44.32 % | \n",
    "    | IVEware |  606,632  |  30.22 % | \n",
    "    \n",
    "- Second Method Results\n",
    "\n",
    "\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,007,235  | 100% | \n",
    "    | RF |  558,936  |  27.85 % | \n",
    "    | Mode |  681,996  |  33.98 % | \n",
    "    | Random |  888,845  |  44.28 % | \n",
    "    | IVEware |  606,062  |  30.19 % | \n",
    "\n",
    "\n",
    "### Analysis\n",
    "- Mode was the same, as it should be.\n",
    "- Random was slightly different, perhaps because the features were in a different order?\n",
    "- IVEware was not significantly different in the two methods.\n",
    "- Random Forest was slightly but significantly better (0.52%) with the second method, not removing the multicollinear features before imputing, which is surprising.  \n",
    "\n",
    "### Conclusion\n",
    "- Run again with different random seed = 1\n",
    "\n",
    "### Second Round Results\n",
    "- First Method\n",
    "\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,006,643  | 100% | \n",
    "    | RF |  568,909  |  28.35 % | \n",
    "    | Mode |  681,061  |  33.94 % | \n",
    "    | Random |  889,048  |  44.31 % | \n",
    "    | IVEware |  592,233  |  29.51 % | \n",
    "\n",
    "\n",
    "- Second Method\n",
    "\n",
    "\n",
    "    | | Number | Percentage |\n",
    "    | --- | --- | --- | \n",
    "    | Total NaN |  2,005,955  | 100% | \n",
    "    | RF |  558,742  |  27.85 % | \n",
    "    | Mode |  680,715  |  33.93 % | \n",
    "    | Random |  887,944  |  44.27 % | \n",
    "    | IVEware |  564,254  |  28.13 % | \n",
    "    \n",
    "### Analysis\n",
    "\n",
    "- Again, the second method, leaving in multicollinear features, is better for both Random Forest and IVEware\n",
    "\n",
    "### Conclusion\n",
    "- When we impute "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32425867",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed07de",
   "metadata": {},
   "source": [
    "- Random imputation is clearly worse than Mode and RF on every feature.\n",
    "- Random is overall worse than IVEware, but on one of our runs there are five features on which Random is better than IVEware.\n",
    "- Random Forest is as good or better than Mode on every feature, which is not surprising, as RF starts at Mode and improves on it.  \n",
    "- Random Forest is as good or better than IVEware on more than half of the features, but not overwhelmingly, and slightly better in the count of missing samples correctly imputed.\n",
    "- IVEware and Mode are comparable in the number of features, but IVEware is much better in the count of missing samples correctly imputed.\n",
    "- Random Forest and Mode make the same mistakes.  \n",
    "- IVEware makes different mistakes from Random Forest and Mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d8b76",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e27f7d",
   "metadata": {},
   "source": [
    "- Use Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6fe8c",
   "metadata": {},
   "source": [
    "## Opportunities for Future Research\n",
    "(or, \"Things we didn't do\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9bb784",
   "metadata": {},
   "source": [
    "- Which features are better imputed by Random imputation than by IVEware, and why?\n",
    "- Which features are better imputed by IVEware than by Random Forest, and why?\n",
    "- Would a different mix of features make IVEware perform better than Random Forest?\n",
    "- Is it okay to use one imputation method for some features and another method for other features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd6971",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db3b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, copy, math, time, os\n",
    "\n",
    "print ('Python version: {}'.format(sys.version))\n",
    "\n",
    "import numpy as np\n",
    "print ('NumPy version: {}'.format(np.__version__))\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "print ('Pandas version:  {}'.format(pd.__version__))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import sklearn\n",
    "print ('SciKit-Learn version: {}'.format(sklearn.__version__))\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from missforest.missforest import MissForest\n",
    "\n",
    "# Set Randomness.  Copied from https://www.kaggle.com/code/abazdyrev/keras-nn-focal-loss-experiments\n",
    "import random\n",
    "random_seed = 1\n",
    "np.random.seed(random_seed) # NumPy\n",
    "random.seed(random_seed) # Python\n",
    "#tf.set_random_seed(random_seed) # Tensorflow\n",
    "\n",
    "from IPython.display import Audio\n",
    "sound_file = './beep.wav'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print ('Finished Importing Libraries')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075d05f7",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "This notebook pulls in the saved output of Ambulance_Dispatch_2024_02_Binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ba441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data():\n",
    "    print ('Get_Data')\n",
    "    data = pd.read_csv('../../Big_Files/CRSS_Binned_Data.csv', low_memory=False)\n",
    "#    data = pd.read_csv('../../Big_Files/CRSS_Binned_Data_Seed_42.csv', low_memory=False)\n",
    "#    data = pd.read_csv('../../Big_Files/CRSS_Binned_Reduced_Dimensionality_Data.csv', low_memory=False)\n",
    "    print ('data.shape = ', data.shape)\n",
    "    print ()\n",
    "\n",
    "    # We already dropped the imputed columns in the Binning stage\n",
    "    print ('Drop Imputed Columns')\n",
    "    for feature in data:\n",
    "        if '_IM' in feature:\n",
    "            print (feature)\n",
    "            data.drop(columns=feature, inplace=True)\n",
    " \n",
    "\n",
    "    # Method for dropping from 67 to 40 features \n",
    "    # to test whether it was just this particular mix of features \n",
    "    # that made the IVEware behave strangely well with random seed of zero.\n",
    "#    print ('data.shape = ', data.shape)\n",
    "#    data = data.sample(n=40, axis='columns')\n",
    "    \n",
    "    print ('data.shape = ', data.shape)\n",
    "    print ()\n",
    "    \n",
    "    print (\"Remaining Features:\")\n",
    "    Features = sorted(list(data.columns))\n",
    "    for feature in Features:\n",
    "        print (\"    \",feature)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d026ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = Get_Data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a664ab1",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489df19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Impute_MissForest(data):\n",
    "\n",
    "    display(data.head(20))\n",
    "#    data.replace({np.nan: ''}, inplace=True)\n",
    "#    display(data.head(20))\n",
    "\n",
    "    categorical = list(data)\n",
    "    print (categorical)\n",
    "    data_MF = MissForest().fit_transform(\n",
    "        x = data,\n",
    "        categorical=categorical,\n",
    "    )\n",
    "    display(data_MF.head(20))\n",
    "    \n",
    "    return data_MF\n",
    "    \n",
    "data = Get_Data()\n",
    "data.replace({99:np.nan}, inplace=True)\n",
    "#data = data.sample(20, axis='columns')\n",
    "#data = data.sample(frac=0.50, axis='rows')\n",
    "print (data.shape)\n",
    "Impute_MissForest(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defec34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Impute_Round_Robin(data):\n",
    "    print ('Impute()')\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    \n",
    "    # Replace 'Unknown' with np.NaN\n",
    "#    data.replace({'Unknown': np.nan}, inplace=True)\n",
    "    data.replace({99: np.nan}, inplace=True)\n",
    "    display(data.head(20))\n",
    "    print ()\n",
    "    \n",
    "    # Make a list of features with missing samples, \n",
    "    #     ordered by the number of missing samples, \n",
    "    #     from least to most.  \n",
    "    Missing = []\n",
    "    Complete = []\n",
    "    for feature in data:\n",
    "        s = data[feature].isna().sum()\n",
    "        if s==0:\n",
    "            Complete.append([feature, s])\n",
    "        if s>0:\n",
    "            Missing.append([feature, s])\n",
    "    Missing = sorted (Missing, key=lambda x:x[1], reverse=False)\n",
    "    print ()\n",
    "    print ('Complete[]')\n",
    "    display(Complete)\n",
    "    print ()\n",
    "    print ('Missing[]')\n",
    "    display(Missing)\n",
    "    print ()\n",
    "    \n",
    "    print ('Make data_Mode')\n",
    "    print ()\n",
    "    data_Mode = pd.DataFrame()\n",
    "    for X in Complete:\n",
    "        feature = X[0]\n",
    "        data_Mode[feature] = data[feature]\n",
    "    for M in Missing:\n",
    "        feature = M[0]\n",
    "        m = data[feature].mode()[0]\n",
    "        print (feature, M[1], m)\n",
    "        data_Mode[feature] = data[feature].fillna(m)\n",
    "    print ('data_Mode')\n",
    "    display(data_Mode.head(20))\n",
    "\n",
    "    print ()\n",
    "    print ('Make starting point for data_Imputed')\n",
    "    data_Imputed = pd.DataFrame()\n",
    "    for X in Complete:\n",
    "        feature = X[0]\n",
    "        data_Imputed[feature] = data[feature]\n",
    "    for X in Missing:\n",
    "        feature = X[0]\n",
    "        data_Imputed[feature] = data_Mode[feature]\n",
    "    print ('data_Imputed')\n",
    "    display(data_Imputed.head(20))\n",
    "    print ()\n",
    "\n",
    "    print ('Start Loop')\n",
    "    print ()\n",
    "    n = 0\n",
    "    for M in Missing:\n",
    "        n += 1\n",
    "        print (M)\n",
    "        feature = M[0]\n",
    "        data_Imputed[feature] = data[feature]\n",
    "#        print ()\n",
    "#        print ('data[feature].isna().sum()')\n",
    "#        print (data[feature].isna().sum())\n",
    "#        print ('data_Imputed[feature].isna().sum()')\n",
    "#        print (data_Imputed[feature].isna().sum())\n",
    "#        print ()\n",
    "        W = data_Imputed.dropna(subset=[feature])\n",
    "        X = data_Imputed.dropna(subset=[feature])\n",
    "        y = X[feature]\n",
    "        X.drop(columns=feature, inplace=True)\n",
    "        Z = data_Imputed[data_Imputed[feature].isna()]\n",
    "        Z.drop(columns=feature, inplace=True)\n",
    "#        Z.reset_index(drop=True, inplace=True)\n",
    "#        print (data.shape)\n",
    "#        print (X.shape)\n",
    "#        display(X.head(40))\n",
    "#        display(y.head(40))\n",
    "#        print (Z.shape)\n",
    "#        display(Z)\n",
    "        clf = RandomForestClassifier(max_depth=2, random_state=random_seed)\n",
    "        clf.fit(X,y)\n",
    "#        print ('clf.predict(Z)')\n",
    "        z = clf.predict(Z)\n",
    "        print (len(z))\n",
    "        display(z)\n",
    "        Z[feature] = z\n",
    "#        display(Z)\n",
    "        data_Imputed = pd.concat([Z, W])\n",
    "#        display(data_Imputed.head(60))\n",
    "        print (data_Imputed.shape)\n",
    "        print ()\n",
    "#        data_Imputed.sort_values(\n",
    "#            by = ['CASENUM', 'VEH_NO', 'PER_NO'], \n",
    "#            ascending = [True, True, True], \n",
    "#            inplace=True\n",
    "#        )\n",
    "#        print ()\n",
    "#        print ('data.PER_NO.equals(data_Imputed.PER_NO)')\n",
    "#        print (data.PER_NO.equals(data_Imputed.PER_NO))\n",
    "#        print ()\n",
    "               \n",
    "        Check_Feature(data, data_Imputed, feature)\n",
    "#        if n==10:\n",
    "#            return data_Imputed\n",
    "    \n",
    "    \n",
    "    display(data_Imputed.head(20))\n",
    "\n",
    "    \n",
    "    print ()\n",
    "    return data_Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a34ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check(data, data_Imputed):\n",
    "    Features = data.columns\n",
    "    print (Features)\n",
    "    for feature in Features:\n",
    "        U = pd.unique(data[feature]).tolist()\n",
    "        print (U)\n",
    "        A = []\n",
    "        for u in U:\n",
    "            a = len(data[data[feature]==u])\n",
    "            b = len(data_Imputed[data_Imputed[feature]==u])\n",
    "            A.append([u, a, b])\n",
    "        display(A)\n",
    "        print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Feature(data, data_Imputed, feature):\n",
    "    U = pd.unique(data[feature]).tolist()\n",
    "    U = [x for x in U if x == x]\n",
    "    print (U)\n",
    "    A = []\n",
    "    for u in U:\n",
    "        a = len(data[data[feature]==u])\n",
    "        b = len(data_Imputed[data_Imputed[feature]==u])\n",
    "        A.append([u, a, b, b-a])\n",
    "    a = data[feature].isna().sum()\n",
    "    b = data_Imputed[feature].isna().sum()\n",
    "    A.append(['NaN', a, b, 0])\n",
    "    A = pd.DataFrame(A, columns=['Value', 'Original', 'Imputed', 'Difference'])\n",
    "    display(A)\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Impute_Randomly(data):\n",
    "    print ()\n",
    "    print ('Impute_Randomly()')\n",
    "    print ()\n",
    "    \n",
    "    data.sample(frac=1, replace=True) # Randomly shuffle the rows of the dataset\n",
    "    for feature in data:\n",
    "        print (feature)\n",
    "#        print ('display(data[feature].head())')\n",
    "#        display(data[feature].head())\n",
    "        dfA = data[feature]\n",
    "#        print ('display(dfA.head())')\n",
    "#        display(dfA.head())\n",
    "        dfA.dropna(inplace=True)\n",
    "#        print ('display(dfA.head()) after dfA.dropna(inplace=True)')\n",
    "#        display(dfA.head())\n",
    "        print ('Original Value Counts')\n",
    "        print (dfA.value_counts(normalize=True))\n",
    "        dfA = dfA.sample(n = len(data), replace=True)\n",
    "#        print ('display(dfA.head()) after dfA.sample(n = len(data), replace=True)')\n",
    "#        display(dfA.head())\n",
    "        print ('Value Counts after Sampling')\n",
    "        print (dfA.value_counts(normalize=True))\n",
    "        dfA.reset_index(drop=True, inplace=True)\n",
    "#        print ('display(dfA.head()) after dfA.reset_index(drop=True)')\n",
    "#        display(dfA.head())\n",
    "        data[feature].fillna(dfA, inplace=True)\n",
    "#        print ('display(data[feature].head())')\n",
    "#        display(data[feature].head())        \n",
    "        print ()\n",
    "        \n",
    "    return data\n",
    "        \n",
    "def Test_Impute_Randomly():\n",
    "    Dict = {\n",
    "        'A':[0,0,0,1,np.nan],\n",
    "        'B':[1,2,3,4,np.nan]\n",
    "    }\n",
    "    \n",
    "    data = pd.DataFrame(Dict)\n",
    "    display(data)\n",
    "    data = Impute_Randomly(data)\n",
    "    display(data)\n",
    "    \n",
    "#Test_Impute_Randomly()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c72a63",
   "metadata": {},
   "source": [
    "# Compare Imputation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25a5b4",
   "metadata": {},
   "source": [
    "## Mode Imputation\n",
    "## Random Forest Imputation\n",
    "## Prepare Data for IVEware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_Imputation_Methods_Part_1():\n",
    "    print ()\n",
    "    print ('Compare_Imputation_Methods_Part_1()')\n",
    "    data = Get_Data()\n",
    "    print (data.shape)\n",
    "\n",
    "    # Drop all samples with missing data, so we have ground truth\n",
    "    data_Ground_Truth = data.replace({99:np.nan})\n",
    "    data_Ground_Truth = data_Ground_Truth.dropna()\n",
    "    data_Ground_Truth.reset_index(inplace=True, drop=True)\n",
    "    for feature in data_Ground_Truth:\n",
    "        data_Ground_Truth[feature] = pd.to_numeric(data_Ground_Truth[feature])\n",
    "    data_Ground_Truth.astype('int64')\n",
    "\n",
    "    for feature in data_Ground_Truth:\n",
    "        data_Ground_Truth[feature] = pd.to_numeric(data_Ground_Truth[feature])\n",
    "    data_Ground_Truth = data_Ground_Truth.astype('int64')\n",
    "    print ('data_Ground_Truth.shape')\n",
    "    print (data_Ground_Truth.shape)\n",
    "    display(data_Ground_Truth.head())\n",
    "\n",
    "    # Randomly pick 15% of the values from each row\n",
    "    # and set them to be missing\n",
    "    print ('Remove 15% of values from each row')\n",
    "    frac = .15\n",
    "    data_NaN = data_Ground_Truth.copy(deep=True)\n",
    "    N = data_NaN.shape[0] * frac # Number of NaN in each feature\n",
    "    for c in data_NaN.columns:\n",
    "        idx = np.random.choice(a=data_NaN.index, size=int(len(data_NaN) * frac))\n",
    "        data_NaN.loc[idx, c] = np.NaN\n",
    "#    for feature in data_NaN:\n",
    "#        data_NaN[feature] = pd.to_numeric(data_NaN[feature])\n",
    "#    data_NaN.astype('int64')\n",
    "\n",
    "\n",
    "    print ('data_NaN.shape')\n",
    "    print (data_NaN.shape)\n",
    "    display(data_NaN.head())\n",
    "    \n",
    "    # Perform MissForest imputation\n",
    "    data_MF = Impute_MissForest(data_NaN)\n",
    "    data_MF.sort_index(inplace=True)\n",
    "    data_MF = data_MF[data.columns]  \n",
    "    data_MF = data_MF.astype('int64')\n",
    "    \n",
    "    print ('data_MF.shape')\n",
    "    print (data_MF.shape)\n",
    "    display(data_MF.head())\n",
    "#    print ()\n",
    "\n",
    "    \n",
    "    # Create .txt file to feed into IVEware imputation\n",
    "    data_IVEware = data_NaN.copy(deep=True)\n",
    "    data_IVEware = data_IVEware.fillna('')\n",
    "    data_IVEware.to_csv('../../Big_Files/data_IVEware.txt', sep='\\t', index=False)\n",
    "    \n",
    "    data_Mode = pd.DataFrame()\n",
    "    for feature in data_NaN:\n",
    "        data_Mode[feature] = data_NaN[feature].fillna(data_NaN[feature].mode()[0])\n",
    "    data_Mode = data_Mode.astype('int64')\n",
    "    print ('data_Mode.shape')\n",
    "    print (data_Mode.shape)\n",
    "    display(data_Mode.head())\n",
    "    \n",
    "    # Perform Round Robin imputation using Random Forest Classifier\n",
    "    data_RF = Impute_Round_Robin(data_NaN)\n",
    "    data_RF.sort_index(inplace=True)\n",
    "    data_RF = data_RF[data.columns]  \n",
    "    data_RF = data_RF.astype('int64')\n",
    "    \n",
    "    print ('data_RF.shape')\n",
    "    print (data_RF.shape)\n",
    "    display(data_RF.head())\n",
    "#    print ()\n",
    "\n",
    "    # Impute randomly\n",
    "    data_Random = data_NaN.copy(deep=True)\n",
    "    data_Random = Impute_Randomly(data_Random)\n",
    "    data_Random = data_Random.astype('int64')\n",
    "    \n",
    "    print ('data_Random.shape')\n",
    "    print (data_Random.shape)\n",
    "    display(data_Random.head())\n",
    "#    print ()\n",
    "\n",
    "    return data_Ground_Truth, data_NaN, data_RF, data_MF, data_Mode, data_Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0ab36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "data_Ground_Truth, data_NaN, data_RF, data_MF, data_Mode, data_Random = Compare_Imputation_Methods_Part_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c93a1",
   "metadata": {},
   "source": [
    "## Do IVEware Imputation (Outside this Jupyter Notebook)\n",
    "- Go to the IVEware folder and run (at the command line) IVE_12_22_22.bat\n",
    "- Requires scrlib and R.  You may need to, in the batch file, change the path to your scrlib installation.\n",
    "- Notes to self:\n",
    "    - Open srcshell\n",
    "    - From srcshell, open IVEware_CRSS_Imputation.xml\n",
    "    - Run\n",
    "- Run time: ./IVEware_CRSS_Imputation.bat  1069.08s user 12.92s system 98% cpu 18:23.92 total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5f0d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_IVEware = pd.read_csv('../../Big_Files/data_IVEware.csv')\n",
    "data_IVEware.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "print ('data_Ground_Truth', data_Ground_Truth.shape)\n",
    "display(data_Ground_Truth.head(10))\n",
    "print ('data_NaN', data_NaN.shape)\n",
    "display(data_NaN.head(10))\n",
    "print ('data_RF', data_RF.shape)\n",
    "display(data_RF.head(10))\n",
    "print ('data_MF', data_RM.shape)\n",
    "display(data_MF.head(10))\n",
    "print ('data_Mode', data_Mode.shape)\n",
    "display(data_Mode.head(10))\n",
    "print ('data_IVEware', data_IVEware.shape)\n",
    "display(data_IVEware.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7745a",
   "metadata": {},
   "source": [
    "## Compare Three Imputation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf238635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_Imputation_Methods_Part_2(\n",
    "    data_Ground_Truth, data_NaN, data_RF, data_MF, data_Mode, data_Random, data_IVEware\n",
    "):\n",
    "    print ('Compare_Imputation_Methods_Part_2')\n",
    "    \n",
    "    \"\"\"\n",
    "    print ('Drop Multicollinear Features')\n",
    "    Drop = ['MAX_VSEV', 'VE_FORMS', 'VTCONT_F', 'MAX_SEV', 'NUM_INJV']\n",
    "    DF = [data_Ground_Truth, data_NaN, data_RF, data_Mode, data_Random, data_IVEware]\n",
    "    \n",
    "    for df in DF:\n",
    "        for feature in Drop:\n",
    "            if feature in df:\n",
    "                df.drop(columns=[feature], inplace=True)\n",
    "                print ('Drop ', feature)\n",
    "    print ()\n",
    "    \"\"\"\n",
    "    \n",
    "    print ('data_Ground_Truth.shape: ', data_Ground_Truth.shape)\n",
    "    print ('data_NaN.shape: ', data_NaN.shape)\n",
    "    print ('data_RF.shape: ', data_RF.shape)\n",
    "    print ('data_MF.shape: ', data_MF.shape)\n",
    "    print ('data_Mode.shape: ', data_Mode.shape)\n",
    "    print ('data_Random.shape: ', data_Random.shape)\n",
    "    print ('data_IVEware.shape: ', data_IVEware.shape)\n",
    "    print ()\n",
    "    \n",
    "    \n",
    "    \n",
    "    A = []\n",
    "    for feature in data_NaN:\n",
    "        N = data_NaN[feature].isna().sum()\n",
    "#        print (feature, N)\n",
    "#        print ()\n",
    "        D = data_Ground_Truth[feature] != data_RF[feature]\n",
    "        d = D.sum()\n",
    "        E = data_Ground_Truth[feature] != data_Mode[feature]\n",
    "        e = E.sum()\n",
    "        F = data_Ground_Truth[feature] != data_Random[feature]\n",
    "        f = F.sum()\n",
    "        G = data_Ground_Truth[feature] != data_IVEware[feature]\n",
    "        g = G.sum()\n",
    "        H = data_RF[feature] != data_Mode[feature]\n",
    "        h = H.sum()\n",
    "        I = data_RF[feature] != data_Random[feature]\n",
    "        i = I.sum()\n",
    "        J = data_RF[feature] != data_IVEware[feature]\n",
    "        j = J.sum()\n",
    "        K = data_Mode[feature] != data_Random[feature]\n",
    "        k = K.sum()\n",
    "        L = data_Mode[feature] != data_IVEware[feature]\n",
    "        l = L.sum()\n",
    "        M = data_Random[feature] != data_IVEware[feature]\n",
    "        m = M.sum()\n",
    "        print (feature, N, d, e, f, g, h, i, j, k, l, m)\n",
    "        print (\n",
    "            feature, \n",
    "            data_Ground_Truth.dtypes[feature],\n",
    "            data_NaN.dtypes[feature],\n",
    "            data_RF.dtypes[feature],\n",
    "            data_Mode.dtypes[feature],\n",
    "            data_Random.dtypes[feature],\n",
    "            data_IVEware.dtypes[feature],\n",
    "        )\n",
    "        A.append([\n",
    "            feature, # 0\n",
    "            N,  # 1\n",
    "            d, int(d/N*100), # 2, 3\n",
    "            e, int(e/N*100), # 4, 5\n",
    "            f, int(f/N*100), # 6, 7\n",
    "            g, int(g/N*100), # 8, 9\n",
    "            h, int(h/N*100), # 10, 11\n",
    "            i, int(i/N*100), # 12, 13\n",
    "            j, int(j/N*100), # 14, 15\n",
    "            k, int(k/N*100), # 16, 17\n",
    "            l, int(l/N*100), # 18, 19\n",
    "            m, int(m/N*100), # 20, 21\n",
    "        ])\n",
    "    print ()\n",
    "    \n",
    "    A = sorted(A, key=lambda x:x[3])\n",
    "    B = pd.DataFrame(\n",
    "        A, \n",
    "        columns=[\n",
    "            'Feature', # 0\n",
    "            'nNaN',  # 1\n",
    "            'nRF Incorrect', 'pRF Incorrect', # 2, 3\n",
    "            'nMode Incorrect', 'pMode Incorrect', # 4, 5\n",
    "            'nRandom Incorrect', 'pRandom Incorrect', # 6, 7\n",
    "            'nIVEware Incorrect', 'pIVEware Incorrect', # 8, 9\n",
    "            'RF and Mode Different', 'RF v/s Mode %', # 10, 11\n",
    "            'RF and Random Different', 'RF v/s Random %', # 12, 13\n",
    "            'RF and IVEware Different', 'RF v/s IVEware %', # 14, 15\n",
    "            'Mode and Random Different', 'Mode v/s Random %', # 16, 17\n",
    "            'Mode and IVEware Different', 'Mode v/s IVEware %', #, 18, 19\n",
    "            'Random and IVEware Different', 'Random v/s IVEware %', # 20, 21\n",
    "        ]\n",
    "    )\n",
    "    display(B)\n",
    "    a = sum([x[1] for x in A]) # nNaN\n",
    "    b = sum([x[2] for x in A]) # nRF Incorrect\n",
    "    c = sum([x[4] for x in A]) # nMode INcorrect\n",
    "    d = sum([x[6] for x in A]) # nRandom Incorrect\n",
    "    e = sum([x[8] for x in A]) # nIVEware Incorrect\n",
    "    f = round(b/a*100,2)\n",
    "    g = round(c/a*100,2)\n",
    "    h = round(d/a*100,2)\n",
    "    i = round(e/a*100,2)\n",
    "\n",
    "    RF_less_Mode = sum([x[2] < x[4] for x in A])\n",
    "    RF_equal_Mode = sum([x[2] == x[4] for x in A])\n",
    "    RF_greater_Mode = sum([x[2] > x[4] for x in A])\n",
    "\n",
    "    RF_less_Random = sum([x[2] < x[6] for x in A])\n",
    "    RF_equal_Random = sum([x[2] == x[6] for x in A])\n",
    "    RF_greater_Random = sum([x[2] > x[6] for x in A])\n",
    "\n",
    "    RF_less_IVEware = sum([x[2] < x[8] for x in A])\n",
    "    RF_equal_IVEware = sum([x[2] == x[8] for x in A])\n",
    "    RF_greater_IVEware = sum([x[2] > x[8] for x in A])\n",
    "\n",
    "    Mode_less_Random = sum([x[4] < x[6] for x in A])\n",
    "    Mode_equal_Random = sum([x[4] == x[6] for x in A])\n",
    "    Mode_greater_Random = sum([x[4] > x[6] for x in A])\n",
    "\n",
    "    Mode_less_IVEware = sum([x[4] < x[8] for x in A])\n",
    "    Mode_equal_IVEware = sum([x[4] == x[8] for x in A])\n",
    "    Mode_greater_IVEware = sum([x[4] > x[8] for x in A])\n",
    "\n",
    "    Random_less_IVEware = sum([x[6] < x[8] for x in A])\n",
    "    Random_equal_IVEware = sum([x[6] == x[8] for x in A])\n",
    "    Random_greater_IVEware = sum([x[6] > x[8] for x in A])\n",
    "\n",
    "    print ()\n",
    "    print ('    | | Number | Percentage |')\n",
    "    print ('    | --- | --- | --- | ')    \n",
    "    print ('    | Total NaN | ', f'{a:,d}', ' | 100% | ')\n",
    "    print ('    | RF | ', f'{b:,d}', ' | ', f, '% | ')\n",
    "    print ('    | Mode | ', f'{c:,d}', ' | ', g, '% | ')\n",
    "    print ('    | Random | ', f'{d:,d}', ' | ', h, '% | ')\n",
    "    print ('    | IVEware | ', f'{e:,d}', ' | ', i, '% | ')\n",
    "    print ()\n",
    "    print ('    |  | Fewer | Equal | More | Total | ')\n",
    "    print ('    | --- | --- | --- | --- | --- | ')\n",
    "    print ('    | Compare RF to Mode | ', RF_less_Mode, ' | ', RF_equal_Mode,  ' | ' ,RF_greater_Mode,  ' |', len(A), ' |' )\n",
    "    print ('    | Compare RF to Random | ', RF_less_Random, ' | ' , RF_equal_Random,  ' | ' , RF_greater_Random,  ' |', len(A), ' |' )\n",
    "    print ('    | Compare RF to IVEware | ', RF_less_IVEware, ' | ' , RF_equal_IVEware, ' | ' , RF_greater_IVEware, ' |', len(A), ' |' )\n",
    "    print ('    | Compare Mode to Random | ', Mode_less_Random, ' | ' , Mode_equal_Random, ' | ' , Mode_greater_Random, ' |', len(A), ' |' )\n",
    "    print ('    | Compare Mode to IVEware | ', Mode_less_IVEware, ' | ' , Mode_equal_IVEware, ' | ' , Mode_greater_IVEware, ' |', len(A), ' |' )\n",
    "    print ('    | Compare Random to IVEware | ', Random_less_IVEware, ' | ' , Random_equal_IVEware, ' | ' , Random_greater_IVEware, ' |', len(A), ' |' )\n",
    "    print ()\n",
    "    \n",
    "    p = sum([x[10] for x in A])\n",
    "    q = sum([x[12] for x in A])\n",
    "    r = sum([x[14] for x in A])\n",
    "    s = sum([x[16] for x in A])\n",
    "    t = sum([x[18] for x in A])\n",
    "    u = sum([x[20] for x in A])\n",
    "    f = round(p/a*100,2)\n",
    "    g = round(q/a*100,2)\n",
    "    h = round(r/a*100,2)\n",
    "    i = round(s/a*100,2)\n",
    "    j = round(t/a*100,2)\n",
    "    k = round(u/a*100,2)\n",
    "    \n",
    "    print ('    |  | Number |  Percentage |')\n",
    "    print ('    | --- | --- | -- |')\n",
    "    print ('    | Total NaN | ', f'{a:,d}', ' | 100% |' )\n",
    "    print ('    | RF Different from Mode | ', f'{p:,d}', ' | ', f, '% |')\n",
    "    print ('    | RF Different from Random | ', f'{q:,d}', ' | ', g, '% |')\n",
    "    print ('    | RF Different from IVEware | ', f'{r:,d}', ' | ', h, '% |')\n",
    "    print ('    | Mode Different from Random | ', f'{s:,d}', ' | ', i, '% |')\n",
    "    print ('    | Mode Different from IVEware | ', f'{t:,d}', ' | ', j, '% |')\n",
    "    print ('    | Random Different from IVEware | ', f'{u:,d}', ' | ', k, '% |' )\n",
    "    print ()\n",
    "        \n",
    "#    display(Audio(sound_file, autoplay=True))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1fa807",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Compare_Imputation_Methods_Part_2(\n",
    "    data_Ground_Truth, data_NaN, data_RF, data_Mode, data_Random, data_IVEware\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a03ad4a",
   "metadata": {},
   "source": [
    "# Impute using Random Forest and Save for Next Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75392b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Impute_Using_Random_Forest():\n",
    "    data = Get_Data()\n",
    "    \n",
    "#    data_Imputed = Impute_Full(data)\n",
    "    data_Imputed = Impute_Round_Robin(data)\n",
    "    data_Imputed.to_csv('../../Big_Files/CRSS_Imputed_by_RF_Data.csv', index=False)\n",
    "#    display(data_Imputed.head(50))\n",
    "    \n",
    "    Check(data, data_Imputed)\n",
    "#    display(Audio(sound_file, autoplay=True))\n",
    "    return 0\n",
    "\n",
    "Impute_Using_Random_Forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af31f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Impute_Using_IVEware():\n",
    "    data = Get_Data()\n",
    "    \n",
    "    # Create .txt file to feed into IVEware imputation\n",
    "    data_IVEware = data.copy(deep=True)\n",
    "    print (data_IVEware.shape)\n",
    "    display(data_IVEware.head(10))\n",
    "    \n",
    "    data_IVEware = data_IVEware.replace(99,'')\n",
    "    display(data_IVEware.head(10))\n",
    "    data_IVEware.to_csv('../../Big_Files/data_IVEware.txt', sep='\\t', index=False)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "Impute_Using_IVEware()\n",
    "# About one hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_2_11",
   "language": "python",
   "name": "tensorflow_2_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
